import cv2
import dlib
import numpy as np
import threading
from imutils import face_utils
from PIL import ImageFont, ImageDraw, Image
from dao.monitoring_dao import MonitoringDAO
from fastapi.responses import StreamingResponse
from scipy.spatial import distance as dist

import time
import pygame
import os
import json

from config.websocket import get_manager



class MonitoringService:
    def __init__(self):
        self.running = False  # ëª¨ë‹ˆí„°ë§ ìƒíƒœ (ì¼œì§/êº¼ì§), ê¸°ë³¸ì ìœ¼ë¡œ ì‹¤í–‰ìƒíƒœ
        self.detector = dlib.get_frontal_face_detector()  # ì–¼êµ´ ê²€ì¶œê¸°
        self.status = False # ê¸°ë³¸ê°’
        self.monitoring_dao = MonitoringDAO
        self.cap = None  # OpenCV VideoCapture ê°ì²´
        self.thread = None  # ì‹¤í–‰ ì¤‘ì¸ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ

        # ìµœì í™”ìš© ìˆ˜ì¹˜
        self.frame_count = 0
        self.current_rects = []
        self.current_gray = None
        
        # self.predictor = dlib.shape_predictor("models/shape_predictor_68_face_landmarks.dat")  # ëœë“œë§ˆí¬ => ì•„ë˜ì—ì„œ í˜¸ì¶œ ì¤‘ í•„ìš”ì—†ìŒ
                
        # âœ… ì‹œì„  ì´íƒˆ ê°ì§€ ë³€ìˆ˜
        self.GAZE_COUNT = 0  
        self.LAST_GAZE_TIME = None  
        self.NORMAL_GAZE_TIME = 0 # í˜„ì¬ì‹œê°„ì—ì„œ ê°’ì´ ì¶”ê°€ë˜ëŠ” ê²ƒ ê°™ì•„ì„œ 0ìœ¼ë¡œ ìˆ˜ì •
        self.GAZE_TIME_THRESH = 2  
        self.HEAD_ANGLE_THRESH_X = 0.08  
        self.HEAD_ANGLE_THRESH_Y = 0.1  
        self.RESET_TIME_THRESH = 60  # 1ë¶„ ë™ì•ˆ ì •ìƒ ì‹œì„  ìœ ì§€ ì‹œ ì´ˆê¸°í™”

        self.BASE_HEAD_X = 0.0  # ê¸°ë³¸ê°’ì„ 0ìœ¼ë¡œ ì„¤ì • 
        self.BASE_HEAD_Y = 0.0  
        
                # ì¡¸ìŒ ê°ì§€ ê´€ë ¨ ë³€ìˆ˜ ì¶”ê°€
        self.EYE_CLOSED_TIME = 0  # ëˆˆ ê°ê³  ìˆëŠ” ëˆ„ì  ì‹œê°„ (ì´ˆ)
        self.DROWSY_WARNING_ACTIVE = False  # ì¡¸ìŒ ì£¼ì˜ ìƒíƒœ ì—¬ë¶€
        self.SLEEPY_WARNING_ACTIVE = False  # ì¡¸ìŒ ê²½ê³  ìƒíƒœ ì—¬ë¶€
        self.LAST_DROWSY_TIME = None  # ë§ˆì§€ë§‰ ì¡¸ìŒ ìƒíƒœ ê¸°ë¡
        self.LAST_WARNING_TIME = None  # ë§ˆì§€ë§‰ ê²½ê³  ìƒíƒœ ê¸°ë¡
        
        # ì¡¸ìŒ ê°ì§€ ê¸°ì¤€ ë³€ìˆ˜ ì¶”ê°€
        self.EYE_AR_THRESH = 0.20  # ëˆˆ ê°ì€ ìƒíƒœ ê¸°ì¤€
        self.MOUTH_AR_THRESH = 0.75  # í•˜í’ˆ ê¸°ì¤€
        self.DROWSY_DISPLAY_TIME = 10  # ì£¼ì˜ ìƒíƒœ í‘œì‹œ ì‹œê°„
        self.WARNING_DISPLAY_TIME = 60  # ê²½ê³  ìƒíƒœ í‘œì‹œ ì‹œê°„ (1ë¶„ê°„ ìœ ì§€)
        
        # ì¹´ìš´íŠ¸ ë³€ìˆ˜ ì¶”ê°€
        self.EYE_COUNTER = 0  # ëˆˆ ê°ì€ ì‹œê°„ ì¹´ìš´íŠ¸
        self.MOUTH_COUNTER = 0  # í•˜í’ˆ ì§€ì† ì¹´ìš´íŠ¸
        self.BLINK_COUNTER = 0  # ëˆˆ ê¹œë¹¡ì„ íšŸìˆ˜ (1ë¶„ ë‚´)
        self.YAWN_COUNTER = 0  # í•˜í’ˆ íšŸìˆ˜ (1ë¶„ ë‚´)
        self.RESET_TIME = time.time()  # 1ë¶„ ê¸°ì¤€ ì´ˆê¸°í™” ì‹œê°„
        self.LAST_YAWN_TIME = 0  # ë§ˆì§€ë§‰ í•˜í’ˆ ê°ì§€ ì‹œê°„ ì´ˆê¸°í™”

        # ì¡¸ìŒ í…ìŠ¤íŠ¸ ìœ ì§€ìš©
        self.text_display_state = None  # 'none', 'drowsy', 'sleepy' ì¤‘ í•˜ë‚˜ì˜ ìƒíƒœë§Œ ìœ ì§€
        self.text_state_change_time = 0  # ìƒíƒœ ë³€ê²½ ì‹œê°„
        
        # ì¡¸ìŒ ê°ì§€ ìƒíƒœ ê´€ë¦¬ ë³€ìˆ˜ ì¶”ê°€
        self.DROWSY_WARNING_ACTIVE = False
        self.SLEEPY_WARNING_ACTIVE = False
        self.LAST_DROWSY_TIME = None
        self.LAST_WARNING_TIME = None
        
        # âœ… í•œê¸€ í°íŠ¸ ì„¤ì •
        font_path = "C:/Windows/Fonts/malgun.ttf"
        self.font = ImageFont.truetype(font_path, 30)
        
        # âœ… ê²½ê³ ìŒ ì„¤ì •
        pygame.mixer.init()
        self.ALERT_SOUND = "alert.mp3"
        try:
            pygame.mixer.music.load(self.ALERT_SOUND)
        except pygame.error:
            print("âš ï¸ ê²½ê³ ìŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        # âœ… ëª¨ë¸ íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œ ì„¤ì •
        base_dir = os.path.dirname(os.path.abspath(__file__))  # í˜„ì¬ íŒŒì¼ì´ ìœ„ì¹˜í•œ ë””ë ‰í† ë¦¬
        # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
        model_dir = os.path.join(base_dir, "..", "models")
        # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ì ˆëŒ€ ê²½ë¡œ ì„¤ì •
        model_path = os.path.join(model_dir, "../models/shape_predictor_68_face_landmarks.dat")

        try:
            # ëª¨ë¸ íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œ í™•ì¸ (ë””ë²„ê¹…ìš©)
            base_dir = os.path.dirname(os.path.abspath(__file__))
            model_path = os.path.join(base_dir, "..", "models", "shape_predictor_68_face_landmarks.dat")
            model_path = os.path.abspath(model_path)
            
            print(f"ğŸ“‚ ëª¨ë¸ íŒŒì¼ ì ˆëŒ€ ê²½ë¡œ: {model_path}")
            print(f"ğŸ“‚ ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(model_path)}")
            
            if os.path.exists(model_path):
                self.predictor = dlib.shape_predictor(model_path)
                print(f"âœ… dlib ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            else:
                print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ì–´ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤: {model_path}")
                self.predictor = None  # ëª¨ë¸ì´ ì—†ì–´ë„ ì„œë²„ëŠ” ë™ì‘
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.predictor = None
                    
            

    async def broadcast_status(self):
        """í˜„ì¬ ëª¨ë‹ˆí„°ë§ ìƒíƒœë¥¼ WebSocketìœ¼ë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        try:
            manager = get_manager()
            status_data = {
                # ì‹œì„  ì´íƒˆê³¼ ì¡¸ìŒ ìƒíƒœ ë¶„ë¦¬
                "distraction_state": self.get_distraction_status(),
                "drowsiness_state": self.get_drowsiness_status(),
            }
            await manager.broadcast(json.dumps(status_data))
        except Exception as e:
            print(f"ìƒíƒœ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        
    def put_text_korean(self, img, text, pos, color=(0, 0, 255)):
        """í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ í™”ë©´ì— ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜"""
        img_pil = Image.fromarray(img)
        draw = ImageDraw.Draw(img_pil)
        draw.text(pos, text, font=self.font, fill=color)
        return np.array(img_pil)
        
    def get_monitoring_status(self):
        # return self.monitoring_dao.get_status # í˜„ì¬ ìƒíƒœ ë°˜í™˜
        return self.status
    
    def toggle_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ìƒíƒœ ON/OFF ì „í™˜ ë° OpenCV ì‹¤í–‰/ì¢…ë£Œ"""
        # toggle ëˆ„ë¥´ë©´ ê¸°ì¡´ì— "on"/"off"ì—ì„œ True/Falseë¡œ ë³€ê²½
        # try / exceptë¡œ ì˜¤ë¥˜ íƒì§€ ë” ê°•í™”
        # threadingì„ ìœ ì—°í•˜ê²Œ ë³€ê²½
        try:
            if self.status == False:
                # ë¹„ë™ê¸°ì ìœ¼ë¡œ ì‹œì‘ => ì“°ë ˆë“œ ì„¤ì •
                threading.Thread(target=self.start_monitoring, daemon=True).start()
                self.status = True
                print("âœ… [Monitoring] ëª¨ë‹ˆí„°ë§ ì‹œì‘ ìš”ì²­!")
            else:
                # running í”Œë˜ê·¸ë§Œ ë³€ê²½í•˜ê³  ì¦‰ì‹œ ë°˜í™˜
                self.running = False
                self.status = False
                print("â›” [Monitoring] ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ ìš”ì²­!")
                
            return {"message": f"Monitoring status changed to {self.status}", "status": self.status}
        except Exception as e:
            print(f"âŒ í† ê¸€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"message": f"Error: {str(e)}", "status": self.status}

    def find_camera(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ë¥¼ ìë™ìœ¼ë¡œ ì°¾ëŠ” í•¨ìˆ˜"""
        for index in range(10):  # 0ë¶€í„° 9ê¹Œì§€ ì¹´ë©”ë¼ ì¸ë±ìŠ¤ í™•ì¸
            temp_cap = cv2.VideoCapture(index)
            if temp_cap.isOpened():
                temp_cap.release()  # í…ŒìŠ¤íŠ¸ í›„ ì¦‰ì‹œ í•´ì œ
                print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ ë°œê²¬: ì¸ë±ìŠ¤ {index}")
                return index
        
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return None

    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘ (OpenCV ì‹¤í–‰)"""
        if not self.running:
            self.running = True
            
            # ì´ì „ ì¹´ë©”ë¼ê°€ ìˆìœ¼ë©´ í•´ì œ
            if self.cap is not None:
                try:
                    self.cap.release()
                except:
                    pass
                self.cap = None
                time.sleep(0.5)  # ì ì‹œ ëŒ€ê¸°
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ ì°¾ê¸°
            camera_index = self.find_camera()
            
            if camera_index is not None:
                try:
                    self.cap = cv2.VideoCapture(camera_index)
                    
                    if not self.cap.isOpened():
                        print(f"âŒ ì¹´ë©”ë¼ {camera_index}ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                        self.running = False
                        self.status = False
                        return
                    
                    print(f"âœ… ì¹´ë©”ë¼ {camera_index} ì‹œì‘ë¨")
                except Exception as e:
                    print(f"âŒ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
                    self.running = False
                    self.status = False
                    return
            else:
                print("âŒ ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ëª¨ë‹ˆí„°ë§ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                self.running = False
                self.status = False
                return
            
            # ìŠ¤ë ˆë“œ ì‹œì‘ ë¶€ë¶„ì€ ê¸°ì¡´ê³¼ ë™ì¼
            if self.thread and self.thread.is_alive():
                try:
                    self.thread.join(timeout=0.5)
                except:
                    pass
                    
            self.thread = threading.Thread(target=self.run_monitoring, daemon=True)
            self.thread.start()


    # ì¤‘ì§€ì½”ë“œ ë³€ê²½ => ì¹´ë©”ë¼ ê°ì²´ê°€ ì‚´ì•„ì„œ ë‹¤ìŒ ì‹¤í–‰ ë  ë•Œ ì•ˆë˜ëŠ” ë²„ê·¸ ë°œìƒ
    # thread í•´ì œ ì•ˆì •í™” ì½”ë“œ ì¶”ê°€ (ë§¨ìœ„ ifë¬¸)
    def stop_monitoring(self):
        """ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ - ì¹´ë©”ë¼ ìì› ì™„ì „íˆ í•´ì œ """
        self.running = False
        
        # ìŠ¤ë ˆë“œê°€ ëë‚  ë•Œê¹Œì§€ ì•½ê°„ ëŒ€ê¸° (ë¸”ë¡œí‚¹ ë°©ì§€)
        if self.thread and self.thread.is_alive():
            try:
                self.thread.join(timeout=0.5)  # ìµœëŒ€ 0.5ì´ˆë§Œ ëŒ€ê¸°
            except:
                pass

        # ì¹´ë©”ë¼ ê°ì²´ ì •ë¦¬
        if self.cap:
            print("ğŸ“· ì¹´ë©”ë¼ ìì› í•´ì œ ì¤‘...")
            # ìœˆë„ìš° ë‹«ê¸°
            cv2.destroyAllWindows()
            # ë¹„ë””ì˜¤ ìº¡ì²˜ í•´ì œ ì‹œë„
            try:
                self.cap.release()
            except Exception as e:
                print(f"âš ï¸ ì¹´ë©”ë¼ í•´ì œ ì¤‘ ì˜¤ë¥˜: {e}")
            finally:
                self.cap = None

            # ì¶”ê°€ ì •ë¦¬ (êº¼ì§€ë©´ ì´ˆê¸°í™” ë˜ì•¼í•˜ëŠ” ê²ƒë“¤)
            self.LAST_GAZE_TIME = None
            self.NORMAL_GAZE_TIME = 0
            self.BASE_HEAD_X = 0.0
            self.BASE_HEAD_Y = 0.0
            self.frame_count = 0
            self.current_gray = None
            self.current_rects = []
            
                
        print("âœ… ëª¨ë‹ˆí„°ë§ì´ ì™„ì „íˆ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    def run_monitoring(self):
        # """OpenCVë¥¼ ì‚¬ìš©í•´ ì˜ìƒ ìº¡ì²˜"""
        # while self.running:
        #     ret, frame = self.cap.read()
        #     if not ret:
        #         break
        #     time.sleep(0.03)  # ë„ˆë¬´ ë¹ ë¥´ê²Œ ë£¨í”„ ëŒì§€ ì•Šë„ë¡ ì¶”ê°€
        # self.cap.release()
        # print("ğŸ“Œ [Monitoring] OpenCV í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
        #     def run_monitoring(self):
        """OpenCV ì‹¤í–‰ (Jupyter ê°ì§€ ë¡œì§ í˜¸ì¶œ)"""
        # self.cap = cv2.VideoCapture(0) # startì—ì„œ í˜¸ì¶œ ì¤‘ì´ë¼ ì¹´ë©”ë¼ê°€ ì¤‘ë³µí˜¸ì¶œë¡œ ì—ëŸ¬ ë°œìƒ
        
        self.show_cv_window = False

        while self.running:
            if self.cap is None:
                break

            ret, frame = self.cap.read()
            if not ret:
                print("âš ï¸ [Monitoring] ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!")
                break

            # âœ… Jupyterì—ì„œ ë§Œë“  ê°ì§€ í•¨ìˆ˜ ì‚¬ìš©
            # frame = self.detect_distraction(frame)  # detect_distraction í•¨ìˆ˜ í˜¸ì¶œ

            # OpenCV ì°½ í‘œì‹œ (ì˜µì…˜)
            # ëª¨ë‹ˆí„°ë§ ì‹¤í–‰ ëì„ ë•Œ ì°½ ëœ¨ëŠ”ê²ƒ ë°©ì§€
            if self.show_cv_window:
                cv2.imshow("Monitoring", frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):  # 'q'ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
                    break
            
            else:
                time.sleep(0)  # 30ì´ˆ ëŒ€ê¸°

        self.stop_monitoring()
        if self.show_cv_window:
            cv2.destroyAllWindows()



    # ë§¨ ìœ„ì— ì¹´ë©”ë¼ ì´ˆê¸°í™” ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì´ˆê¸°í™” ì½”ë“œ ì¶”ê°€
    def generate_frames(self):
        """ì›¹ìº  í”„ë ˆì„ì„ ì§€ì†ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ì œë„ˆë ˆì´í„°"""

        # ì¹´ë©”ë¼ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì—´ë ¤ìˆì§€ ì•Šìœ¼ë©´ ì´ˆê¸°í™”
        if self.cap is None or not self.cap.isOpened():
            try:
                # ê¸°ì¡´ ì¹´ë©”ë¼ ê°ì²´ ì •ë¦¬
                if self.cap is not None:
                    self.cap.release()
                    self.cap = None
                    time.sleep(0.5)  # ì ì‹œ ëŒ€ê¸°
                    
                # ìƒˆ ì¹´ë©”ë¼ ê°ì²´ ìƒì„±
                self.cap = cv2.VideoCapture(0)
                if not self.cap.isOpened():
                    yield self._error_frame("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    return
            except Exception as e:
                yield self._error_frame(f"ì¹´ë©”ë¼ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
                return


        # whileë¬¸ì„ videoíƒì§€ì™€ videoì˜¤í”ˆ ë° ëª¨ë‹ˆí„°ë§ ëŸ¬ë‹ê¹Œì§€ ë‹¤ ë ê²½ìš° ì‹¤í–‰
        while self.running and self.cap and self.cap.isOpened():
            # try / exceptë¡œ ì˜ˆì™¸ì²˜ë¦¬ ì¶”ê°€
            try:
                success, frame = self.cap.read()
                if not success:
                    yield self._error_frame("í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    continue
                    
                # ì£¼ì˜ ë¶„ì‚° ê°ì§€ ë¡œì§ ì ìš©
                detected_frame = self.detect_distraction(frame)
                    
                # ì¡¸ìŒ ê°ì§€
                detected_frame = self.detect_drowsiness(detected_frame)

                if detected_frame is None:
                    detected_frame = frame

                # í”„ë ˆì„ì„ JPGë¡œ ë³€í™˜
                _, buffer = cv2.imencode(".jpg", detected_frame)
                frame_bytes = buffer.tobytes()
                
                yield (b"--frame\r\n"
                    b"Content-Type: image/jpeg\r\n\r\n" + frame_bytes + b"\r\n")
                    
                    
            except Exception as e:
                print(f"âŒ [Streaming] í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                yield self._error_frame(f"ì˜¤ë¥˜: {str(e)}")

    # ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œìš© í—¬í¼ í•¨ìˆ˜ ì¶”ê°€
    def _error_frame(self, error_message):
        """ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ í¬í•¨ëœ í”„ë ˆì„ ìƒì„±"""
        frame = np.zeros((480, 640, 3), dtype=np.uint8)  # ê²€ì€ í”„ë ˆì„ ìƒì„±
        print("ì—ëŸ¬ ë©”ì„¸ì§€:", error_message)
        cv2.putText(frame, error_message, (50, 240), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        _, buffer = cv2.imencode(".jpg", frame)
        frame_bytes = buffer.tobytes()
        return (b"--frame\r\n"
                b"Content-Type: image/jpeg\r\n\r\n" + frame_bytes + b"\r\n")
        
    def eye_aspect_ratio(self, eye):
        """ëˆˆì˜ EAR(ëˆˆ ê°ê¹€ ë¹„ìœ¨) ê³„ì‚°"""
        A = dist.euclidean(eye[1], eye[5])
        B = dist.euclidean(eye[2], eye[4])
        C = dist.euclidean(eye[0], eye[3])
        return (A + B) / (2.0 * C)

    def mouth_aspect_ratio(self, mouth):
        """ì…ì˜ MAR(ì… ë²Œë¦¼ ë¹„ìœ¨) ê³„ì‚°"""
        A = dist.euclidean(mouth[2], mouth[10])
        B = dist.euclidean(mouth[4], mouth[8])
        C = dist.euclidean(mouth[0], mouth[6])
        return (A + B) / (2.0 * C)

    def detect_drowsiness(self, frame):
            """
            ì¡¸ìŒ ê°ì§€ ë©”ì„œë“œ - ëˆˆ ê°ê¹€ê³¼ í•˜í’ˆì„ ê¸°ë°˜ìœ¼ë¡œ ì¡¸ìŒ ìƒíƒœë¥¼ ê°ì§€
            """
            # ì „ì²´ í•¨ìˆ˜ë¥¼ try-exceptë¡œ ê°ì‹¸ì„œ ì–´ë–¤ ì˜ˆì™¸ê°€ ë°œìƒí•´ë„ í”„ë ˆì„ ë°˜í™˜
            try:
                
                # ìƒíƒœ ë³€ìˆ˜ê°€ ì—†ëŠ” ê²½ìš° ì´ˆê¸°í™”
                if not hasattr(self, 'DROWSY_WARNING_ACTIVE'):
                    self.DROWSY_WARNING_ACTIVE = False
                if not hasattr(self, 'SLEEPY_WARNING_ACTIVE'):
                    self.SLEEPY_WARNING_ACTIVE = False
                
                # í˜„ì¬ ì‹œê°„ ê¸°ë¡ (ì—¬ëŸ¬ íƒ€ì´ë¨¸ì— ì‚¬ìš©)
                current_time = time.time()
                
                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜ (ì–¼êµ´ íƒì§€ì— í•„ìš”)
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                # ì–¼êµ´ íƒì§€ ì‹¤í–‰
                rects, _, _ = self.detector.run(gray, 0, 0)
                
                # ì–¼êµ´ ì²˜ë¦¬ ë¡œì§
                if len(rects) > 0:  # ì–¼êµ´ì´ ê°ì§€ëœ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
                    for rect in rects:
                        try:
                            # ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ
                            shape = self.predictor(gray, rect)
                            shape = face_utils.shape_to_np(shape)

                            # âœ… ì–¼êµ´ ë°”ìš´ë”© ë°•ìŠ¤ ë° ëœë“œë§ˆí¬ í‘œì‹œ
                            (x, y, w, h) = face_utils.rect_to_bb(rect)  
                            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                            for (px, py) in shape:
                                cv2.circle(frame, (px, py), 1, (0, 255, 255), -1)
                                    
                            # ëˆˆ ë° ì… ì˜ì—­ ì„¤ì •
                            leftEye = shape[42:48]  # ì˜¤ë¥¸ìª½ ëˆˆ
                            rightEye = shape[36:42]  # ì™¼ìª½ ëˆˆ
                            mouth = shape[48:68]  # ì… ì˜ì—­

                            # EAR(ëˆˆ ê°ê¹€ ë¹„ìœ¨) & MAR(ì… ë²Œë¦¼ ë¹„ìœ¨) ê³„ì‚°
                            leftEAR = self.eye_aspect_ratio(leftEye)
                            rightEAR = self.eye_aspect_ratio(rightEye)
                            ear = (leftEAR + rightEAR) / 2.0
                            mar = self.mouth_aspect_ratio(mouth)

                            # 1ë¶„ë§ˆë‹¤ ëˆˆ ê¹œë¹¡ì„ê³¼ í•˜í’ˆ ì¹´ìš´íŠ¸ ì´ˆê¸°í™”
                            if current_time - self.RESET_TIME >= 60:
                                self.BLINK_COUNTER = 0
                                self.YAWN_COUNTER = 0
                                self.RESET_TIME = current_time
                                print("âœ… 1ë¶„ ê²½ê³¼: ëˆˆ ê¹œë¹¡ì„/í•˜í’ˆ ì¹´ìš´íŠ¸ ì´ˆê¸°í™”")

                            # ===== ëˆˆ ê°ê¹€ ìƒíƒœ ì²˜ë¦¬ =====
                            if ear < self.EYE_AR_THRESH:
                                # ëˆˆ ê°ì€ ì‹œê°„ ëˆ„ì 
                                self.EYE_CLOSED_TIME += 1/30  # 30FPS ê°€ì •
                                
                                # 1ë‹¨ê³„: ì¡¸ìŒ ì£¼ì˜ (ì°¸ì¡° ì½”ë“œì™€ ë™ì¼í•œ ì¡°ê±´ ì‚¬ìš©)
                                if (self.BLINK_COUNTER <= 12 or self.BLINK_COUNTER >= 22 or self.YAWN_COUNTER >= 2) \
                                and self.EYE_CLOSED_TIME >= 1 \
                                and not self.SLEEPY_WARNING_ACTIVE:  # ê²½ê³  ìƒíƒœê°€ ì•„ë‹ ë•Œë§Œ
                                    if not self.DROWSY_WARNING_ACTIVE:
                                        self.DROWSY_WARNING_ACTIVE = True
                                        self.LAST_DROWSY_TIME = current_time
                                        print("âš ï¸ ì¡¸ìŒ ì£¼ì˜!")
                                
                                # 2ë‹¨ê³„: ì¡¸ìŒ ê²½ê³  (ì°¸ì¡° ì½”ë“œì™€ ë™ì¼í•œ ì¡°ê±´ ì‚¬ìš©)
                                if (self.BLINK_COUNTER <= 10 or self.BLINK_COUNTER >= 24 or self.YAWN_COUNTER >= 3) \
                                and self.EYE_CLOSED_TIME >= 2:
                                    if not self.SLEEPY_WARNING_ACTIVE:
                                        self.SLEEPY_WARNING_ACTIVE = True
                                        self.LAST_WARNING_TIME = current_time
                                        # pygame.mixer.music.play()
                                        print("ğŸš¨ ì¡¸ìŒ ê²½ê³ ! ìš´ì „ ì¤‘ì§€!")
                            
                            else:
                                # ëˆˆì„ ëœ¬ ìƒíƒœì—ì„œ ìƒíƒœ ìœ ì§€ ì‹œê°„ í™•ì¸ (ì°¸ì¡° ì½”ë“œì™€ ìœ ì‚¬í•˜ê²Œ êµ¬í˜„)
                                
                                # ì¡¸ìŒ ì£¼ì˜ ìœ ì§€ (3ì´ˆ)
                                if self.DROWSY_WARNING_ACTIVE:
                                    elapsed_drowsy = current_time - self.LAST_DROWSY_TIME
                                    if elapsed_drowsy >= self.DROWSY_DISPLAY_TIME:
                                        self.DROWSY_WARNING_ACTIVE = False
                                        self.LAST_DROWSY_TIME = None
                                
                                # ì¡¸ìŒ ê²½ê³  ìœ ì§€ (60ì´ˆ)
                                if self.SLEEPY_WARNING_ACTIVE:
                                    elapsed_warning = current_time - self.LAST_WARNING_TIME
                                    if elapsed_warning >= self.WARNING_DISPLAY_TIME:
                                        self.SLEEPY_WARNING_ACTIVE = False
                                        self.LAST_WARNING_TIME = None
                                        self.EYE_CLOSED_TIME = 0
                                
                                # ê²½ê³  ìƒíƒœê°€ ì•„ë‹ ë•Œë§Œ EYE_CLOSED_TIME ì´ˆê¸°í™”
                                if not self.SLEEPY_WARNING_ACTIVE:
                                    self.EYE_CLOSED_TIME = 0
                            
                            # ===== í•˜í’ˆ ê°ì§€ =====
                            if mar > self.MOUTH_AR_THRESH:
                                self.MOUTH_COUNTER += 1
                                if self.MOUTH_COUNTER >= 30 and (current_time - self.LAST_YAWN_TIME > 1):
                                    self.YAWN_COUNTER += 1
                                    # í•˜í’ˆ ê°ì§€ ì‹œ ì•Œë¦¼ (í•˜ì§€ë§Œ í™”ë©´ ì¶œë ¥ì€ ë£¨í”„ ë°–ì—ì„œ ì²˜ë¦¬)
                                    print(f"ğŸ˜´ í•˜í’ˆ ê°ì§€ë¨! (ì´ {self.YAWN_COUNTER}íšŒ)")
                                    self.LAST_YAWN_TIME = current_time
                                    self.MOUTH_COUNTER = 0
                            else:
                                self.MOUTH_COUNTER = 0

                            # ===== ëˆˆ ê¹œë¹¡ì„ ê°ì§€ =====
                            if ear < self.EYE_AR_THRESH:
                                self.EYE_COUNTER += 1
                            else:
                                if self.EYE_COUNTER > 0:
                                    self.BLINK_COUNTER += 1
                                self.EYE_COUNTER = 0

                        except Exception as e:
                            print(f"âŒ ëˆˆ/ì… ì¸¡ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                            continue
            
                # ===== í…ìŠ¤íŠ¸ í‘œì‹œ ë¶€ë¶„ (for ë£¨í”„ ë°”ê¹¥) =====
                # ì¤‘ìš”: ì–¼êµ´ ì¸ì‹ ì—¬ë¶€ì™€ ìƒê´€ì—†ì´ ìƒíƒœ ë³€ìˆ˜ì— ë”°ë¼ í…ìŠ¤íŠ¸ í‘œì‹œ
                # ì´ë ‡ê²Œ í•˜ë©´ ì–¼êµ´ ì¸ì‹ì´ ë¶ˆì•ˆì •í•´ë„ í…ìŠ¤íŠ¸ê°€ ê¹œë¹¡ì´ì§€ ì•ŠìŒ

                if len(rects) > 0 :
                    # ì¡¸ìŒ ê²½ê³  í…ìŠ¤íŠ¸ (ìƒíƒœì— ë”°ë¼ í‘œì‹œ)
                    if self.SLEEPY_WARNING_ACTIVE:
                        frame = self.put_text_korean(frame, "ğŸš¨ ì¡¸ìŒ ê²½ê³ ! ìš´ì „ ì¤‘ì§€!", (10, 220), (0, 0, 255))
                    elif self.DROWSY_WARNING_ACTIVE:
                        frame = self.put_text_korean(frame, "âš ï¸ ì¡¸ìŒ ì£¼ì˜!", (10, 200), (0, 255, 255))
                        
                    # í•˜í’ˆ í‘œì‹œëŠ” ì‹œê°„ ê¸°ë°˜ìœ¼ë¡œ í‘œì‹œ (ìµœê·¼ 3ì´ˆê°„ë§Œ í‘œì‹œ)
                    if current_time - self.LAST_YAWN_TIME < 3:
                        frame = self.put_text_korean(frame, f"í•˜í’ˆ ê°ì§€ë¨! (ì´ {self.YAWN_COUNTER}íšŒ)", (10, 260), (0, 0, 255))
                        
                    # í•­ìƒ í‘œì‹œí•  ì •ë³´ (ê¹œë¹¡ì„ ì—†ì´ í‘œì‹œ)
                    display_text = f"ëˆˆ ê¹œë¹¡ì„: {self.BLINK_COUNTER}íšŒ | í•˜í’ˆ: {self.YAWN_COUNTER}íšŒ"
                    frame = self.put_text_korean(frame, display_text, (10, 160), (255, 120, 0))
                        
                # í•­ìƒ í”„ë ˆì„ ë°˜í™˜
                return frame

            except Exception as e:
                print(f"âŒ ì¡¸ìŒ ê°ì§€ ë©”ì„œë“œ ì „ì²´ ì˜¤ë¥˜: {e}")
                return frame  # ì–´ë–¤ ê²½ìš°ì—ë„ ì›ë³¸ í”„ë ˆì„ ë°˜í™˜
            
    # try / except ë„£ì–´ì„œ ë²„ê·¸ë“± ì˜ˆì™¸ìƒí™© íƒì§€í•˜ê²Œ ìˆ˜ì •ì •        
    def detect_distraction(self, frame):
        """ì£¼ì˜ ë¶„ì‚° ê°ì§€"""
        try:
            self.frame_count += 1

            # ì‹¤ì‹œê°„ íƒì§€ê°€ ì•ˆë˜ì„œ 15í”„ë ˆì„ë‹¹ íƒì§€ë˜ê²Œë” ì„¤ì • => ì¡°ê¸ˆ ë²„ë²…ì„
            if self.frame_count % 15 == 0:
                self.current_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                # run(img, ì—…ìƒ˜í”Œë§ => ì–¼êµ´ ì—¬ëŸ¬ê°œ íƒì§€ 1ë¡œ ê°ˆìˆ˜ë¡ ë”ë§ì´ íƒì§€, ë¯¼ê°ë„ -1ë¡œ ê°ˆìˆ˜ë¡ ìœ ì—° 1ë¡œ ê°ˆìˆ˜ë¡ íƒì§€ê°€ ì˜ ì•ˆë¨)
                rects, _, _  = self.detector.run(self.current_gray, 0, 0) # ì„ê³„ê°’(0) ìˆ˜ì • => ë¹„ì •ìƒ íƒì§€ ë„ˆë¬´ ë§ìŒ
                self.current_rects = rects
            

            if len(self.current_rects) == 0:
                self.IS_NORMAL_GAZE = False
                self.NORMAL_GAZE_TIME = time.time()  # ì •ìƒ ì‹œì„  íƒ€ì´ë¨¸ ë¦¬ì…‹
                frame = self.put_text_korean(frame, "âš ï¸ ì–¼êµ´ ê°ì§€ ì•ˆë¨", (10, 110), (0, 0, 255))

            # ì´ê³³ë„ try exceptë¬¸ ì¶”ê°€í•´ì„œ ë²„ê·¸ íƒì§€ ë° ì„œë²„ ë¦¬ì…‹ ë§‰ê¸° 
            for (i, rect) in enumerate(self.current_rects):
                try:
                    (x, y, w, h) = face_utils.rect_to_bb(rect)  

                    shape = self.predictor(self.current_gray, rect)
                    shape = face_utils.shape_to_np(shape)

                    # âœ… ë¨¸ë¦¬ ê¸°ìš¸ê¸° ê³„ì‚° (ì •ê·œí™”ëœ ê°’)
                    head_x = (np.mean(shape[36:42][:, 0]) - np.mean(shape[42:48][:, 0])) / w  
                    head_y = (np.mean(shape[19:27][:, 1]) - np.mean(shape[0:17][:, 1])) / h  

                    # âœ… ê¸°ì¤€ê°’ ì„¤ì • (í•œ ë²ˆë§Œ ì €ì¥)
                    if self.BASE_HEAD_X == 0.0 or self.BASE_HEAD_Y == 0.0:
                        self.BASE_HEAD_X = head_x
                        self.BASE_HEAD_Y = head_y

                    # âœ… ì‹œì„  ì´íƒˆ ê°ì§€
                    delta_x = abs(head_x - self.BASE_HEAD_X)
                    delta_y = abs(head_y - self.BASE_HEAD_Y)
                    
                    # ğŸš€ **(ìˆ˜ì •) ì‹œì„  ì´íƒˆì´ 2ì´ˆ ì§€ì†ë˜ì—ˆì„ ë•Œë§Œ ì¹´ìš´íŠ¸ ì¦ê°€**
                    if delta_x > self.HEAD_ANGLE_THRESH_X or delta_y > self.HEAD_ANGLE_THRESH_Y:
                        if self.LAST_GAZE_TIME is None:  # ì‹œì„  ì´íƒˆ ì‹œì‘ ì‹œê°„ ê¸°ë¡
                            self.LAST_GAZE_TIME = time.time()

                        elapsed_time = time.time() - self.LAST_GAZE_TIME

                        if elapsed_time >= self.GAZE_TIME_THRESH:  # ğŸš¨ **ì´íƒˆì´ 2ì´ˆ ì§€ì†ë˜ì—ˆì„ ë•Œë§Œ ì¦ê°€**
                            self.GAZE_COUNT += 1  # ğŸš¨ ì‹œì„  ì´íƒˆ íšŸìˆ˜ ì¦ê°€
                            self.LAST_GAZE_TIME = None  # ì´ˆê¸°í™”í•˜ì—¬ ì¤‘ë³µ ê°ì§€ ë°©ì§€
                            self.NORMAL_GAZE_TIME = time.time()  # âœ… **ì´íƒˆ í›„ ì •ìƒ ì‹œì„  ìœ ì§€ ì‹œê°„ ì´ˆê¸°í™”**
                    else:
                        self.LAST_GAZE_TIME = None  # ê¸°ì¤€ ì´í•˜ë¡œ ëŒì•„ì˜¤ë©´ ë¦¬ì…‹

                    # âœ… ì •ìƒ ì‹œì„  ìœ ì§€ ì‹œê°„ í‘œì‹œ
                    normal_time = int(time.time() - self.NORMAL_GAZE_TIME)
                    normal_text = f"ì •ìƒ ì‹œì„  ìœ ì§€: {normal_time}ì´ˆ/{self.RESET_TIME_THRESH}ì´ˆ"
                    frame = self.put_text_korean(frame, normal_text, (10, 70), (0, 255, 0))

                    # âœ… ì£¼ì˜ ë‹¨ê³„ & ê²½ê³  ë‹¨ê³„ í‘œì‹œ
                    if self.GAZE_COUNT >= 5:
                        frame = self.put_text_korean(frame, "ğŸš¨ ìš´ì „ ì§‘ì¤‘ ê²½ê³ !", (10, 120), (0, 0, 255))
                        # pygame.mixer.music.play()
                    elif self.GAZE_COUNT >= 2:
                        frame = self.put_text_korean(frame, "âš ï¸ ì „ë°© ì£¼ì‹œ ì£¼ì˜!", (10, 120), (0, 255, 255))
                        # pygame.mixer.music.play()

                    # âœ… ì‹œì„  ì´íƒˆ íšŸìˆ˜ í™”ë©´ í‘œì‹œ (í°ìƒ‰)
                    gaze_text = f"ì‹œì„  ì´íƒˆ íšŸìˆ˜: {self.GAZE_COUNT}íšŒ"
                    frame = self.put_text_korean(frame, gaze_text, (10, 30), (255, 120, 0))

                except Exception as e:
                    print(f"âš ï¸ ì–¼êµ´ ëœë“œë§ˆí¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue  # ì´ ì–¼êµ´ ê±´ë„ˆë›°ê³  ë‹¤ìŒ ì–¼êµ´ ì²˜ë¦¬

            # ğŸš€ **(ì¶”ê°€) ì „ë°© ì£¼ì‹œ 1ë¶„ê°„ ìœ ì§€ ì‹œ ì´ˆê¸°í™”**
            if (time.time() - self.NORMAL_GAZE_TIME) >= self.RESET_TIME_THRESH:
                print("ğŸ•’ 1ë¶„ê°„ ì •ìƒ ì‹œì„  ìœ ì§€: ì‹œì„  ì´íƒˆ íšŸìˆ˜ ì´ˆê¸°í™”")
                self.GAZE_COUNT = 0
                self.NORMAL_GAZE_TIME = time.time()  # íƒ€ì´ë¨¸ ë¦¬ì…‹

            return frame

        except Exception as e:
            print(f"âŒ ì£¼ì˜ ë¶„ì‚° ê°ì§€ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ í”„ë ˆì„ì— ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ í›„ ë°˜í™˜
            try:
                height, width = frame.shape[:2]
                cv2.putText(frame, f"Error: {str(e)}", (10, height//2), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            except:
                # í”„ë ˆì„ ì²˜ë¦¬ë„ ì•ˆ ë˜ëŠ” ê²½ìš° ë¹ˆ í”„ë ˆì„ ìƒì„±
                frame = np.zeros((480, 640, 3), dtype=np.uint8)
                
            return frame
        
    # ì‹œì„  ì´íƒˆ ìƒíƒœë§Œ í™•ì¸
    def get_distraction_status(self):
        if self.GAZE_COUNT >= 5:
            return "danger"
        elif self.GAZE_COUNT >= 2:
            return "warn"
        else:
            return "normal"

    # ì¡¸ìŒ ìƒíƒœë§Œ í™•ì¸
    def get_drowsiness_status(self):
        if self.DROWSY_WARNING_ACTIVE:
            return "danger"
        elif self.SLEEPY_WARNING_ACTIVE:
            return "warn"
        else:
            return "normal"
# def detect_distraction(self, frame):
#     print("ğŸ§ [DEBUG] ì£¼ì˜ ë¶„ì‚° ê°ì§€ í•¨ìˆ˜ ì‹¤í–‰ë¨")  # âœ… ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
#     ...




