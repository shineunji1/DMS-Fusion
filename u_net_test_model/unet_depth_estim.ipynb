{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02b3b3f-23ba-46da-abc4-92d0ccdd7c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 11:37:07.275546: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-14 11:37:10.055776: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69bd90fc-b5c1-4c0f-bebc-5b449a69bed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU 메모리 성장 설정 완료!\n",
      "\n",
      "================================================================================\n",
      "🚀 개선된 깊이 보정 파이프라인 시작\n",
      "================================================================================\n",
      "📁 visualizations 디렉토리 확인 완료\n",
      "📁 checkpoints 디렉토리 확인 완료\n",
      "📁 logs 디렉토리 확인 완료\n",
      "📁 test_results 디렉토리 확인 완료\n",
      "📊 발견된 RGB 이미지: 1008개\n",
      "📊 사용할 샘플 수: 1000개\n",
      "🔧 정밀도 설정: float32 (안정성 향상)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "📚 점진적 해상도 학습 시작\n",
      "--------------------------------------------------------------------------------\n",
      "학습 샘플: 600, 검증 샘플: 200, 테스트 샘플: 200\n",
      "\n",
      "==================== 학습 단계 1/5: 해상도 (32, 32) ====================\n",
      "현재 학습률: 1.00e-05\n",
      "데이터셋 생성 중... 대상 해상도: (32, 32)\n",
      "데이터셋 생성 중... 대상 해상도: (32, 32), Stage: 0\n",
      "로드된 샘플 수: 600\n",
      "데이터 전처리 시작\n",
      "최종 입력 데이터 형태: (600, 32, 32, 5)\n",
      "입력 데이터 범위:\n",
      "  RGB: 0.0 ~ 1.0\n",
      "  깊이: 0.0 ~ 1.0\n",
      "  MDE: 0.0 ~ 1.0\n",
      "최종 타겟 데이터 형태: (600, 32, 32, 1)\n",
      "타겟 깊이 범위: 0.0 ~ 1.0\n",
      "데이터셋 생성 중... 대상 해상도: (32, 32), Stage: 0\n",
      "로드된 샘플 수: 200\n",
      "데이터 전처리 시작\n",
      "최종 입력 데이터 형태: (200, 32, 32, 5)\n",
      "입력 데이터 범위:\n",
      "  RGB: 0.0 ~ 1.0\n",
      "  깊이: 0.0 ~ 1.0\n",
      "  MDE: 0.0 ~ 1.0\n",
      "최종 타겟 데이터 형태: (200, 32, 32, 1)\n",
      "타겟 깊이 범위: 0.0 ~ 1.0\n",
      "학습 데이터 배치 형태: 입력=(16, 32, 32, 5), 타겟=(16, 32, 32, 1)\n",
      "데이터셋 NaN/Inf 검사 중...\n",
      "학습 데이터셋에 NaN/Inf 값이 감지되지 않았습니다.\n",
      "검증 데이터셋에 NaN/Inf 값이 감지되지 않았습니다.\n",
      "모델 입력 차원: (32, 32, 5)\n",
      "새 모델 생성 완료\n",
      "Model: \"model_75\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_76 (InputLayer)       [(None, 32, 32, 5)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_2353 (Conv2D)        (None, 32, 32, 32)           1472      ['input_76[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1112 (  (None, 32, 32, 32)           128       ['conv2d_2353[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1377 (Activatio  (None, 32, 32, 32)           0         ['batch_normalization_1112[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2d_2354 (Conv2D)        (None, 32, 32, 32)           9248      ['activation_1377[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1113 (  (None, 32, 32, 32)           128       ['conv2d_2354[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1378 (Activatio  (None, 32, 32, 32)           0         ['batch_normalization_1113[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " max_pooling2d_521 (MaxPool  (None, 16, 16, 32)           0         ['activation_1378[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2355 (Conv2D)        (None, 16, 16, 64)           18496     ['max_pooling2d_521[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_1114 (  (None, 16, 16, 64)           256       ['conv2d_2355[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1379 (Activatio  (None, 16, 16, 64)           0         ['batch_normalization_1114[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2d_2356 (Conv2D)        (None, 16, 16, 64)           36928     ['activation_1379[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1115 (  (None, 16, 16, 64)           256       ['conv2d_2356[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1380 (Activatio  (None, 16, 16, 64)           0         ['batch_normalization_1115[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " max_pooling2d_522 (MaxPool  (None, 8, 8, 64)             0         ['activation_1380[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2357 (Conv2D)        (None, 8, 8, 128)            73856     ['max_pooling2d_522[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_1116 (  (None, 8, 8, 128)            512       ['conv2d_2357[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1381 (Activatio  (None, 8, 8, 128)            0         ['batch_normalization_1116[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2d_2358 (Conv2D)        (None, 8, 8, 128)            147584    ['activation_1381[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1117 (  (None, 8, 8, 128)            512       ['conv2d_2358[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1382 (Activatio  (None, 8, 8, 128)            0         ['batch_normalization_1117[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " up_sampling2d_150 (UpSampl  (None, 16, 16, 128)          0         ['activation_1382[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2359 (Conv2D)        (None, 16, 16, 64)           32832     ['up_sampling2d_150[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_1118 (  (None, 16, 16, 64)           256       ['conv2d_2359[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1383 (Activatio  (None, 16, 16, 64)           0         ['batch_normalization_1118[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " concatenate_892 (Concatena  (None, 16, 16, 128)          0         ['activation_1380[0][0]',     \n",
      " te)                                                                 'activation_1383[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2360 (Conv2D)        (None, 16, 16, 64)           73792     ['concatenate_892[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1119 (  (None, 16, 16, 64)           256       ['conv2d_2360[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1384 (Activatio  (None, 16, 16, 64)           0         ['batch_normalization_1119[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2d_2361 (Conv2D)        (None, 16, 16, 64)           36928     ['activation_1384[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1120 (  (None, 16, 16, 64)           256       ['conv2d_2361[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1385 (Activatio  (None, 16, 16, 64)           0         ['batch_normalization_1120[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " up_sampling2d_151 (UpSampl  (None, 32, 32, 64)           0         ['activation_1385[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2362 (Conv2D)        (None, 32, 32, 32)           8224      ['up_sampling2d_151[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_1121 (  (None, 32, 32, 32)           128       ['conv2d_2362[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1386 (Activatio  (None, 32, 32, 32)           0         ['batch_normalization_1121[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " concatenate_893 (Concatena  (None, 32, 32, 64)           0         ['activation_1378[0][0]',     \n",
      " te)                                                                 'activation_1386[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2363 (Conv2D)        (None, 32, 32, 32)           18464     ['concatenate_893[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1122 (  (None, 32, 32, 32)           128       ['conv2d_2363[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1387 (Activatio  (None, 32, 32, 32)           0         ['batch_normalization_1122[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2d_2364 (Conv2D)        (None, 32, 32, 32)           9248      ['activation_1387[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1123 (  (None, 32, 32, 32)           128       ['conv2d_2364[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1388 (Activatio  (None, 32, 32, 32)           0         ['batch_normalization_1123[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2d_2365 (Conv2D)        (None, 32, 32, 1)            33        ['activation_1388[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2142 (Lambda)        (None, 32, 32, 1)            0         ['conv2d_2365[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 470049 (1.79 MB)\n",
      "Trainable params: 468577 (1.79 MB)\n",
      "Non-trainable params: 1472 (5.75 KB)\n",
      "__________________________________________________________________________________________________\n",
      "학습 시작: 단계 1, 해상도 (32, 32), 에폭 15\n",
      "Epoch 1/15\n",
      " 6/38 [===>..........................] - ETA: 0s - loss: 0.4810 - mae: 0.3221  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0087s vs `on_train_batch_end` time: 0.0157s). Check your callbacks.\n",
      "1/1 [==============================] - 0s 201ms/steposs: 0.4516 - mae: 0.30\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "38/38 [==============================] - 9s 53ms/step - loss: 0.4516 - mae: 0.3018 - val_loss: 0.4580 - val_mae: 0.3214 - lr: 1.0000e-05\n",
      "Epoch 2/15\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.4011 - mae: 0.2721 - val_loss: 0.3904 - val_mae: 0.2714 - lr: 1.0000e-05\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 0s 21ms/steploss: 0.3741 - mae: 0.25\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.3738 - mae: 0.2557 - val_loss: 0.3686 - val_mae: 0.2576 - lr: 1.0000e-05\n",
      "Epoch 4/15\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.3544 - mae: 0.2432 - val_loss: 0.3513 - val_mae: 0.2461 - lr: 1.0000e-05\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 0s 21ms/steploss: 0.3396 - mae: 0.23\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.3391 - mae: 0.2327 - val_loss: 0.3369 - val_mae: 0.2363 - lr: 1.0000e-05\n",
      "Epoch 6/15\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.3259 - mae: 0.2235 - val_loss: 0.3244 - val_mae: 0.2275 - lr: 1.0000e-05\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 0s 20ms/steploss: 0.3144 - mae: 0.21\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.3139 - mae: 0.2151 - val_loss: 0.3131 - val_mae: 0.2196 - lr: 1.0000e-05\n",
      "Epoch 8/15\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.3021 - mae: 0.2067 - val_loss: 0.3011 - val_mae: 0.2111 - lr: 1.0000e-05\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 0s 20ms/steploss: 0.2901 - mae: 0.19\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.2895 - mae: 0.1979 - val_loss: 0.2882 - val_mae: 0.2019 - lr: 1.0000e-05\n",
      "Epoch 10/15\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.2754 - mae: 0.1881 - val_loss: 0.2733 - val_mae: 0.1913 - lr: 1.0000e-05\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 0s 21ms/steploss: 0.2606 - mae: 0.17\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 0.2600 - mae: 0.1776 - val_loss: 0.2578 - val_mae: 0.1805 - lr: 1.0000e-05\n",
      "Epoch 12/15\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.2440 - mae: 0.1668 - val_loss: 0.2416 - val_mae: 0.1692 - lr: 1.0000e-05\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 0s 20ms/steploss: 0.2295 - mae: 0.15\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.2289 - mae: 0.1568 - val_loss: 0.2261 - val_mae: 0.1586 - lr: 1.0000e-05\n",
      "Epoch 14/15\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.2154 - mae: 0.1481 - val_loss: 0.2121 - val_mae: 0.1492 - lr: 1.0000e-05\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 0s 21ms/steploss: 0.2037 - mae: 0.14\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "38/38 [==============================] - 1s 40ms/step - loss: 0.2034 - mae: 0.1404 - val_loss: 0.1997 - val_mae: 0.1409 - lr: 1.0000e-05\n",
      "단계 1 최종 결과:\n",
      "  - 훈련 손실: 0.2034\n",
      "  - 검증 손실: 0.1997\n",
      "  - 훈련 MAE: 0.1404\n",
      "  - 검증 MAE: 0.1409\n",
      "단계 1 모델 저장 완료: checkpoints/depth_model_stage1.h5\n",
      "\n",
      "==================== 학습 단계 2/5: 해상도 (48, 64) ====================\n",
      "현재 학습률: 1.00e-06\n",
      "데이터셋 생성 중... 대상 해상도: (48, 64)\n",
      "데이터셋 생성 중... 대상 해상도: (48, 64), Stage: 1\n",
      "로드된 샘플 수: 600\n",
      "데이터 전처리 시작\n",
      "최종 입력 데이터 형태: (600, 48, 64, 7)\n",
      "입력 데이터 범위:\n",
      "  RGB: 0.0 ~ 1.0\n",
      "  깊이: 0.0 ~ 1.0\n",
      "  MDE: 0.0 ~ 1.0\n",
      "  Sensor Confidence: 0.3 ~ 0.7\n",
      "  MDE Confidence: 0.7 ~ 0.7\n",
      "최종 타겟 데이터 형태: (600, 48, 64, 1)\n",
      "타겟 깊이 범위: 0.0 ~ 1.0\n",
      "데이터셋 생성 중... 대상 해상도: (48, 64), Stage: 1\n",
      "로드된 샘플 수: 200\n",
      "데이터 전처리 시작\n",
      "최종 입력 데이터 형태: (200, 48, 64, 7)\n",
      "입력 데이터 범위:\n",
      "  RGB: 0.0 ~ 1.0\n",
      "  깊이: 0.0 ~ 1.0\n",
      "  MDE: 0.0 ~ 1.0\n",
      "  Sensor Confidence: 0.3 ~ 0.7\n",
      "  MDE Confidence: 0.7 ~ 0.7\n",
      "최종 타겟 데이터 형태: (200, 48, 64, 1)\n",
      "타겟 깊이 범위: 0.0 ~ 1.0\n",
      "학습 데이터 배치 형태: 입력=(12, 48, 64, 7), 타겟=(12, 48, 64, 1)\n",
      "데이터셋 NaN/Inf 검사 중...\n",
      "학습 데이터셋에 NaN/Inf 값이 감지되지 않았습니다.\n",
      "검증 데이터셋에 NaN/Inf 값이 감지되지 않았습니다.\n",
      "모델 입력 차원: (48, 64, 7)\n",
      "개선된 가중치 전이 함수 실행 중...\n",
      "가중치 전이 성공! (일치하지 않는 레이어는 건너뜀)\n",
      "가중치 전이 성공\n",
      "Model: \"model_76\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_77 (InputLayer)       [(None, 48, 64, 7)]          0         []                            \n",
      "                                                                                                  \n",
      " lambda_2143 (Lambda)        (None, 48, 64, 3)            0         ['input_77[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_2370 (Conv2D)        (None, 48, 64, 32)           896       ['lambda_2143[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1126 (  (None, 48, 64, 32)           128       ['conv2d_2370[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1391 (Activatio  (None, 48, 64, 32)           0         ['batch_normalization_1126[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 32)                   0         ['activation_1391[0][0]']     \n",
      " 65 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_265 (  (None, 32)                   0         ['activation_1391[0][0]']     \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " lambda_2144 (Lambda)        (None, 48, 64, 1)            0         ['input_77[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_530 (Reshape)       (None, 1, 1, 32)             0         ['global_average_pooling2d_265\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_531 (Reshape)       (None, 1, 1, 32)             0         ['global_max_pooling2d_265[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " lambda_2146 (Lambda)        (None, 48, 64, 1)            0         ['input_77[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_2145 (Lambda)        (None, 48, 64, 1)            0         ['input_77[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_2147 (Lambda)        (None, 48, 64, 1)            0         ['input_77[0][0]']            \n",
      "                                                                                                  \n",
      " dense_530 (Dense)           (None, 1, 1, 4)              132       ['reshape_530[0][0]',         \n",
      "                                                                     'reshape_531[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_896 (Concatena  (None, 48, 64, 2)            0         ['lambda_2144[0][0]',         \n",
      " te)                                                                 'lambda_2146[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_899 (Concatena  (None, 48, 64, 2)            0         ['lambda_2145[0][0]',         \n",
      " te)                                                                 'lambda_2147[0][0]']         \n",
      "                                                                                                  \n",
      " dense_531 (Dense)           (None, 1, 1, 32)             160       ['dense_530[0][0]',           \n",
      "                                                                     'dense_530[1][0]']           \n",
      "                                                                                                  \n",
      " conv2d_2372 (Conv2D)        (None, 48, 64, 32)           608       ['concatenate_896[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2376 (Conv2D)        (None, 48, 64, 32)           608       ['concatenate_899[0][0]']     \n",
      "                                                                                                  \n",
      " add_584 (Add)               (None, 1, 1, 32)             0         ['dense_531[0][0]',           \n",
      "                                                                     'dense_531[1][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_1128 (  (None, 48, 64, 32)           128       ['conv2d_2372[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_1130 (  (None, 48, 64, 32)           128       ['conv2d_2376[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1392 (Activatio  (None, 1, 1, 32)             0         ['add_584[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " activation_1395 (Activatio  (None, 48, 64, 32)           0         ['batch_normalization_1128[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " activation_1397 (Activatio  (None, 48, 64, 32)           0         ['batch_normalization_1130[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " multiply_1060 (Multiply)    (None, 48, 64, 32)           0         ['activation_1391[0][0]',     \n",
      "                                                                     'activation_1392[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2151 (Lambda)        (None, 48, 64, 1)            0         ['activation_1395[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2152 (Lambda)        (None, 48, 64, 1)            0         ['activation_1395[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2155 (Lambda)        (None, 48, 64, 1)            0         ['activation_1397[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2156 (Lambda)        (None, 48, 64, 1)            0         ['activation_1397[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_523 (MaxPool  (None, 24, 32, 32)           0         ['multiply_1060[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_897 (Concatena  (None, 48, 64, 2)            0         ['lambda_2151[0][0]',         \n",
      " te)                                                                 'lambda_2152[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_900 (Concatena  (None, 48, 64, 2)            0         ['lambda_2155[0][0]',         \n",
      " te)                                                                 'lambda_2156[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2371 (Conv2D)        (None, 24, 32, 64)           18496     ['max_pooling2d_523[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_2373 (Conv2D)        (None, 48, 64, 1)            98        ['concatenate_897[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2377 (Conv2D)        (None, 48, 64, 1)            98        ['concatenate_900[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1127 (  (None, 24, 32, 64)           256       ['conv2d_2371[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multiply_1062 (Multiply)    (None, 48, 64, 32)           0         ['activation_1395[0][0]',     \n",
      "                                                                     'conv2d_2373[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1064 (Multiply)    (None, 48, 64, 32)           0         ['activation_1397[0][0]',     \n",
      "                                                                     'conv2d_2377[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1393 (Activatio  (None, 24, 32, 64)           0         ['batch_normalization_1127[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " max_pooling2d_525 (MaxPool  (None, 24, 32, 32)           0         ['multiply_1062[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_527 (MaxPool  (None, 24, 32, 32)           0         ['multiply_1064[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 64)                   0         ['activation_1393[0][0]']     \n",
      " 66 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_266 (  (None, 64)                   0         ['activation_1393[0][0]']     \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2374 (Conv2D)        (None, 24, 32, 64)           18496     ['max_pooling2d_525[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_2378 (Conv2D)        (None, 24, 32, 64)           18496     ['max_pooling2d_527[0][0]']   \n",
      "                                                                                                  \n",
      " reshape_532 (Reshape)       (None, 1, 1, 64)             0         ['global_average_pooling2d_266\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_533 (Reshape)       (None, 1, 1, 64)             0         ['global_max_pooling2d_266[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization_1129 (  (None, 24, 32, 64)           256       ['conv2d_2374[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_1131 (  (None, 24, 32, 64)           256       ['conv2d_2378[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_532 (Dense)           (None, 1, 1, 8)              520       ['reshape_532[0][0]',         \n",
      "                                                                     'reshape_533[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1396 (Activatio  (None, 24, 32, 64)           0         ['batch_normalization_1129[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " activation_1398 (Activatio  (None, 24, 32, 64)           0         ['batch_normalization_1131[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " subtract_53 (Subtract)      (None, 48, 64, 1)            0         ['lambda_2144[0][0]',         \n",
      "                                                                     'lambda_2145[0][0]']         \n",
      "                                                                                                  \n",
      " dense_533 (Dense)           (None, 1, 1, 64)             576       ['dense_532[0][0]',           \n",
      "                                                                     'dense_532[1][0]']           \n",
      "                                                                                                  \n",
      " lambda_2153 (Lambda)        (None, 24, 32, 1)            0         ['activation_1396[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2154 (Lambda)        (None, 24, 32, 1)            0         ['activation_1396[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2157 (Lambda)        (None, 24, 32, 1)            0         ['activation_1398[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2158 (Lambda)        (None, 24, 32, 1)            0         ['activation_1398[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2380 (Conv2D)        (None, 48, 64, 32)           320       ['subtract_53[0][0]']         \n",
      "                                                                                                  \n",
      " add_585 (Add)               (None, 1, 1, 64)             0         ['dense_533[0][0]',           \n",
      "                                                                     'dense_533[1][0]']           \n",
      "                                                                                                  \n",
      " concatenate_898 (Concatena  (None, 24, 32, 2)            0         ['lambda_2153[0][0]',         \n",
      " te)                                                                 'lambda_2154[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_901 (Concatena  (None, 24, 32, 2)            0         ['lambda_2157[0][0]',         \n",
      " te)                                                                 'lambda_2158[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1132 (  (None, 48, 64, 32)           128       ['conv2d_2380[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1394 (Activatio  (None, 1, 1, 64)             0         ['add_585[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2375 (Conv2D)        (None, 24, 32, 1)            98        ['concatenate_898[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2379 (Conv2D)        (None, 24, 32, 1)            98        ['concatenate_901[0][0]']     \n",
      "                                                                                                  \n",
      " activation_1399 (Activatio  (None, 48, 64, 32)           0         ['batch_normalization_1132[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " multiply_1061 (Multiply)    (None, 24, 32, 64)           0         ['activation_1393[0][0]',     \n",
      "                                                                     'activation_1394[0][0]']     \n",
      "                                                                                                  \n",
      " multiply_1063 (Multiply)    (None, 24, 32, 64)           0         ['activation_1396[0][0]',     \n",
      "                                                                     'conv2d_2375[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1065 (Multiply)    (None, 24, 32, 64)           0         ['activation_1398[0][0]',     \n",
      "                                                                     'conv2d_2379[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling2d_529 (MaxPool  (None, 24, 32, 32)           0         ['activation_1399[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2381 (Conv2D)        (None, 24, 32, 64)           18496     ['max_pooling2d_529[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_2390 (Conv2D)        (None, 24, 32, 64)           4160      ['multiply_1061[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2391 (Conv2D)        (None, 24, 32, 64)           4160      ['multiply_1063[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2392 (Conv2D)        (None, 24, 32, 64)           4160      ['multiply_1065[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1133 (  (None, 24, 32, 64)           256       ['conv2d_2381[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " concatenate_904 (Concatena  (None, 24, 32, 192)          0         ['conv2d_2390[0][0]',         \n",
      " te)                                                                 'conv2d_2391[0][0]',         \n",
      "                                                                     'conv2d_2392[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1400 (Activatio  (None, 24, 32, 64)           0         ['batch_normalization_1133[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2d_2393 (Conv2D)        (None, 24, 32, 64)           110656    ['concatenate_904[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_524 (MaxPool  (None, 12, 16, 64)           0         ['multiply_1061[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_526 (MaxPool  (None, 12, 16, 64)           0         ['multiply_1063[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_528 (MaxPool  (None, 12, 16, 64)           0         ['multiply_1065[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_530 (MaxPool  (None, 12, 16, 64)           0         ['activation_1400[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_1135 (  (None, 24, 32, 64)           256       ['conv2d_2393[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " concatenate_906 (Concatena  (None, 12, 16, 256)          0         ['max_pooling2d_524[0][0]',   \n",
      " te)                                                                 'max_pooling2d_526[0][0]',   \n",
      "                                                                     'max_pooling2d_528[0][0]',   \n",
      "                                                                     'max_pooling2d_530[0][0]']   \n",
      "                                                                                                  \n",
      " activation_1403 (Activatio  (None, 24, 32, 64)           0         ['batch_normalization_1135[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 256)                  0         ['concatenate_906[0][0]']     \n",
      " 69 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_269 (  (None, 256)                  0         ['concatenate_906[0][0]']     \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2394 (Conv2D)        (None, 24, 32, 3)            195       ['activation_1403[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2382 (Conv2D)        (None, 48, 64, 32)           1056      ['multiply_1060[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2383 (Conv2D)        (None, 48, 64, 32)           1056      ['multiply_1062[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2384 (Conv2D)        (None, 48, 64, 32)           1056      ['multiply_1064[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_538 (Reshape)       (None, 1, 1, 256)            0         ['global_average_pooling2d_269\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_539 (Reshape)       (None, 1, 1, 256)            0         ['global_max_pooling2d_269[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " lambda_2167 (Lambda)        (None, 24, 32, 1)            0         ['conv2d_2394[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2168 (Lambda)        (None, 24, 32, 1)            0         ['conv2d_2394[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2169 (Lambda)        (None, 24, 32, 1)            0         ['conv2d_2394[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_902 (Concatena  (None, 48, 64, 96)           0         ['conv2d_2382[0][0]',         \n",
      " te)                                                                 'conv2d_2383[0][0]',         \n",
      "                                                                     'conv2d_2384[0][0]']         \n",
      "                                                                                                  \n",
      " dense_538 (Dense)           (None, 1, 1, 32)             8224      ['reshape_538[0][0]',         \n",
      "                                                                     'reshape_539[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2170 (Lambda)        (None, 24, 32, 64)           0         ['lambda_2167[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2171 (Lambda)        (None, 24, 32, 64)           0         ['lambda_2168[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2172 (Lambda)        (None, 24, 32, 64)           0         ['lambda_2169[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2385 (Conv2D)        (None, 48, 64, 32)           27680     ['concatenate_902[0][0]']     \n",
      "                                                                                                  \n",
      " dense_539 (Dense)           (None, 1, 1, 256)            8448      ['dense_538[0][0]',           \n",
      "                                                                     'dense_538[1][0]']           \n",
      "                                                                                                  \n",
      " multiply_1071 (Multiply)    (None, 24, 32, 64)           0         ['conv2d_2390[0][0]',         \n",
      "                                                                     'lambda_2170[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1072 (Multiply)    (None, 24, 32, 64)           0         ['conv2d_2391[0][0]',         \n",
      "                                                                     'lambda_2171[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1073 (Multiply)    (None, 24, 32, 64)           0         ['conv2d_2392[0][0]',         \n",
      "                                                                     'lambda_2172[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1134 (  (None, 48, 64, 32)           128       ['conv2d_2385[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " add_592 (Add)               (None, 1, 1, 256)            0         ['dense_539[0][0]',           \n",
      "                                                                     'dense_539[1][0]']           \n",
      "                                                                                                  \n",
      " add_589 (Add)               (None, 24, 32, 64)           0         ['multiply_1071[0][0]',       \n",
      "                                                                     'multiply_1072[0][0]',       \n",
      "                                                                     'multiply_1073[0][0]']       \n",
      "                                                                                                  \n",
      " activation_1401 (Activatio  (None, 48, 64, 32)           0         ['batch_normalization_1134[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " activation_1405 (Activatio  (None, 1, 1, 256)            0         ['add_592[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 64)                   0         ['add_589[0][0]']             \n",
      " 68 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_268 (  (None, 64)                   0         ['add_589[0][0]']             \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2386 (Conv2D)        (None, 48, 64, 3)            99        ['activation_1401[0][0]']     \n",
      "                                                                                                  \n",
      " multiply_1076 (Multiply)    (None, 12, 16, 256)          0         ['concatenate_906[0][0]',     \n",
      "                                                                     'activation_1405[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_536 (Reshape)       (None, 1, 1, 64)             0         ['global_average_pooling2d_268\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_537 (Reshape)       (None, 1, 1, 64)             0         ['global_max_pooling2d_268[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " lambda_2159 (Lambda)        (None, 48, 64, 1)            0         ['conv2d_2386[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2160 (Lambda)        (None, 48, 64, 1)            0         ['conv2d_2386[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2161 (Lambda)        (None, 48, 64, 1)            0         ['conv2d_2386[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2175 (Lambda)        (None, 12, 16, 1)            0         ['multiply_1076[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_2176 (Lambda)        (None, 12, 16, 1)            0         ['multiply_1076[0][0]']       \n",
      "                                                                                                  \n",
      " dense_536 (Dense)           (None, 1, 1, 8)              520       ['reshape_536[0][0]',         \n",
      "                                                                     'reshape_537[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2162 (Lambda)        (None, 48, 64, 32)           0         ['lambda_2159[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2163 (Lambda)        (None, 48, 64, 32)           0         ['lambda_2160[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2164 (Lambda)        (None, 48, 64, 32)           0         ['lambda_2161[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_907 (Concatena  (None, 12, 16, 2)            0         ['lambda_2175[0][0]',         \n",
      " te)                                                                 'lambda_2176[0][0]']         \n",
      "                                                                                                  \n",
      " dense_537 (Dense)           (None, 1, 1, 64)             576       ['dense_536[0][0]',           \n",
      "                                                                     'dense_536[1][0]']           \n",
      "                                                                                                  \n",
      " multiply_1066 (Multiply)    (None, 48, 64, 32)           0         ['conv2d_2382[0][0]',         \n",
      "                                                                     'lambda_2162[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1067 (Multiply)    (None, 48, 64, 32)           0         ['conv2d_2383[0][0]',         \n",
      "                                                                     'lambda_2163[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1068 (Multiply)    (None, 48, 64, 32)           0         ['conv2d_2384[0][0]',         \n",
      "                                                                     'lambda_2164[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2398 (Conv2D)        (None, 12, 16, 1)            98        ['concatenate_907[0][0]']     \n",
      "                                                                                                  \n",
      " add_590 (Add)               (None, 1, 1, 64)             0         ['dense_537[0][0]',           \n",
      "                                                                     'dense_537[1][0]']           \n",
      "                                                                                                  \n",
      " add_586 (Add)               (None, 48, 64, 32)           0         ['multiply_1066[0][0]',       \n",
      "                                                                     'multiply_1067[0][0]',       \n",
      "                                                                     'multiply_1068[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_1077 (Multiply)    (None, 12, 16, 256)          0         ['multiply_1076[0][0]',       \n",
      "                                                                     'conv2d_2398[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1404 (Activatio  (None, 1, 1, 64)             0         ['add_590[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 32)                   0         ['add_586[0][0]']             \n",
      " 67 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_267 (  (None, 32)                   0         ['add_586[0][0]']             \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2399 (Conv2D)        (None, 12, 16, 256)          590080    ['multiply_1077[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_1074 (Multiply)    (None, 24, 32, 64)           0         ['add_589[0][0]',             \n",
      "                                                                     'activation_1404[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_534 (Reshape)       (None, 1, 1, 32)             0         ['global_average_pooling2d_267\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_535 (Reshape)       (None, 1, 1, 32)             0         ['global_max_pooling2d_267[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization_1136 (  (None, 12, 16, 256)          1024      ['conv2d_2399[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " lambda_2173 (Lambda)        (None, 24, 32, 1)            0         ['multiply_1074[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_2174 (Lambda)        (None, 24, 32, 1)            0         ['multiply_1074[0][0]']       \n",
      "                                                                                                  \n",
      " dense_534 (Dense)           (None, 1, 1, 4)              132       ['reshape_534[0][0]',         \n",
      "                                                                     'reshape_535[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1406 (Activatio  (None, 12, 16, 256)          0         ['batch_normalization_1136[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " concatenate_905 (Concatena  (None, 24, 32, 2)            0         ['lambda_2173[0][0]',         \n",
      " te)                                                                 'lambda_2174[0][0]']         \n",
      "                                                                                                  \n",
      " dense_535 (Dense)           (None, 1, 1, 32)             160       ['dense_534[0][0]',           \n",
      "                                                                     'dense_534[1][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_152 (UpSampl  (None, 24, 32, 256)          0         ['activation_1406[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2395 (Conv2D)        (None, 24, 32, 1)            98        ['concatenate_905[0][0]']     \n",
      "                                                                                                  \n",
      " add_587 (Add)               (None, 1, 1, 32)             0         ['dense_535[0][0]',           \n",
      "                                                                     'dense_535[1][0]']           \n",
      "                                                                                                  \n",
      " conv2d_2400 (Conv2D)        (None, 24, 32, 128)          295040    ['up_sampling2d_152[0][0]']   \n",
      "                                                                                                  \n",
      " multiply_1075 (Multiply)    (None, 24, 32, 64)           0         ['multiply_1074[0][0]',       \n",
      "                                                                     'conv2d_2395[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1402 (Activatio  (None, 1, 1, 32)             0         ['add_587[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_894 (Concatena  (None, 48, 64, 2)            0         ['lambda_2146[0][0]',         \n",
      " te)                                                                 'lambda_2147[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1137 (  (None, 24, 32, 128)          512       ['conv2d_2400[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2397 (Conv2D)        (None, 24, 32, 64)           12352     ['concatenate_904[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2396 (Conv2D)        (None, 24, 32, 64)           4160      ['multiply_1075[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_1069 (Multiply)    (None, 48, 64, 32)           0         ['add_586[0][0]',             \n",
      "                                                                     'activation_1402[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_895 (Concatena  (None, 48, 64, 7)            0         ['lambda_2143[0][0]',         \n",
      " te)                                                                 'lambda_2144[0][0]',         \n",
      "                                                                     'lambda_2145[0][0]',         \n",
      "                                                                     'concatenate_894[0][0]']     \n",
      "                                                                                                  \n",
      " activation_1407 (Activatio  (None, 24, 32, 128)          0         ['batch_normalization_1137[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " add_591 (Add)               (None, 24, 32, 64)           0         ['conv2d_2397[0][0]',         \n",
      "                                                                     'conv2d_2396[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2165 (Lambda)        (None, 48, 64, 1)            0         ['multiply_1069[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_2166 (Lambda)        (None, 48, 64, 1)            0         ['multiply_1069[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2366 (Conv2D)        (None, 48, 64, 16)           1024      ['concatenate_895[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_908 (Concatena  (None, 24, 32, 192)          0         ['activation_1407[0][0]',     \n",
      " te)                                                                 'add_591[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_903 (Concatena  (None, 48, 64, 2)            0         ['lambda_2165[0][0]',         \n",
      " te)                                                                 'lambda_2166[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1124 (  (None, 48, 64, 16)           64        ['conv2d_2366[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " up_sampling2d_153 (UpSampl  (None, 48, 64, 192)          0         ['concatenate_908[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2387 (Conv2D)        (None, 48, 64, 1)            98        ['concatenate_903[0][0]']     \n",
      "                                                                                                  \n",
      " activation_1389 (Activatio  (None, 48, 64, 16)           0         ['batch_normalization_1124[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2d_2401 (Conv2D)        (None, 48, 64, 64)           110656    ['up_sampling2d_153[0][0]']   \n",
      "                                                                                                  \n",
      " multiply_1070 (Multiply)    (None, 48, 64, 32)           0         ['multiply_1069[0][0]',       \n",
      "                                                                     'conv2d_2387[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2367 (Conv2D)        (None, 48, 64, 8)            1160      ['activation_1389[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2369 (Conv2D)        (None, 48, 64, 1)            10        ['lambda_2144[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1138 (  (None, 48, 64, 64)           256       ['conv2d_2401[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2389 (Conv2D)        (None, 48, 64, 32)           3104      ['concatenate_902[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2388 (Conv2D)        (None, 48, 64, 32)           1056      ['multiply_1070[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1125 (  (None, 48, 64, 8)            32        ['conv2d_2367[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " lambda_2148 (Lambda)        (None, 48, 64, 1)            0         ['conv2d_2369[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1408 (Activatio  (None, 48, 64, 64)           0         ['batch_normalization_1138[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " add_588 (Add)               (None, 48, 64, 32)           0         ['conv2d_2389[0][0]',         \n",
      "                                                                     'conv2d_2388[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1390 (Activatio  (None, 48, 64, 8)            0         ['batch_normalization_1125[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " lambda_2149 (Lambda)        (None, 48, 64, 1)            0         ['lambda_2148[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_909 (Concatena  (None, 48, 64, 96)           0         ['activation_1408[0][0]',     \n",
      " te)                                                                 'add_588[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_2368 (Conv2D)        (None, 48, 64, 1)            73        ['activation_1390[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_53 (TFOpL  (None, 48, 64, 1)            0         ['lambda_2149[0][0]']         \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2402 (Conv2D)        (None, 48, 64, 32)           27680     ['concatenate_909[0][0]']     \n",
      "                                                                                                  \n",
      " add_583 (Add)               (None, 48, 64, 1)            0         ['conv2d_2368[0][0]',         \n",
      "                                                                     'tf.math.multiply_53[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_1139 (  (None, 48, 64, 32)           128       ['conv2d_2402[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " lambda_2150 (Lambda)        (None, 48, 64, 1)            0         ['add_583[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1409 (Activatio  (None, 48, 64, 32)           0         ['batch_normalization_1139[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " lambda_2177 (Lambda)        (None, 48, 64, 32)           0         ['lambda_2150[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1078 (Multiply)    (None, 48, 64, 32)           0         ['activation_1409[0][0]',     \n",
      "                                                                     'lambda_2177[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2403 (Conv2D)        (None, 48, 64, 1)            289       ['multiply_1078[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2404 (Conv2D)        (None, 48, 64, 1)            289       ['activation_1409[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2179 (Lambda)        (None, 48, 64, 1)            0         ['lambda_2144[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2178 (Lambda)        (None, 48, 64, 1)            0         ['conv2d_2403[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2181 (Lambda)        (None, 48, 64, 1)            0         ['lambda_2144[0][0]',         \n",
      "                                                                     'conv2d_2404[0][0]',         \n",
      "                                                                     'lambda_2146[0][0]',         \n",
      "                                                                     'lambda_2179[0][0]',         \n",
      "                                                                     'lambda_2145[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1079 (Multiply)    (None, 48, 64, 1)            0         ['lambda_2178[0][0]',         \n",
      "                                                                     'lambda_2150[0][0]']         \n",
      "                                                                                                  \n",
      " add_593 (Add)               (None, 48, 64, 1)            0         ['lambda_2181[0][0]',         \n",
      "                                                                     'multiply_1079[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_2182 (Lambda)        (None, 48, 64, 1)            0         ['add_593[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1301737 (4.97 MB)\n",
      "Trainable params: 1299769 (4.96 MB)\n",
      "Non-trainable params: 1968 (7.69 KB)\n",
      "__________________________________________________________________________________________________\n",
      "학습 시작: 단계 2, 해상도 (48, 64), 에폭 12\n",
      "Epoch 1/12\n",
      " 5/50 [==>...........................] - ETA: 1s - loss: 0.1652 - mae: 0.1492  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0293s vs `on_train_batch_end` time: 0.0333s). Check your callbacks.\n",
      "1/1 [==============================] - 1s 840ms/steposs: 0.1688 - mae: 0.15\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "50/50 [==============================] - 23s 105ms/step - loss: 0.1689 - mae: 0.1539 - val_loss: 0.1893 - val_mae: 0.1709 - lr: 1.0000e-06\n",
      "Epoch 2/12\n",
      "50/50 [==============================] - 3s 66ms/step - loss: 0.1633 - mae: 0.1492 - val_loss: 0.1842 - val_mae: 0.1669 - lr: 1.0000e-06\n",
      "Epoch 3/12\n",
      "1/1 [==============================] - 0s 24ms/steploss: 0.1581 - mae: 0.14\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "50/50 [==============================] - 3s 68ms/step - loss: 0.1582 - mae: 0.1449 - val_loss: 0.1789 - val_mae: 0.1627 - lr: 1.0000e-06\n",
      "Epoch 4/12\n",
      "50/50 [==============================] - 3s 56ms/step - loss: 0.1536 - mae: 0.1410 - val_loss: 0.1735 - val_mae: 0.1583 - lr: 1.0000e-06\n",
      "Epoch 5/12\n",
      "1/1 [==============================] - 0s 24ms/steploss: 0.1492 - mae: 0.13\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "50/50 [==============================] - 3s 70ms/step - loss: 0.1493 - mae: 0.1374 - val_loss: 0.1690 - val_mae: 0.1544 - lr: 1.0000e-06\n",
      "Epoch 6/12\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.1454 - mae: 0.1341 - val_loss: 0.1652 - val_mae: 0.1508 - lr: 1.0000e-06\n",
      "Epoch 7/12\n",
      "1/1 [==============================] - 0s 24ms/steploss: 0.1417 - mae: 0.13\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "50/50 [==============================] - 3s 67ms/step - loss: 0.1418 - mae: 0.1310 - val_loss: 0.1615 - val_mae: 0.1472 - lr: 1.0000e-06\n",
      "Epoch 8/12\n",
      "50/50 [==============================] - 4s 91ms/step - loss: 0.1384 - mae: 0.1282 - val_loss: 0.1572 - val_mae: 0.1429 - lr: 1.0000e-06\n",
      "Epoch 9/12\n",
      "1/1 [==============================] - 0s 32ms/steploss: 0.1352 - mae: 0.12\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "50/50 [==============================] - 3s 68ms/step - loss: 0.1353 - mae: 0.1256 - val_loss: 0.1518 - val_mae: 0.1380 - lr: 1.0000e-06\n",
      "Epoch 10/12\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.1324 - mae: 0.1232 - val_loss: 0.1460 - val_mae: 0.1327 - lr: 1.0000e-06\n",
      "Epoch 11/12\n",
      "1/1 [==============================] - 0s 30ms/steploss: 0.1296 - mae: 0.12\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "50/50 [==============================] - 3s 69ms/step - loss: 0.1297 - mae: 0.1210 - val_loss: 0.1407 - val_mae: 0.1280 - lr: 1.0000e-06\n",
      "Epoch 12/12\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.1271 - mae: 0.1189 - val_loss: 0.1361 - val_mae: 0.1240 - lr: 1.0000e-06\n",
      "단계 2 최종 결과:\n",
      "  - 훈련 손실: 0.1271\n",
      "  - 검증 손실: 0.1361\n",
      "  - 훈련 MAE: 0.1189\n",
      "  - 검증 MAE: 0.1240\n",
      "단계 2 모델 저장 완료: checkpoints/depth_model_stage2.h5\n",
      "\n",
      "==================== 학습 단계 3/5: 해상도 (96, 128) ====================\n",
      "현재 학습률: 5.00e-07\n",
      "데이터셋 생성 중... 대상 해상도: (96, 128)\n",
      "데이터셋 생성 중... 대상 해상도: (96, 128), Stage: 2\n",
      "로드된 샘플 수: 600\n",
      "데이터 전처리 시작\n",
      "최종 입력 데이터 형태: (600, 96, 128, 7)\n",
      "입력 데이터 범위:\n",
      "  RGB: 0.0 ~ 1.0\n",
      "  깊이: 0.0 ~ 1.0\n",
      "  MDE: 0.0 ~ 1.0\n",
      "  Sensor Confidence: 0.3 ~ 0.7\n",
      "  MDE Confidence: 0.7 ~ 0.7\n",
      "최종 타겟 데이터 형태: (600, 96, 128, 1)\n",
      "타겟 깊이 범위: 0.0 ~ 1.0\n",
      "데이터셋 생성 중... 대상 해상도: (96, 128), Stage: 2\n",
      "로드된 샘플 수: 200\n",
      "데이터 전처리 시작\n",
      "최종 입력 데이터 형태: (200, 96, 128, 7)\n",
      "입력 데이터 범위:\n",
      "  RGB: 0.0 ~ 1.0\n",
      "  깊이: 0.0 ~ 1.0\n",
      "  MDE: 0.0 ~ 1.0\n",
      "  Sensor Confidence: 0.3 ~ 0.7\n",
      "  MDE Confidence: 0.7 ~ 0.7\n",
      "최종 타겟 데이터 형태: (200, 96, 128, 1)\n",
      "타겟 깊이 범위: 0.0 ~ 1.0\n",
      "학습 데이터 배치 형태: 입력=(8, 96, 128, 7), 타겟=(8, 96, 128, 1)\n",
      "데이터셋 NaN/Inf 검사 중...\n",
      "학습 데이터셋에 NaN/Inf 값이 감지되지 않았습니다.\n",
      "검증 데이터셋에 NaN/Inf 값이 감지되지 않았습니다.\n",
      "모델 입력 차원: (96, 128, 7)\n",
      "개선된 가중치 전이 함수 실행 중...\n",
      "가중치 전이 성공! (일치하지 않는 레이어는 건너뜀)\n",
      "가중치 전이 성공\n",
      "Model: \"model_77\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_78 (InputLayer)       [(None, 96, 128, 7)]         0         []                            \n",
      "                                                                                                  \n",
      " lambda_2183 (Lambda)        (None, 96, 128, 3)           0         ['input_78[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_2409 (Conv2D)        (None, 96, 128, 32)          896       ['lambda_2183[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1142 (  (None, 96, 128, 32)          128       ['conv2d_2409[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1412 (Activatio  (None, 96, 128, 32)          0         ['batch_normalization_1142[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 32)                   0         ['activation_1412[0][0]']     \n",
      " 70 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_270 (  (None, 32)                   0         ['activation_1412[0][0]']     \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " lambda_2184 (Lambda)        (None, 96, 128, 1)           0         ['input_78[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_540 (Reshape)       (None, 1, 1, 32)             0         ['global_average_pooling2d_270\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_541 (Reshape)       (None, 1, 1, 32)             0         ['global_max_pooling2d_270[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " lambda_2186 (Lambda)        (None, 96, 128, 1)           0         ['input_78[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_2185 (Lambda)        (None, 96, 128, 1)           0         ['input_78[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_2187 (Lambda)        (None, 96, 128, 1)           0         ['input_78[0][0]']            \n",
      "                                                                                                  \n",
      " dense_540 (Dense)           (None, 1, 1, 4)              132       ['reshape_540[0][0]',         \n",
      "                                                                     'reshape_541[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_912 (Concatena  (None, 96, 128, 2)           0         ['lambda_2184[0][0]',         \n",
      " te)                                                                 'lambda_2186[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_915 (Concatena  (None, 96, 128, 2)           0         ['lambda_2185[0][0]',         \n",
      " te)                                                                 'lambda_2187[0][0]']         \n",
      "                                                                                                  \n",
      " dense_541 (Dense)           (None, 1, 1, 32)             160       ['dense_540[0][0]',           \n",
      "                                                                     'dense_540[1][0]']           \n",
      "                                                                                                  \n",
      " conv2d_2411 (Conv2D)        (None, 96, 128, 32)          608       ['concatenate_912[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2415 (Conv2D)        (None, 96, 128, 32)          608       ['concatenate_915[0][0]']     \n",
      "                                                                                                  \n",
      " add_595 (Add)               (None, 1, 1, 32)             0         ['dense_541[0][0]',           \n",
      "                                                                     'dense_541[1][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_1144 (  (None, 96, 128, 32)          128       ['conv2d_2411[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_1146 (  (None, 96, 128, 32)          128       ['conv2d_2415[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1413 (Activatio  (None, 1, 1, 32)             0         ['add_595[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " activation_1416 (Activatio  (None, 96, 128, 32)          0         ['batch_normalization_1144[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " activation_1418 (Activatio  (None, 96, 128, 32)          0         ['batch_normalization_1146[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " multiply_1080 (Multiply)    (None, 96, 128, 32)          0         ['activation_1412[0][0]',     \n",
      "                                                                     'activation_1413[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2191 (Lambda)        (None, 96, 128, 1)           0         ['activation_1416[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2192 (Lambda)        (None, 96, 128, 1)           0         ['activation_1416[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2195 (Lambda)        (None, 96, 128, 1)           0         ['activation_1418[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2196 (Lambda)        (None, 96, 128, 1)           0         ['activation_1418[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_532 (MaxPool  (None, 48, 64, 32)           0         ['multiply_1080[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_913 (Concatena  (None, 96, 128, 2)           0         ['lambda_2191[0][0]',         \n",
      " te)                                                                 'lambda_2192[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_916 (Concatena  (None, 96, 128, 2)           0         ['lambda_2195[0][0]',         \n",
      " te)                                                                 'lambda_2196[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2410 (Conv2D)        (None, 48, 64, 64)           18496     ['max_pooling2d_532[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_2412 (Conv2D)        (None, 96, 128, 1)           98        ['concatenate_913[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2416 (Conv2D)        (None, 96, 128, 1)           98        ['concatenate_916[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1143 (  (None, 48, 64, 64)           256       ['conv2d_2410[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multiply_1082 (Multiply)    (None, 96, 128, 32)          0         ['activation_1416[0][0]',     \n",
      "                                                                     'conv2d_2412[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1084 (Multiply)    (None, 96, 128, 32)          0         ['activation_1418[0][0]',     \n",
      "                                                                     'conv2d_2416[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1414 (Activatio  (None, 48, 64, 64)           0         ['batch_normalization_1143[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " max_pooling2d_534 (MaxPool  (None, 48, 64, 32)           0         ['multiply_1082[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_536 (MaxPool  (None, 48, 64, 32)           0         ['multiply_1084[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 64)                   0         ['activation_1414[0][0]']     \n",
      " 71 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_271 (  (None, 64)                   0         ['activation_1414[0][0]']     \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2413 (Conv2D)        (None, 48, 64, 64)           18496     ['max_pooling2d_534[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_2417 (Conv2D)        (None, 48, 64, 64)           18496     ['max_pooling2d_536[0][0]']   \n",
      "                                                                                                  \n",
      " reshape_542 (Reshape)       (None, 1, 1, 64)             0         ['global_average_pooling2d_271\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_543 (Reshape)       (None, 1, 1, 64)             0         ['global_max_pooling2d_271[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization_1145 (  (None, 48, 64, 64)           256       ['conv2d_2413[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_1147 (  (None, 48, 64, 64)           256       ['conv2d_2417[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_542 (Dense)           (None, 1, 1, 8)              520       ['reshape_542[0][0]',         \n",
      "                                                                     'reshape_543[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1417 (Activatio  (None, 48, 64, 64)           0         ['batch_normalization_1145[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " activation_1419 (Activatio  (None, 48, 64, 64)           0         ['batch_normalization_1147[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " subtract_54 (Subtract)      (None, 96, 128, 1)           0         ['lambda_2184[0][0]',         \n",
      "                                                                     'lambda_2185[0][0]']         \n",
      "                                                                                                  \n",
      " dense_543 (Dense)           (None, 1, 1, 64)             576       ['dense_542[0][0]',           \n",
      "                                                                     'dense_542[1][0]']           \n",
      "                                                                                                  \n",
      " lambda_2193 (Lambda)        (None, 48, 64, 1)            0         ['activation_1417[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2194 (Lambda)        (None, 48, 64, 1)            0         ['activation_1417[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2197 (Lambda)        (None, 48, 64, 1)            0         ['activation_1419[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2198 (Lambda)        (None, 48, 64, 1)            0         ['activation_1419[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2419 (Conv2D)        (None, 96, 128, 32)          320       ['subtract_54[0][0]']         \n",
      "                                                                                                  \n",
      " add_596 (Add)               (None, 1, 1, 64)             0         ['dense_543[0][0]',           \n",
      "                                                                     'dense_543[1][0]']           \n",
      "                                                                                                  \n",
      " concatenate_914 (Concatena  (None, 48, 64, 2)            0         ['lambda_2193[0][0]',         \n",
      " te)                                                                 'lambda_2194[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_917 (Concatena  (None, 48, 64, 2)            0         ['lambda_2197[0][0]',         \n",
      " te)                                                                 'lambda_2198[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1148 (  (None, 96, 128, 32)          128       ['conv2d_2419[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1415 (Activatio  (None, 1, 1, 64)             0         ['add_596[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2414 (Conv2D)        (None, 48, 64, 1)            98        ['concatenate_914[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2418 (Conv2D)        (None, 48, 64, 1)            98        ['concatenate_917[0][0]']     \n",
      "                                                                                                  \n",
      " activation_1420 (Activatio  (None, 96, 128, 32)          0         ['batch_normalization_1148[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " multiply_1081 (Multiply)    (None, 48, 64, 64)           0         ['activation_1414[0][0]',     \n",
      "                                                                     'activation_1415[0][0]']     \n",
      "                                                                                                  \n",
      " multiply_1083 (Multiply)    (None, 48, 64, 64)           0         ['activation_1417[0][0]',     \n",
      "                                                                     'conv2d_2414[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1085 (Multiply)    (None, 48, 64, 64)           0         ['activation_1419[0][0]',     \n",
      "                                                                     'conv2d_2418[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling2d_538 (MaxPool  (None, 48, 64, 32)           0         ['activation_1420[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2420 (Conv2D)        (None, 48, 64, 64)           18496     ['max_pooling2d_538[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_2429 (Conv2D)        (None, 48, 64, 64)           4160      ['multiply_1081[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2430 (Conv2D)        (None, 48, 64, 64)           4160      ['multiply_1083[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2431 (Conv2D)        (None, 48, 64, 64)           4160      ['multiply_1085[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1149 (  (None, 48, 64, 64)           256       ['conv2d_2420[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " concatenate_920 (Concatena  (None, 48, 64, 192)          0         ['conv2d_2429[0][0]',         \n",
      " te)                                                                 'conv2d_2430[0][0]',         \n",
      "                                                                     'conv2d_2431[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1421 (Activatio  (None, 48, 64, 64)           0         ['batch_normalization_1149[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2d_2432 (Conv2D)        (None, 48, 64, 64)           110656    ['concatenate_920[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_533 (MaxPool  (None, 24, 32, 64)           0         ['multiply_1081[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_535 (MaxPool  (None, 24, 32, 64)           0         ['multiply_1083[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_537 (MaxPool  (None, 24, 32, 64)           0         ['multiply_1085[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_539 (MaxPool  (None, 24, 32, 64)           0         ['activation_1421[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_1151 (  (None, 48, 64, 64)           256       ['conv2d_2432[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " concatenate_922 (Concatena  (None, 24, 32, 256)          0         ['max_pooling2d_533[0][0]',   \n",
      " te)                                                                 'max_pooling2d_535[0][0]',   \n",
      "                                                                     'max_pooling2d_537[0][0]',   \n",
      "                                                                     'max_pooling2d_539[0][0]']   \n",
      "                                                                                                  \n",
      " activation_1424 (Activatio  (None, 48, 64, 64)           0         ['batch_normalization_1151[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 256)                  0         ['concatenate_922[0][0]']     \n",
      " 74 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_274 (  (None, 256)                  0         ['concatenate_922[0][0]']     \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2433 (Conv2D)        (None, 48, 64, 3)            195       ['activation_1424[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2421 (Conv2D)        (None, 96, 128, 32)          1056      ['multiply_1080[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2422 (Conv2D)        (None, 96, 128, 32)          1056      ['multiply_1082[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2423 (Conv2D)        (None, 96, 128, 32)          1056      ['multiply_1084[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_548 (Reshape)       (None, 1, 1, 256)            0         ['global_average_pooling2d_274\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_549 (Reshape)       (None, 1, 1, 256)            0         ['global_max_pooling2d_274[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " lambda_2207 (Lambda)        (None, 48, 64, 1)            0         ['conv2d_2433[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2208 (Lambda)        (None, 48, 64, 1)            0         ['conv2d_2433[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2209 (Lambda)        (None, 48, 64, 1)            0         ['conv2d_2433[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_918 (Concatena  (None, 96, 128, 96)          0         ['conv2d_2421[0][0]',         \n",
      " te)                                                                 'conv2d_2422[0][0]',         \n",
      "                                                                     'conv2d_2423[0][0]']         \n",
      "                                                                                                  \n",
      " dense_548 (Dense)           (None, 1, 1, 32)             8224      ['reshape_548[0][0]',         \n",
      "                                                                     'reshape_549[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2210 (Lambda)        (None, 48, 64, 64)           0         ['lambda_2207[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2211 (Lambda)        (None, 48, 64, 64)           0         ['lambda_2208[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2212 (Lambda)        (None, 48, 64, 64)           0         ['lambda_2209[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2424 (Conv2D)        (None, 96, 128, 32)          27680     ['concatenate_918[0][0]']     \n",
      "                                                                                                  \n",
      " dense_549 (Dense)           (None, 1, 1, 256)            8448      ['dense_548[0][0]',           \n",
      "                                                                     'dense_548[1][0]']           \n",
      "                                                                                                  \n",
      " multiply_1091 (Multiply)    (None, 48, 64, 64)           0         ['conv2d_2429[0][0]',         \n",
      "                                                                     'lambda_2210[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1092 (Multiply)    (None, 48, 64, 64)           0         ['conv2d_2430[0][0]',         \n",
      "                                                                     'lambda_2211[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1093 (Multiply)    (None, 48, 64, 64)           0         ['conv2d_2431[0][0]',         \n",
      "                                                                     'lambda_2212[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1150 (  (None, 96, 128, 32)          128       ['conv2d_2424[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " add_603 (Add)               (None, 1, 1, 256)            0         ['dense_549[0][0]',           \n",
      "                                                                     'dense_549[1][0]']           \n",
      "                                                                                                  \n",
      " add_600 (Add)               (None, 48, 64, 64)           0         ['multiply_1091[0][0]',       \n",
      "                                                                     'multiply_1092[0][0]',       \n",
      "                                                                     'multiply_1093[0][0]']       \n",
      "                                                                                                  \n",
      " activation_1422 (Activatio  (None, 96, 128, 32)          0         ['batch_normalization_1150[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " activation_1426 (Activatio  (None, 1, 1, 256)            0         ['add_603[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 64)                   0         ['add_600[0][0]']             \n",
      " 73 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_273 (  (None, 64)                   0         ['add_600[0][0]']             \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2425 (Conv2D)        (None, 96, 128, 3)           99        ['activation_1422[0][0]']     \n",
      "                                                                                                  \n",
      " multiply_1096 (Multiply)    (None, 24, 32, 256)          0         ['concatenate_922[0][0]',     \n",
      "                                                                     'activation_1426[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_546 (Reshape)       (None, 1, 1, 64)             0         ['global_average_pooling2d_273\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_547 (Reshape)       (None, 1, 1, 64)             0         ['global_max_pooling2d_273[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " lambda_2199 (Lambda)        (None, 96, 128, 1)           0         ['conv2d_2425[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2200 (Lambda)        (None, 96, 128, 1)           0         ['conv2d_2425[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2201 (Lambda)        (None, 96, 128, 1)           0         ['conv2d_2425[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2215 (Lambda)        (None, 24, 32, 1)            0         ['multiply_1096[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_2216 (Lambda)        (None, 24, 32, 1)            0         ['multiply_1096[0][0]']       \n",
      "                                                                                                  \n",
      " dense_546 (Dense)           (None, 1, 1, 8)              520       ['reshape_546[0][0]',         \n",
      "                                                                     'reshape_547[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2202 (Lambda)        (None, 96, 128, 32)          0         ['lambda_2199[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2203 (Lambda)        (None, 96, 128, 32)          0         ['lambda_2200[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2204 (Lambda)        (None, 96, 128, 32)          0         ['lambda_2201[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_923 (Concatena  (None, 24, 32, 2)            0         ['lambda_2215[0][0]',         \n",
      " te)                                                                 'lambda_2216[0][0]']         \n",
      "                                                                                                  \n",
      " dense_547 (Dense)           (None, 1, 1, 64)             576       ['dense_546[0][0]',           \n",
      "                                                                     'dense_546[1][0]']           \n",
      "                                                                                                  \n",
      " multiply_1086 (Multiply)    (None, 96, 128, 32)          0         ['conv2d_2421[0][0]',         \n",
      "                                                                     'lambda_2202[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1087 (Multiply)    (None, 96, 128, 32)          0         ['conv2d_2422[0][0]',         \n",
      "                                                                     'lambda_2203[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1088 (Multiply)    (None, 96, 128, 32)          0         ['conv2d_2423[0][0]',         \n",
      "                                                                     'lambda_2204[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2437 (Conv2D)        (None, 24, 32, 1)            98        ['concatenate_923[0][0]']     \n",
      "                                                                                                  \n",
      " add_601 (Add)               (None, 1, 1, 64)             0         ['dense_547[0][0]',           \n",
      "                                                                     'dense_547[1][0]']           \n",
      "                                                                                                  \n",
      " add_597 (Add)               (None, 96, 128, 32)          0         ['multiply_1086[0][0]',       \n",
      "                                                                     'multiply_1087[0][0]',       \n",
      "                                                                     'multiply_1088[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_1097 (Multiply)    (None, 24, 32, 256)          0         ['multiply_1096[0][0]',       \n",
      "                                                                     'conv2d_2437[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1425 (Activatio  (None, 1, 1, 64)             0         ['add_601[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 32)                   0         ['add_597[0][0]']             \n",
      " 72 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_272 (  (None, 32)                   0         ['add_597[0][0]']             \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2438 (Conv2D)        (None, 24, 32, 256)          590080    ['multiply_1097[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_1094 (Multiply)    (None, 48, 64, 64)           0         ['add_600[0][0]',             \n",
      "                                                                     'activation_1425[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_544 (Reshape)       (None, 1, 1, 32)             0         ['global_average_pooling2d_272\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_545 (Reshape)       (None, 1, 1, 32)             0         ['global_max_pooling2d_272[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization_1152 (  (None, 24, 32, 256)          1024      ['conv2d_2438[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " lambda_2213 (Lambda)        (None, 48, 64, 1)            0         ['multiply_1094[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_2214 (Lambda)        (None, 48, 64, 1)            0         ['multiply_1094[0][0]']       \n",
      "                                                                                                  \n",
      " dense_544 (Dense)           (None, 1, 1, 4)              132       ['reshape_544[0][0]',         \n",
      "                                                                     'reshape_545[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1427 (Activatio  (None, 24, 32, 256)          0         ['batch_normalization_1152[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " concatenate_921 (Concatena  (None, 48, 64, 2)            0         ['lambda_2213[0][0]',         \n",
      " te)                                                                 'lambda_2214[0][0]']         \n",
      "                                                                                                  \n",
      " dense_545 (Dense)           (None, 1, 1, 32)             160       ['dense_544[0][0]',           \n",
      "                                                                     'dense_544[1][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_154 (UpSampl  (None, 48, 64, 256)          0         ['activation_1427[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2434 (Conv2D)        (None, 48, 64, 1)            98        ['concatenate_921[0][0]']     \n",
      "                                                                                                  \n",
      " add_598 (Add)               (None, 1, 1, 32)             0         ['dense_545[0][0]',           \n",
      "                                                                     'dense_545[1][0]']           \n",
      "                                                                                                  \n",
      " conv2d_2439 (Conv2D)        (None, 48, 64, 128)          295040    ['up_sampling2d_154[0][0]']   \n",
      "                                                                                                  \n",
      " multiply_1095 (Multiply)    (None, 48, 64, 64)           0         ['multiply_1094[0][0]',       \n",
      "                                                                     'conv2d_2434[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1423 (Activatio  (None, 1, 1, 32)             0         ['add_598[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_910 (Concatena  (None, 96, 128, 2)           0         ['lambda_2186[0][0]',         \n",
      " te)                                                                 'lambda_2187[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1153 (  (None, 48, 64, 128)          512       ['conv2d_2439[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2436 (Conv2D)        (None, 48, 64, 64)           12352     ['concatenate_920[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2435 (Conv2D)        (None, 48, 64, 64)           4160      ['multiply_1095[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_1089 (Multiply)    (None, 96, 128, 32)          0         ['add_597[0][0]',             \n",
      "                                                                     'activation_1423[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_911 (Concatena  (None, 96, 128, 7)           0         ['lambda_2183[0][0]',         \n",
      " te)                                                                 'lambda_2184[0][0]',         \n",
      "                                                                     'lambda_2185[0][0]',         \n",
      "                                                                     'concatenate_910[0][0]']     \n",
      "                                                                                                  \n",
      " activation_1428 (Activatio  (None, 48, 64, 128)          0         ['batch_normalization_1153[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " add_602 (Add)               (None, 48, 64, 64)           0         ['conv2d_2436[0][0]',         \n",
      "                                                                     'conv2d_2435[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2205 (Lambda)        (None, 96, 128, 1)           0         ['multiply_1089[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_2206 (Lambda)        (None, 96, 128, 1)           0         ['multiply_1089[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2405 (Conv2D)        (None, 96, 128, 16)          1024      ['concatenate_911[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_924 (Concatena  (None, 48, 64, 192)          0         ['activation_1428[0][0]',     \n",
      " te)                                                                 'add_602[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_919 (Concatena  (None, 96, 128, 2)           0         ['lambda_2205[0][0]',         \n",
      " te)                                                                 'lambda_2206[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1140 (  (None, 96, 128, 16)          64        ['conv2d_2405[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " up_sampling2d_155 (UpSampl  (None, 96, 128, 192)         0         ['concatenate_924[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2426 (Conv2D)        (None, 96, 128, 1)           98        ['concatenate_919[0][0]']     \n",
      "                                                                                                  \n",
      " activation_1410 (Activatio  (None, 96, 128, 16)          0         ['batch_normalization_1140[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2d_2440 (Conv2D)        (None, 96, 128, 64)          110656    ['up_sampling2d_155[0][0]']   \n",
      "                                                                                                  \n",
      " multiply_1090 (Multiply)    (None, 96, 128, 32)          0         ['multiply_1089[0][0]',       \n",
      "                                                                     'conv2d_2426[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2406 (Conv2D)        (None, 96, 128, 8)           1160      ['activation_1410[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2408 (Conv2D)        (None, 96, 128, 1)           10        ['lambda_2184[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1154 (  (None, 96, 128, 64)          256       ['conv2d_2440[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2428 (Conv2D)        (None, 96, 128, 32)          3104      ['concatenate_918[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2427 (Conv2D)        (None, 96, 128, 32)          1056      ['multiply_1090[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1141 (  (None, 96, 128, 8)           32        ['conv2d_2406[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " lambda_2188 (Lambda)        (None, 96, 128, 1)           0         ['conv2d_2408[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1429 (Activatio  (None, 96, 128, 64)          0         ['batch_normalization_1154[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " add_599 (Add)               (None, 96, 128, 32)          0         ['conv2d_2428[0][0]',         \n",
      "                                                                     'conv2d_2427[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1411 (Activatio  (None, 96, 128, 8)           0         ['batch_normalization_1141[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " lambda_2189 (Lambda)        (None, 96, 128, 1)           0         ['lambda_2188[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_925 (Concatena  (None, 96, 128, 96)          0         ['activation_1429[0][0]',     \n",
      " te)                                                                 'add_599[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_2407 (Conv2D)        (None, 96, 128, 1)           73        ['activation_1411[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_54 (TFOpL  (None, 96, 128, 1)           0         ['lambda_2189[0][0]']         \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2441 (Conv2D)        (None, 96, 128, 32)          27680     ['concatenate_925[0][0]']     \n",
      "                                                                                                  \n",
      " add_594 (Add)               (None, 96, 128, 1)           0         ['conv2d_2407[0][0]',         \n",
      "                                                                     'tf.math.multiply_54[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_1155 (  (None, 96, 128, 32)          128       ['conv2d_2441[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " lambda_2190 (Lambda)        (None, 96, 128, 1)           0         ['add_594[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1430 (Activatio  (None, 96, 128, 32)          0         ['batch_normalization_1155[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " lambda_2217 (Lambda)        (None, 96, 128, 32)          0         ['lambda_2190[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1098 (Multiply)    (None, 96, 128, 32)          0         ['activation_1430[0][0]',     \n",
      "                                                                     'lambda_2217[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2442 (Conv2D)        (None, 96, 128, 1)           289       ['multiply_1098[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2443 (Conv2D)        (None, 96, 128, 1)           289       ['activation_1430[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2219 (Lambda)        (None, 96, 128, 1)           0         ['lambda_2184[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2218 (Lambda)        (None, 96, 128, 1)           0         ['conv2d_2442[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2221 (Lambda)        (None, 96, 128, 1)           0         ['lambda_2184[0][0]',         \n",
      "                                                                     'conv2d_2443[0][0]',         \n",
      "                                                                     'lambda_2186[0][0]',         \n",
      "                                                                     'lambda_2219[0][0]',         \n",
      "                                                                     'lambda_2185[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1099 (Multiply)    (None, 96, 128, 1)           0         ['lambda_2218[0][0]',         \n",
      "                                                                     'lambda_2190[0][0]']         \n",
      "                                                                                                  \n",
      " add_604 (Add)               (None, 96, 128, 1)           0         ['lambda_2221[0][0]',         \n",
      "                                                                     'multiply_1099[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_2222 (Lambda)        (None, 96, 128, 1)           0         ['add_604[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1301737 (4.97 MB)\n",
      "Trainable params: 1299769 (4.96 MB)\n",
      "Non-trainable params: 1968 (7.69 KB)\n",
      "__________________________________________________________________________________________________\n",
      "학습 시작: 단계 3, 해상도 (96, 128), 에폭 10\n",
      "Epoch 1/10\n",
      " 6/75 [=>............................] - ETA: 4s - loss: 0.1915 - mae: 0.1714WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0421s vs `on_train_batch_end` time: 0.0484s). Check your callbacks.\n",
      "1/1 [==============================] - 1s 806ms/steposs: 0.1968 - mae: 0.17\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "75/75 [==============================] - 26s 118ms/step - loss: 0.1968 - mae: 0.1768 - val_loss: 0.2001 - val_mae: 0.1835 - lr: 5.0000e-07\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 6s 79ms/step - loss: 0.1904 - mae: 0.1716 - val_loss: 0.2034 - val_mae: 0.1859 - lr: 5.0000e-07\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 26ms/steploss: 0.1845 - mae: 0.16\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "75/75 [==============================] - 8s 105ms/step - loss: 0.1845 - mae: 0.1668 - val_loss: 0.1933 - val_mae: 0.1780 - lr: 5.0000e-07\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 7s 88ms/step - loss: 0.1790 - mae: 0.1624 - val_loss: 0.1813 - val_mae: 0.1681 - lr: 5.0000e-07\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 26ms/steploss: 0.1740 - mae: 0.15\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "75/75 [==============================] - 7s 98ms/step - loss: 0.1740 - mae: 0.1583 - val_loss: 0.1727 - val_mae: 0.1604 - lr: 5.0000e-07\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1694 - mae: 0.1547 - val_loss: 0.1658 - val_mae: 0.1538 - lr: 5.0000e-07\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 26ms/steploss: 0.1653 - mae: 0.15\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "75/75 [==============================] - 7s 98ms/step - loss: 0.1653 - mae: 0.1513 - val_loss: 0.1597 - val_mae: 0.1478 - lr: 5.0000e-07\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 7s 88ms/step - loss: 0.1616 - mae: 0.1483 - val_loss: 0.1568 - val_mae: 0.1444 - lr: 5.0000e-07\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 26ms/steploss: 0.1582 - mae: 0.14\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "75/75 [==============================] - 7s 100ms/step - loss: 0.1582 - mae: 0.1456 - val_loss: 0.1568 - val_mae: 0.1437 - lr: 5.0000e-07\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 6s 81ms/step - loss: 0.1551 - mae: 0.1431 - val_loss: 0.1570 - val_mae: 0.1435 - lr: 5.0000e-07\n",
      "단계 3 최종 결과:\n",
      "  - 훈련 손실: 0.1551\n",
      "  - 검증 손실: 0.1570\n",
      "  - 훈련 MAE: 0.1431\n",
      "  - 검증 MAE: 0.1435\n",
      "단계 3 모델 저장 완료: checkpoints/depth_model_stage3.h5\n",
      "\n",
      "==================== 학습 단계 4/5: 해상도 (240, 320) ====================\n",
      "현재 학습률: 2.00e-07\n",
      "데이터셋 생성 중... 대상 해상도: (240, 320)\n",
      "데이터셋 생성 중... 대상 해상도: (240, 320), Stage: 3\n",
      "로드된 샘플 수: 600\n",
      "데이터 전처리 시작\n",
      "최종 입력 데이터 형태: (600, 240, 320, 7)\n",
      "입력 데이터 범위:\n",
      "  RGB: 0.0 ~ 1.0\n",
      "  깊이: 0.0 ~ 1.0\n",
      "  MDE: 0.0 ~ 1.0\n",
      "  Sensor Confidence: 0.3 ~ 0.7\n",
      "  MDE Confidence: 0.7 ~ 0.7\n",
      "최종 타겟 데이터 형태: (600, 240, 320, 1)\n",
      "타겟 깊이 범위: 0.0 ~ 1.0\n",
      "데이터셋 생성 중... 대상 해상도: (240, 320), Stage: 3\n",
      "로드된 샘플 수: 200\n",
      "데이터 전처리 시작\n",
      "최종 입력 데이터 형태: (200, 240, 320, 7)\n",
      "입력 데이터 범위:\n",
      "  RGB: 0.0 ~ 1.0\n",
      "  깊이: 0.0 ~ 1.0\n",
      "  MDE: 0.0 ~ 1.0\n",
      "  Sensor Confidence: 0.3 ~ 0.7\n",
      "  MDE Confidence: 0.7 ~ 0.7\n",
      "최종 타겟 데이터 형태: (200, 240, 320, 1)\n",
      "타겟 깊이 범위: 0.0 ~ 1.0\n",
      "학습 데이터 배치 형태: 입력=(4, 240, 320, 7), 타겟=(4, 240, 320, 1)\n",
      "데이터셋 NaN/Inf 검사 중...\n",
      "학습 데이터셋에 NaN/Inf 값이 감지되지 않았습니다.\n",
      "검증 데이터셋에 NaN/Inf 값이 감지되지 않았습니다.\n",
      "모델 입력 차원: (240, 320, 7)\n",
      "개선된 가중치 전이 함수 실행 중...\n",
      "가중치 전이 성공! (일치하지 않는 레이어는 건너뜀)\n",
      "가중치 전이 성공\n",
      "Model: \"model_78\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_79 (InputLayer)       [(None, 240, 320, 7)]        0         []                            \n",
      "                                                                                                  \n",
      " lambda_2223 (Lambda)        (None, 240, 320, 3)          0         ['input_79[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_2448 (Conv2D)        (None, 240, 320, 32)         896       ['lambda_2223[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1158 (  (None, 240, 320, 32)         128       ['conv2d_2448[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1433 (Activatio  (None, 240, 320, 32)         0         ['batch_normalization_1158[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 32)                   0         ['activation_1433[0][0]']     \n",
      " 75 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_275 (  (None, 32)                   0         ['activation_1433[0][0]']     \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " lambda_2224 (Lambda)        (None, 240, 320, 1)          0         ['input_79[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_550 (Reshape)       (None, 1, 1, 32)             0         ['global_average_pooling2d_275\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_551 (Reshape)       (None, 1, 1, 32)             0         ['global_max_pooling2d_275[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " lambda_2226 (Lambda)        (None, 240, 320, 1)          0         ['input_79[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_2225 (Lambda)        (None, 240, 320, 1)          0         ['input_79[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_2227 (Lambda)        (None, 240, 320, 1)          0         ['input_79[0][0]']            \n",
      "                                                                                                  \n",
      " dense_550 (Dense)           (None, 1, 1, 4)              132       ['reshape_550[0][0]',         \n",
      "                                                                     'reshape_551[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_928 (Concatena  (None, 240, 320, 2)          0         ['lambda_2224[0][0]',         \n",
      " te)                                                                 'lambda_2226[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_931 (Concatena  (None, 240, 320, 2)          0         ['lambda_2225[0][0]',         \n",
      " te)                                                                 'lambda_2227[0][0]']         \n",
      "                                                                                                  \n",
      " dense_551 (Dense)           (None, 1, 1, 32)             160       ['dense_550[0][0]',           \n",
      "                                                                     'dense_550[1][0]']           \n",
      "                                                                                                  \n",
      " conv2d_2450 (Conv2D)        (None, 240, 320, 32)         608       ['concatenate_928[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2454 (Conv2D)        (None, 240, 320, 32)         608       ['concatenate_931[0][0]']     \n",
      "                                                                                                  \n",
      " add_606 (Add)               (None, 1, 1, 32)             0         ['dense_551[0][0]',           \n",
      "                                                                     'dense_551[1][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_1160 (  (None, 240, 320, 32)         128       ['conv2d_2450[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_1162 (  (None, 240, 320, 32)         128       ['conv2d_2454[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1434 (Activatio  (None, 1, 1, 32)             0         ['add_606[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " activation_1437 (Activatio  (None, 240, 320, 32)         0         ['batch_normalization_1160[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " activation_1439 (Activatio  (None, 240, 320, 32)         0         ['batch_normalization_1162[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " multiply_1100 (Multiply)    (None, 240, 320, 32)         0         ['activation_1433[0][0]',     \n",
      "                                                                     'activation_1434[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2231 (Lambda)        (None, 240, 320, 1)          0         ['activation_1437[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2232 (Lambda)        (None, 240, 320, 1)          0         ['activation_1437[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2235 (Lambda)        (None, 240, 320, 1)          0         ['activation_1439[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2236 (Lambda)        (None, 240, 320, 1)          0         ['activation_1439[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_541 (MaxPool  (None, 120, 160, 32)         0         ['multiply_1100[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_929 (Concatena  (None, 240, 320, 2)          0         ['lambda_2231[0][0]',         \n",
      " te)                                                                 'lambda_2232[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_932 (Concatena  (None, 240, 320, 2)          0         ['lambda_2235[0][0]',         \n",
      " te)                                                                 'lambda_2236[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2449 (Conv2D)        (None, 120, 160, 64)         18496     ['max_pooling2d_541[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_2451 (Conv2D)        (None, 240, 320, 1)          98        ['concatenate_929[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2455 (Conv2D)        (None, 240, 320, 1)          98        ['concatenate_932[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1159 (  (None, 120, 160, 64)         256       ['conv2d_2449[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multiply_1102 (Multiply)    (None, 240, 320, 32)         0         ['activation_1437[0][0]',     \n",
      "                                                                     'conv2d_2451[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1104 (Multiply)    (None, 240, 320, 32)         0         ['activation_1439[0][0]',     \n",
      "                                                                     'conv2d_2455[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1435 (Activatio  (None, 120, 160, 64)         0         ['batch_normalization_1159[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " max_pooling2d_543 (MaxPool  (None, 120, 160, 32)         0         ['multiply_1102[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_545 (MaxPool  (None, 120, 160, 32)         0         ['multiply_1104[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 64)                   0         ['activation_1435[0][0]']     \n",
      " 76 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_276 (  (None, 64)                   0         ['activation_1435[0][0]']     \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2452 (Conv2D)        (None, 120, 160, 64)         18496     ['max_pooling2d_543[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_2456 (Conv2D)        (None, 120, 160, 64)         18496     ['max_pooling2d_545[0][0]']   \n",
      "                                                                                                  \n",
      " reshape_552 (Reshape)       (None, 1, 1, 64)             0         ['global_average_pooling2d_276\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_553 (Reshape)       (None, 1, 1, 64)             0         ['global_max_pooling2d_276[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization_1161 (  (None, 120, 160, 64)         256       ['conv2d_2452[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_1163 (  (None, 120, 160, 64)         256       ['conv2d_2456[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_552 (Dense)           (None, 1, 1, 8)              520       ['reshape_552[0][0]',         \n",
      "                                                                     'reshape_553[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1438 (Activatio  (None, 120, 160, 64)         0         ['batch_normalization_1161[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " activation_1440 (Activatio  (None, 120, 160, 64)         0         ['batch_normalization_1163[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " subtract_55 (Subtract)      (None, 240, 320, 1)          0         ['lambda_2224[0][0]',         \n",
      "                                                                     'lambda_2225[0][0]']         \n",
      "                                                                                                  \n",
      " dense_553 (Dense)           (None, 1, 1, 64)             576       ['dense_552[0][0]',           \n",
      "                                                                     'dense_552[1][0]']           \n",
      "                                                                                                  \n",
      " lambda_2233 (Lambda)        (None, 120, 160, 1)          0         ['activation_1438[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2234 (Lambda)        (None, 120, 160, 1)          0         ['activation_1438[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2237 (Lambda)        (None, 120, 160, 1)          0         ['activation_1440[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2238 (Lambda)        (None, 120, 160, 1)          0         ['activation_1440[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2458 (Conv2D)        (None, 240, 320, 32)         320       ['subtract_55[0][0]']         \n",
      "                                                                                                  \n",
      " add_607 (Add)               (None, 1, 1, 64)             0         ['dense_553[0][0]',           \n",
      "                                                                     'dense_553[1][0]']           \n",
      "                                                                                                  \n",
      " concatenate_930 (Concatena  (None, 120, 160, 2)          0         ['lambda_2233[0][0]',         \n",
      " te)                                                                 'lambda_2234[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_933 (Concatena  (None, 120, 160, 2)          0         ['lambda_2237[0][0]',         \n",
      " te)                                                                 'lambda_2238[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1164 (  (None, 240, 320, 32)         128       ['conv2d_2458[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_1436 (Activatio  (None, 1, 1, 64)             0         ['add_607[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2453 (Conv2D)        (None, 120, 160, 1)          98        ['concatenate_930[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2457 (Conv2D)        (None, 120, 160, 1)          98        ['concatenate_933[0][0]']     \n",
      "                                                                                                  \n",
      " activation_1441 (Activatio  (None, 240, 320, 32)         0         ['batch_normalization_1164[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " multiply_1101 (Multiply)    (None, 120, 160, 64)         0         ['activation_1435[0][0]',     \n",
      "                                                                     'activation_1436[0][0]']     \n",
      "                                                                                                  \n",
      " multiply_1103 (Multiply)    (None, 120, 160, 64)         0         ['activation_1438[0][0]',     \n",
      "                                                                     'conv2d_2453[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1105 (Multiply)    (None, 120, 160, 64)         0         ['activation_1440[0][0]',     \n",
      "                                                                     'conv2d_2457[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling2d_547 (MaxPool  (None, 120, 160, 32)         0         ['activation_1441[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2459 (Conv2D)        (None, 120, 160, 64)         18496     ['max_pooling2d_547[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_2468 (Conv2D)        (None, 120, 160, 64)         4160      ['multiply_1101[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2469 (Conv2D)        (None, 120, 160, 64)         4160      ['multiply_1103[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2470 (Conv2D)        (None, 120, 160, 64)         4160      ['multiply_1105[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1165 (  (None, 120, 160, 64)         256       ['conv2d_2459[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " concatenate_936 (Concatena  (None, 120, 160, 192)        0         ['conv2d_2468[0][0]',         \n",
      " te)                                                                 'conv2d_2469[0][0]',         \n",
      "                                                                     'conv2d_2470[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1442 (Activatio  (None, 120, 160, 64)         0         ['batch_normalization_1165[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2d_2471 (Conv2D)        (None, 120, 160, 64)         110656    ['concatenate_936[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_542 (MaxPool  (None, 60, 80, 64)           0         ['multiply_1101[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_544 (MaxPool  (None, 60, 80, 64)           0         ['multiply_1103[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_546 (MaxPool  (None, 60, 80, 64)           0         ['multiply_1105[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_548 (MaxPool  (None, 60, 80, 64)           0         ['activation_1442[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_1167 (  (None, 120, 160, 64)         256       ['conv2d_2471[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " concatenate_938 (Concatena  (None, 60, 80, 256)          0         ['max_pooling2d_542[0][0]',   \n",
      " te)                                                                 'max_pooling2d_544[0][0]',   \n",
      "                                                                     'max_pooling2d_546[0][0]',   \n",
      "                                                                     'max_pooling2d_548[0][0]']   \n",
      "                                                                                                  \n",
      " activation_1445 (Activatio  (None, 120, 160, 64)         0         ['batch_normalization_1167[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 256)                  0         ['concatenate_938[0][0]']     \n",
      " 79 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_279 (  (None, 256)                  0         ['concatenate_938[0][0]']     \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2472 (Conv2D)        (None, 120, 160, 3)          195       ['activation_1445[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2460 (Conv2D)        (None, 240, 320, 32)         1056      ['multiply_1100[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2461 (Conv2D)        (None, 240, 320, 32)         1056      ['multiply_1102[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2462 (Conv2D)        (None, 240, 320, 32)         1056      ['multiply_1104[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_558 (Reshape)       (None, 1, 1, 256)            0         ['global_average_pooling2d_279\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_559 (Reshape)       (None, 1, 1, 256)            0         ['global_max_pooling2d_279[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " lambda_2247 (Lambda)        (None, 120, 160, 1)          0         ['conv2d_2472[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2248 (Lambda)        (None, 120, 160, 1)          0         ['conv2d_2472[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2249 (Lambda)        (None, 120, 160, 1)          0         ['conv2d_2472[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_934 (Concatena  (None, 240, 320, 96)         0         ['conv2d_2460[0][0]',         \n",
      " te)                                                                 'conv2d_2461[0][0]',         \n",
      "                                                                     'conv2d_2462[0][0]']         \n",
      "                                                                                                  \n",
      " dense_558 (Dense)           (None, 1, 1, 32)             8224      ['reshape_558[0][0]',         \n",
      "                                                                     'reshape_559[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2250 (Lambda)        (None, 120, 160, 64)         0         ['lambda_2247[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2251 (Lambda)        (None, 120, 160, 64)         0         ['lambda_2248[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2252 (Lambda)        (None, 120, 160, 64)         0         ['lambda_2249[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2463 (Conv2D)        (None, 240, 320, 32)         27680     ['concatenate_934[0][0]']     \n",
      "                                                                                                  \n",
      " dense_559 (Dense)           (None, 1, 1, 256)            8448      ['dense_558[0][0]',           \n",
      "                                                                     'dense_558[1][0]']           \n",
      "                                                                                                  \n",
      " multiply_1111 (Multiply)    (None, 120, 160, 64)         0         ['conv2d_2468[0][0]',         \n",
      "                                                                     'lambda_2250[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1112 (Multiply)    (None, 120, 160, 64)         0         ['conv2d_2469[0][0]',         \n",
      "                                                                     'lambda_2251[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1113 (Multiply)    (None, 120, 160, 64)         0         ['conv2d_2470[0][0]',         \n",
      "                                                                     'lambda_2252[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1166 (  (None, 240, 320, 32)         128       ['conv2d_2463[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " add_614 (Add)               (None, 1, 1, 256)            0         ['dense_559[0][0]',           \n",
      "                                                                     'dense_559[1][0]']           \n",
      "                                                                                                  \n",
      " add_611 (Add)               (None, 120, 160, 64)         0         ['multiply_1111[0][0]',       \n",
      "                                                                     'multiply_1112[0][0]',       \n",
      "                                                                     'multiply_1113[0][0]']       \n",
      "                                                                                                  \n",
      " activation_1443 (Activatio  (None, 240, 320, 32)         0         ['batch_normalization_1166[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " activation_1447 (Activatio  (None, 1, 1, 256)            0         ['add_614[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 64)                   0         ['add_611[0][0]']             \n",
      " 78 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_278 (  (None, 64)                   0         ['add_611[0][0]']             \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2464 (Conv2D)        (None, 240, 320, 3)          99        ['activation_1443[0][0]']     \n",
      "                                                                                                  \n",
      " multiply_1116 (Multiply)    (None, 60, 80, 256)          0         ['concatenate_938[0][0]',     \n",
      "                                                                     'activation_1447[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_556 (Reshape)       (None, 1, 1, 64)             0         ['global_average_pooling2d_278\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_557 (Reshape)       (None, 1, 1, 64)             0         ['global_max_pooling2d_278[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " lambda_2239 (Lambda)        (None, 240, 320, 1)          0         ['conv2d_2464[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2240 (Lambda)        (None, 240, 320, 1)          0         ['conv2d_2464[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2241 (Lambda)        (None, 240, 320, 1)          0         ['conv2d_2464[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2255 (Lambda)        (None, 60, 80, 1)            0         ['multiply_1116[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_2256 (Lambda)        (None, 60, 80, 1)            0         ['multiply_1116[0][0]']       \n",
      "                                                                                                  \n",
      " dense_556 (Dense)           (None, 1, 1, 8)              520       ['reshape_556[0][0]',         \n",
      "                                                                     'reshape_557[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2242 (Lambda)        (None, 240, 320, 32)         0         ['lambda_2239[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2243 (Lambda)        (None, 240, 320, 32)         0         ['lambda_2240[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2244 (Lambda)        (None, 240, 320, 32)         0         ['lambda_2241[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_939 (Concatena  (None, 60, 80, 2)            0         ['lambda_2255[0][0]',         \n",
      " te)                                                                 'lambda_2256[0][0]']         \n",
      "                                                                                                  \n",
      " dense_557 (Dense)           (None, 1, 1, 64)             576       ['dense_556[0][0]',           \n",
      "                                                                     'dense_556[1][0]']           \n",
      "                                                                                                  \n",
      " multiply_1106 (Multiply)    (None, 240, 320, 32)         0         ['conv2d_2460[0][0]',         \n",
      "                                                                     'lambda_2242[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1107 (Multiply)    (None, 240, 320, 32)         0         ['conv2d_2461[0][0]',         \n",
      "                                                                     'lambda_2243[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1108 (Multiply)    (None, 240, 320, 32)         0         ['conv2d_2462[0][0]',         \n",
      "                                                                     'lambda_2244[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2476 (Conv2D)        (None, 60, 80, 1)            98        ['concatenate_939[0][0]']     \n",
      "                                                                                                  \n",
      " add_612 (Add)               (None, 1, 1, 64)             0         ['dense_557[0][0]',           \n",
      "                                                                     'dense_557[1][0]']           \n",
      "                                                                                                  \n",
      " add_608 (Add)               (None, 240, 320, 32)         0         ['multiply_1106[0][0]',       \n",
      "                                                                     'multiply_1107[0][0]',       \n",
      "                                                                     'multiply_1108[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_1117 (Multiply)    (None, 60, 80, 256)          0         ['multiply_1116[0][0]',       \n",
      "                                                                     'conv2d_2476[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1446 (Activatio  (None, 1, 1, 64)             0         ['add_612[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 32)                   0         ['add_608[0][0]']             \n",
      " 77 (GlobalAveragePooling2D                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_277 (  (None, 32)                   0         ['add_608[0][0]']             \n",
      " GlobalMaxPooling2D)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2477 (Conv2D)        (None, 60, 80, 256)          590080    ['multiply_1117[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_1114 (Multiply)    (None, 120, 160, 64)         0         ['add_611[0][0]',             \n",
      "                                                                     'activation_1446[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_554 (Reshape)       (None, 1, 1, 32)             0         ['global_average_pooling2d_277\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " reshape_555 (Reshape)       (None, 1, 1, 32)             0         ['global_max_pooling2d_277[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization_1168 (  (None, 60, 80, 256)          1024      ['conv2d_2477[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " lambda_2253 (Lambda)        (None, 120, 160, 1)          0         ['multiply_1114[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_2254 (Lambda)        (None, 120, 160, 1)          0         ['multiply_1114[0][0]']       \n",
      "                                                                                                  \n",
      " dense_554 (Dense)           (None, 1, 1, 4)              132       ['reshape_554[0][0]',         \n",
      "                                                                     'reshape_555[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1448 (Activatio  (None, 60, 80, 256)          0         ['batch_normalization_1168[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " concatenate_937 (Concatena  (None, 120, 160, 2)          0         ['lambda_2253[0][0]',         \n",
      " te)                                                                 'lambda_2254[0][0]']         \n",
      "                                                                                                  \n",
      " dense_555 (Dense)           (None, 1, 1, 32)             160       ['dense_554[0][0]',           \n",
      "                                                                     'dense_554[1][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_156 (UpSampl  (None, 120, 160, 256)        0         ['activation_1448[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2473 (Conv2D)        (None, 120, 160, 1)          98        ['concatenate_937[0][0]']     \n",
      "                                                                                                  \n",
      " add_609 (Add)               (None, 1, 1, 32)             0         ['dense_555[0][0]',           \n",
      "                                                                     'dense_555[1][0]']           \n",
      "                                                                                                  \n",
      " conv2d_2478 (Conv2D)        (None, 120, 160, 128)        295040    ['up_sampling2d_156[0][0]']   \n",
      "                                                                                                  \n",
      " multiply_1115 (Multiply)    (None, 120, 160, 64)         0         ['multiply_1114[0][0]',       \n",
      "                                                                     'conv2d_2473[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1444 (Activatio  (None, 1, 1, 32)             0         ['add_609[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_926 (Concatena  (None, 240, 320, 2)          0         ['lambda_2226[0][0]',         \n",
      " te)                                                                 'lambda_2227[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1169 (  (None, 120, 160, 128)        512       ['conv2d_2478[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2475 (Conv2D)        (None, 120, 160, 64)         12352     ['concatenate_936[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2474 (Conv2D)        (None, 120, 160, 64)         4160      ['multiply_1115[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_1109 (Multiply)    (None, 240, 320, 32)         0         ['add_608[0][0]',             \n",
      "                                                                     'activation_1444[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_927 (Concatena  (None, 240, 320, 7)          0         ['lambda_2223[0][0]',         \n",
      " te)                                                                 'lambda_2224[0][0]',         \n",
      "                                                                     'lambda_2225[0][0]',         \n",
      "                                                                     'concatenate_926[0][0]']     \n",
      "                                                                                                  \n",
      " activation_1449 (Activatio  (None, 120, 160, 128)        0         ['batch_normalization_1169[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " add_613 (Add)               (None, 120, 160, 64)         0         ['conv2d_2475[0][0]',         \n",
      "                                                                     'conv2d_2474[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2245 (Lambda)        (None, 240, 320, 1)          0         ['multiply_1109[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_2246 (Lambda)        (None, 240, 320, 1)          0         ['multiply_1109[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2444 (Conv2D)        (None, 240, 320, 16)         1024      ['concatenate_927[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_940 (Concatena  (None, 120, 160, 192)        0         ['activation_1449[0][0]',     \n",
      " te)                                                                 'add_613[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_935 (Concatena  (None, 240, 320, 2)          0         ['lambda_2245[0][0]',         \n",
      " te)                                                                 'lambda_2246[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1156 (  (None, 240, 320, 16)         64        ['conv2d_2444[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " up_sampling2d_157 (UpSampl  (None, 240, 320, 192)        0         ['concatenate_940[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2465 (Conv2D)        (None, 240, 320, 1)          98        ['concatenate_935[0][0]']     \n",
      "                                                                                                  \n",
      " activation_1431 (Activatio  (None, 240, 320, 16)         0         ['batch_normalization_1156[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2d_2479 (Conv2D)        (None, 240, 320, 64)         110656    ['up_sampling2d_157[0][0]']   \n",
      "                                                                                                  \n",
      " multiply_1110 (Multiply)    (None, 240, 320, 32)         0         ['multiply_1109[0][0]',       \n",
      "                                                                     'conv2d_2465[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2445 (Conv2D)        (None, 240, 320, 8)          1160      ['activation_1431[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2447 (Conv2D)        (None, 240, 320, 1)          10        ['lambda_2224[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1170 (  (None, 240, 320, 64)         256       ['conv2d_2479[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " conv2d_2467 (Conv2D)        (None, 240, 320, 32)         3104      ['concatenate_934[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2466 (Conv2D)        (None, 240, 320, 32)         1056      ['multiply_1110[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1157 (  (None, 240, 320, 8)          32        ['conv2d_2445[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " lambda_2228 (Lambda)        (None, 240, 320, 1)          0         ['conv2d_2447[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1450 (Activatio  (None, 240, 320, 64)         0         ['batch_normalization_1170[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " add_610 (Add)               (None, 240, 320, 32)         0         ['conv2d_2467[0][0]',         \n",
      "                                                                     'conv2d_2466[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1432 (Activatio  (None, 240, 320, 8)          0         ['batch_normalization_1157[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " lambda_2229 (Lambda)        (None, 240, 320, 1)          0         ['lambda_2228[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_941 (Concatena  (None, 240, 320, 96)         0         ['activation_1450[0][0]',     \n",
      " te)                                                                 'add_610[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_2446 (Conv2D)        (None, 240, 320, 1)          73        ['activation_1432[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_55 (TFOpL  (None, 240, 320, 1)          0         ['lambda_2229[0][0]']         \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2480 (Conv2D)        (None, 240, 320, 32)         27680     ['concatenate_941[0][0]']     \n",
      "                                                                                                  \n",
      " add_605 (Add)               (None, 240, 320, 1)          0         ['conv2d_2446[0][0]',         \n",
      "                                                                     'tf.math.multiply_55[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_1171 (  (None, 240, 320, 32)         128       ['conv2d_2480[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " lambda_2230 (Lambda)        (None, 240, 320, 1)          0         ['add_605[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1451 (Activatio  (None, 240, 320, 32)         0         ['batch_normalization_1171[0][\n",
      " n)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " lambda_2257 (Lambda)        (None, 240, 320, 32)         0         ['lambda_2230[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1118 (Multiply)    (None, 240, 320, 32)         0         ['activation_1451[0][0]',     \n",
      "                                                                     'lambda_2257[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_2481 (Conv2D)        (None, 240, 320, 1)          289       ['multiply_1118[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2482 (Conv2D)        (None, 240, 320, 1)          289       ['activation_1451[0][0]']     \n",
      "                                                                                                  \n",
      " lambda_2259 (Lambda)        (None, 240, 320, 1)          0         ['lambda_2224[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2258 (Lambda)        (None, 240, 320, 1)          0         ['conv2d_2481[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_2261 (Lambda)        (None, 240, 320, 1)          0         ['lambda_2224[0][0]',         \n",
      "                                                                     'conv2d_2482[0][0]',         \n",
      "                                                                     'lambda_2226[0][0]',         \n",
      "                                                                     'lambda_2259[0][0]',         \n",
      "                                                                     'lambda_2225[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1119 (Multiply)    (None, 240, 320, 1)          0         ['lambda_2258[0][0]',         \n",
      "                                                                     'lambda_2230[0][0]']         \n",
      "                                                                                                  \n",
      " add_615 (Add)               (None, 240, 320, 1)          0         ['lambda_2261[0][0]',         \n",
      "                                                                     'multiply_1119[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_2262 (Lambda)        (None, 240, 320, 1)          0         ['add_615[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1301737 (4.97 MB)\n",
      "Trainable params: 1299769 (4.96 MB)\n",
      "Non-trainable params: 1968 (7.69 KB)\n",
      "__________________________________________________________________________________________________\n",
      "학습 시작: 단계 4, 해상도 (240, 320), 에폭 8\n",
      "Epoch 1/8\n",
      "  6/150 [>.............................] - ETA: 26s - loss: 0.1751 - mae: 0.1614WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0920s vs `on_train_batch_end` time: 0.0996s). Check your callbacks.\n",
      "1/1 [==============================] - 1s 823ms/step loss: 0.1819 - mae: 0.16\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "150/150 [==============================] - 50s 224ms/step - loss: 0.1819 - mae: 0.1694 - val_loss: 0.1850 - val_mae: 0.1759 - lr: 2.0000e-07\n",
      "Epoch 2/8\n",
      "150/150 [==============================] - 31s 209ms/step - loss: 0.1781 - mae: 0.1664 - val_loss: 0.1827 - val_mae: 0.1740 - lr: 2.0000e-07\n",
      "Epoch 3/8\n",
      "1/1 [==============================] - 0s 31ms/step- loss: 0.1744 - mae: 0.16\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "150/150 [==============================] - 32s 214ms/step - loss: 0.1744 - mae: 0.1634 - val_loss: 0.1810 - val_mae: 0.1706 - lr: 2.0000e-07\n",
      "Epoch 4/8\n",
      "150/150 [==============================] - 31s 206ms/step - loss: 0.1709 - mae: 0.1606 - val_loss: 0.1785 - val_mae: 0.1666 - lr: 2.0000e-07\n",
      "Epoch 5/8\n",
      "1/1 [==============================] - 0s 30ms/step- loss: 0.1675 - mae: 0.15\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "150/150 [==============================] - 32s 212ms/step - loss: 0.1675 - mae: 0.1579 - val_loss: 0.1758 - val_mae: 0.1635 - lr: 2.0000e-07\n",
      "Epoch 6/8\n",
      "150/150 [==============================] - 34s 226ms/step - loss: 0.1642 - mae: 0.1552 - val_loss: 0.1729 - val_mae: 0.1608 - lr: 2.0000e-07\n",
      "Epoch 7/8\n",
      "1/1 [==============================] - 0s 36ms/step- loss: 0.1610 - mae: 0.15\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "150/150 [==============================] - 32s 215ms/step - loss: 0.1610 - mae: 0.1527 - val_loss: 0.1697 - val_mae: 0.1582 - lr: 2.0000e-07\n",
      "Epoch 8/8\n",
      "150/150 [==============================] - 31s 209ms/step - loss: 0.1579 - mae: 0.1502 - val_loss: 0.1664 - val_mae: 0.1555 - lr: 2.0000e-07\n",
      "단계 4 최종 결과:\n",
      "  - 훈련 손실: 0.1579\n",
      "  - 검증 손실: 0.1664\n",
      "  - 훈련 MAE: 0.1502\n",
      "  - 검증 MAE: 0.1555\n",
      "단계 4 모델 저장 완료: checkpoints/depth_model_stage4.h5\n",
      "✅ 학습 메트릭 시각화가 저장되었습니다: visualizations/training_metrics.png\n",
      "✅ 최종 모델이 저장되었습니다: depth_correction_model_final.h5\n",
      "\n",
      "===== 최종 모델 평가 =====\n",
      "데이터셋 생성 중... 대상 해상도: (480, 640), Stage: 4\n",
      "로드된 샘플 수: 200\n",
      "데이터 전처리 시작\n",
      "최종 입력 데이터 형태: (200, 480, 640, 7)\n",
      "입력 데이터 범위:\n",
      "  RGB: 0.0 ~ 1.0\n",
      "  깊이: 0.0 ~ 1.0\n",
      "  MDE: 0.0 ~ 1.0\n",
      "  Sensor Confidence: 0.3 ~ 0.7\n",
      "  MDE Confidence: 0.7 ~ 0.7\n",
      "최종 타겟 데이터 형태: (200, 480, 640, 1)\n",
      "타겟 깊이 범위: 0.0 ~ 1.0\n",
      "100/100 [==============================] - 12s 94ms/step - loss: 0.1506 - mae: 0.1484\n",
      "테스트 손실: 0.1506, MAE: 0.1484\n",
      "테스트 데이터셋 디버깅:\n",
      "입력 데이터 형태: (2, 480, 640, 7)\n",
      "타겟 데이터 형태: (2, 480, 640, 1)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "예측 결과 형태: (2, 480, 640, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_322296/2693354063.py:1915: RuntimeWarning: divide by zero encountered in divide\n",
      "  max_ratio = np.maximum(ratio, 1/ratio)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n",
      "예측 결과 형태: (2, 480, 640, 1)\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "예측 결과 형태: (2, 480, 640, 1)\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "예측 결과 형태: (2, 480, 640, 1)\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "예측 결과 형태: (2, 480, 640, 1)\n",
      "\n",
      "===== 깊이 보정 성능 평가 =====\n",
      "RMSE: 0.1638 ± 0.0605\n",
      "MAE: 0.1468 ± 0.0638\n",
      "상대 오차: 2.4792 ± 1.5981\n",
      "델타(δ) < 1.25: 0.2502 ± 0.2381\n",
      "델타(δ) < 1.25²: 0.6258 ± 0.1993\n",
      "델타(δ) < 1.25³: 0.8645 ± 0.0851\n",
      "✅ 테스트 결과가 저장되었습니다: test_results/test_metrics.txt\n",
      "✅ 모델 학습 완료!\n",
      "✅ 최종 모델이 저장되었습니다: depth_correction_model_final.h5\n",
      "\n",
      "테스트 데이터셋 생성 중...\n",
      "데이터셋 생성 중... 대상 해상도: (480, 640), Stage: 3\n",
      "로드된 샘플 수: 200\n",
      "데이터 전처리 시작\n",
      "최종 입력 데이터 형태: (200, 480, 640, 7)\n",
      "입력 데이터 범위:\n",
      "  RGB: 0.0 ~ 1.0\n",
      "  깊이: 0.0 ~ 1.0\n",
      "  MDE: 0.0 ~ 1.0\n",
      "  Sensor Confidence: 0.3 ~ 0.7\n",
      "  MDE Confidence: 0.7 ~ 0.7\n",
      "최종 타겟 데이터 형태: (200, 480, 640, 1)\n",
      "타겟 깊이 범위: 0.0 ~ 1.0\n",
      "\n",
      "===== 최종 모델 평가 =====\n",
      "25/25 [==============================] - 37s 350ms/step - loss: 0.1506 - mae: 0.1484\n",
      "테스트 손실: 0.1506, MAE: 0.1484\n",
      "테스트 데이터셋 디버깅:\n",
      "입력 데이터 형태: (8, 480, 640, 7)\n",
      "타겟 데이터 형태: (8, 480, 640, 1)\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "예측 결과 형태: (8, 480, 640, 1)\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "예측 결과 형태: (8, 480, 640, 1)\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "예측 결과 형태: (8, 480, 640, 1)\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "예측 결과 형태: (8, 480, 640, 1)\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "예측 결과 형태: (8, 480, 640, 1)\n",
      "\n",
      "===== 깊이 보정 성능 평가 =====\n",
      "RMSE: 0.1392 ± 0.0458\n",
      "MAE: 0.1222 ± 0.0486\n",
      "상대 오차: 4.4459 ± 5.6190\n",
      "델타(δ) < 1.25: 0.3096 ± 0.2035\n",
      "델타(δ) < 1.25²: 0.6747 ± 0.1804\n",
      "델타(δ) < 1.25³: 0.8846 ± 0.0667\n",
      "\n",
      "⏱️ 총 학습 시간: 0시간 9분 49초\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input, mixed_precision\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Activation, Add, Multiply, Concatenate\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter, map_coordinates, median_filter, sobel, binary_dilation, distance_transform_edt\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# ✅ TensorFlow GPU 활성화 (변경 없음)\n",
    "# GPU 메모리 사용량 제한\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # 두 설정 중 하나만 선택해야 합니다\n",
    "        # 옵션 1: 메모리 성장 설정\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✅ GPU 메모리 성장 설정 완료!\")\n",
    "        \n",
    "        # 옵션 2: 메모리 제한 설정 (위 설정과 함께 사용 불가)\n",
    "        # for gpu in gpus:\n",
    "        #     tf.config.experimental.set_virtual_device_configuration(\n",
    "        #         gpu,\n",
    "        #         [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)]\n",
    "        #     )\n",
    "        # print(\"✅ GPU 메모리 제한 설정 완료!\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"⚠️ GPU를 사용할 수 없습니다. CPU 모드로 실행됩니다.\")\n",
    "\n",
    "# ✅ 학습 결과 저장 디렉토리 생성 (변경 없음)\n",
    "if not os.path.exists('checkpoints'):\n",
    "    os.makedirs('checkpoints')\n",
    "\n",
    "# ✅ 시각화 결과 저장 디렉토리 추가\n",
    "if not os.path.exists('visualizations'):\n",
    "    os.makedirs('visualizations')\n",
    "\n",
    "# ✅ 코드 맨 앞에 추가 (변경 없음)\n",
    "tf.config.run_functions_eagerly(False)\n",
    "\n",
    "\n",
    "def convert_mde_image_to_depth(mde_image_path):\n",
    "    \"\"\"\n",
    "    MDE 시각화 이미지를 깊이 정보로 변환\n",
    "    \n",
    "    Parameters:\n",
    "    - mde_image_path: MDE 시각화 이미지 경로\n",
    "    \n",
    "    Returns:\n",
    "    - 깊이 정보 배열 (float32)\n",
    "    \"\"\"\n",
    "    # 그레이스케일로 이미지 로드\n",
    "    mde_vis = cv2.imread(mde_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if mde_vis is None:\n",
    "        print(f\"❌ 이미지를 로드할 수 없습니다: {mde_image_path}\")\n",
    "        return None\n",
    "    \n",
    "    # 0-255 범위의 그레이스케일 이미지를 깊이 값으로 정규화\n",
    "    # 예: 0-255 값을 0-10m(미터) 범위로 변환\n",
    "    depth = mde_vis.astype(np.float32) / 255.0 * 10000.0\n",
    "    \n",
    "    return depth\n",
    "\n",
    "def load_paired_data_from_existing_files(rgb_dir, depth_array_dir, depth_image_dir, mde_dir, max_samples):\n",
    "    # 파일 목록 생성\n",
    "    rgb_files = sorted([f for f in os.listdir(rgb_dir) if f.startswith('color_') and f.endswith('.png')])\n",
    "    depth_array_files = sorted([f for f in os.listdir(depth_array_dir) if f.startswith('depth_') and f.endswith('.npy')])\n",
    "    depth_image_files = sorted([f for f in os.listdir(depth_image_dir) if f.startswith('depth_') and f.endswith('.png')])\n",
    "    \n",
    "    mde_npy_files = sorted([f for f in os.listdir(mde_dir) if f.endswith('_depth.npy')])\n",
    "    mde_png_files = sorted([f for f in os.listdir(mde_dir) if f.endswith('_depth_vis.png')])\n",
    "\n",
    "    print(f\"📊 Found files: RGB {len(rgb_files)}, Depth Array {len(depth_array_files)}, Depth Image {len(depth_image_files)}\")\n",
    "    print(f\"MDE NPY {len(mde_npy_files)}, MDE PNG {len(mde_png_files)}\")\n",
    "\n",
    "    # 타임스탬프 딕셔너리 생성\n",
    "    timestamp_dict = {}\n",
    "    \n",
    "    # RGB 파일 처리\n",
    "    for rgb_file in rgb_files:\n",
    "        try:\n",
    "            # 파일명에서 타임스탬프 추출 (color_20250314_154240.png)\n",
    "            timestamp = rgb_file.replace('color_', '').replace('.png', '')\n",
    "            \n",
    "            timestamp_dict[timestamp] = {\n",
    "                'rgb_file': rgb_file,\n",
    "                'has_rgb': True,\n",
    "                'depth_array_file': f'depth_{timestamp}.npy',\n",
    "                'depth_image_file': f'depth_{timestamp}.png',\n",
    "                'mde_npy_file': f'color_{timestamp}_depth.npy',\n",
    "                'mde_png_file': f'color_{timestamp}_depth_vis.png'\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ RGB 파일 처리 중 오류: {rgb_file}, {e}\")\n",
    "    \n",
    "    # 깊이 파일 처리\n",
    "    for depth_file in depth_array_files + depth_image_files:\n",
    "        try:\n",
    "            # 파일명에서 타임스탬프 추출 (depth_20250314_154240.npy 또는 depth_20250314_154240.png)\n",
    "            timestamp = depth_file.replace('depth_', '').replace('.npy', '').replace('.png', '')\n",
    "            \n",
    "            if timestamp in timestamp_dict:\n",
    "                timestamp_dict[timestamp]['depth_valid'] = True\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 깊이 파일 처리 중 오류: {depth_file}, {e}\")\n",
    "    \n",
    "    # MDE 파일 처리\n",
    "    for mde_file in mde_npy_files + mde_png_files:\n",
    "        try:\n",
    "            # 파일명에서 타임스탬프 추출 (color_20250314_154240_depth.npy 또는 color_20250314_154240_depth_vis.png)\n",
    "            timestamp = mde_file.split('_depth')[0].replace('color_', '')\n",
    "            \n",
    "            if timestamp in timestamp_dict:\n",
    "                timestamp_dict[timestamp]['mde_valid'] = True\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ MDE 파일 처리 중 오류: {mde_file}, {e}\")\n",
    "    \n",
    "    # 유효한 타임스탬프 수집\n",
    "    valid_timestamps = [\n",
    "        ts for ts, info in timestamp_dict.items() \n",
    "        if info.get('has_rgb', False) and \n",
    "           info.get('depth_valid', False) and \n",
    "           info.get('mde_valid', False)\n",
    "    ]\n",
    "    \n",
    "    print(f\"✅ 매칭된 타임스탬프: {len(valid_timestamps)}\")\n",
    "    \n",
    "    # 샘플 수 제한\n",
    "    valid_timestamps = valid_timestamps[:max_samples]\n",
    "    \n",
    "    # 데이터 저장 리스트\n",
    "    rgb_images = []\n",
    "    depth_maps = []\n",
    "    mde_maps = []\n",
    "    \n",
    "    # 매칭된 타임스탬프로 데이터 로드\n",
    "    for timestamp in valid_timestamps:\n",
    "        try:\n",
    "            info = timestamp_dict[timestamp]\n",
    "            \n",
    "            # RGB 이미지 로드\n",
    "            rgb_path = os.path.join(rgb_dir, info['rgb_file'])\n",
    "            rgb = cv2.imread(rgb_path)\n",
    "            if rgb is None:\n",
    "                print(f\"❌ RGB 이미지 로드 실패: {rgb_path}\")\n",
    "                continue\n",
    "            rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # 깊이 맵 로드 (NPY 파일 우선)\n",
    "            depth_npy_path = os.path.join(depth_array_dir, f'depth_{timestamp}.npy')\n",
    "            depth_png_path = os.path.join(depth_image_dir, f'depth_{timestamp}.png')\n",
    "            \n",
    "            if os.path.exists(depth_npy_path):\n",
    "                depth = np.load(depth_npy_path)\n",
    "            else:\n",
    "                depth = cv2.imread(depth_png_path, cv2.IMREAD_ANYDEPTH)\n",
    "            \n",
    "            # MDE 데이터 로드 (NPY 파일 우선)\n",
    "            mde_npy_path = os.path.join(mde_dir, f'color_{timestamp}_depth.npy')\n",
    "            \n",
    "            if os.path.exists(mde_npy_path):\n",
    "                mde = np.load(mde_npy_path)\n",
    "            else:\n",
    "                # PNG 파일을 깊이로 변환\n",
    "                mde_png_path = os.path.join(mde_dir, f'color_{timestamp}_depth_vis.png')\n",
    "                mde = convert_mde_image_to_depth(mde_png_path)\n",
    "            \n",
    "            # 데이터 추가\n",
    "            rgb_images.append(rgb)\n",
    "            depth_maps.append(depth)\n",
    "            mde_maps.append(mde)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 타임스탬프 {timestamp} 처리 중 오류: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    print(f\"✅ 총 로드된 샘플: {len(rgb_images)}\")\n",
    "    \n",
    "    # NumPy 배열로 변환\n",
    "    if len(rgb_images) > 0:\n",
    "        return (\n",
    "            np.array(rgb_images), \n",
    "            np.array(depth_maps), \n",
    "            np.array(mde_maps)\n",
    "        )\n",
    "    else:\n",
    "        print(\"❌ 유효한 샘플 없음!\")\n",
    "        return None\n",
    "\n",
    "def safe_load_image(path, color_conversion=cv2.COLOR_BGR2RGB):\n",
    "    \"\"\"안전한 이미지 로딩\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"❌ 이미지 로드 실패: {path}\")\n",
    "            return None\n",
    "        return cv2.cvtColor(img, color_conversion)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 이미지 로드 중 오류: {path}, {e}\")\n",
    "        return None\n",
    "\n",
    "def safe_load_depth(path, is_npy=False):\n",
    "    \"\"\"안전한 깊이 데이터 로딩\"\"\"\n",
    "    try:\n",
    "        if is_npy:\n",
    "            depth = np.load(path)\n",
    "        else:\n",
    "            depth = cv2.imread(path, cv2.IMREAD_ANYDEPTH)\n",
    "        \n",
    "        if depth is None:\n",
    "            print(f\"❌ 깊이 데이터 로드 실패: {path}\")\n",
    "            return None\n",
    "        return depth\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 깊이 데이터 로드 중 오류: {path}, {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_timestamp_safely(filename):\n",
    "    \"\"\"안전한 타임스탬프 추출\"\"\"\n",
    "    try:\n",
    "        # color_20250314_154240.png 형식 가정\n",
    "        parts = filename.replace('color_', '').replace('.png', '').split('_')\n",
    "        if len(parts) >= 2:\n",
    "            return f\"{parts[0]}_{parts[1]}\"\n",
    "        else:\n",
    "            print(f\"❌ 타임스탬프 추출 실패: {filename}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 타임스탬프 추출 중 오류: {filename}, {e}\")\n",
    "        return None\n",
    "\n",
    "def robust_dataset_loading(rgb_dir, depth_array_dir, depth_image_dir, mde_dir, indices, target_size=(64, 64)):\n",
    "    \"\"\"개선된 데이터셋 로딩 함수\"\"\"\n",
    "    rgb_files = sorted([f for f in os.listdir(rgb_dir) if f.startswith('color_') and f.endswith('.png')])\n",
    "    \n",
    "    rgb_images = []\n",
    "    depth_maps = []\n",
    "    mde_maps = []\n",
    "    \n",
    "    for index in indices:\n",
    "        if index >= len(rgb_files):\n",
    "            print(f\"❌ 인덱스 {index}는 파일 범위를 벗어났습니다.\")\n",
    "            continue\n",
    "        \n",
    "        rgb_filename = rgb_files[index]\n",
    "        timestamp = extract_timestamp_safely(rgb_filename)\n",
    "        \n",
    "        if not timestamp:\n",
    "            continue\n",
    "        \n",
    "        # RGB 이미지 로드\n",
    "        rgb_path = os.path.join(rgb_dir, rgb_filename)\n",
    "        rgb = safe_load_image(rgb_path)\n",
    "        if rgb is None:\n",
    "            continue\n",
    "        \n",
    "        # 깊이 맵 로드 (우선순위: NPY > PNG)\n",
    "        depth_npy_path = os.path.join(depth_array_dir, f'depth_{timestamp}.npy')\n",
    "        depth_png_path = os.path.join(depth_image_dir, f'depth_{timestamp}.png')\n",
    "        \n",
    "        depth = safe_load_depth(depth_npy_path, is_npy=True)\n",
    "        if depth is None:\n",
    "            depth = safe_load_depth(depth_png_path)\n",
    "        \n",
    "        if depth is None:\n",
    "            continue\n",
    "        \n",
    "        # MDE 맵 로드\n",
    "        mde_path = os.path.join(mde_dir, f'color_{timestamp}_depth.npy')\n",
    "        mde = safe_load_depth(mde_path, is_npy=True)\n",
    "        \n",
    "        if mde is None:\n",
    "            continue\n",
    "        \n",
    "        # 크기 조정\n",
    "        rgb_resized = cv2.resize(rgb, target_size, interpolation=cv2.INTER_AREA)\n",
    "        depth_resized = cv2.resize(depth, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        mde_resized = cv2.resize(mde, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        rgb_images.append(rgb_resized)\n",
    "        depth_maps.append(depth_resized)\n",
    "        mde_maps.append(mde_resized)\n",
    "    \n",
    "    if not rgb_images:\n",
    "        print(\"❌ 유효한 샘플이 없습니다!\")\n",
    "        return None\n",
    "    \n",
    "    return (\n",
    "        np.array(rgb_images), \n",
    "        np.array(depth_maps), \n",
    "        np.array(mde_maps)\n",
    "    )\n",
    "\n",
    "\n",
    "# 데이터셋 생성 함수 - 기존 데이터 파일 활용\n",
    "def create_dataset_from_existing_data(rgb_dir, depth_array_dir ,depth_image_dir, mde_dir, batch_size=8, target_size=(64, 64), max_samples=1000):\n",
    "    \"\"\"\n",
    "    기존 데이터 파일에서 MDE 인식 모델을 위한 데이터셋 생성\n",
    "    \"\"\"\n",
    "    # 매칭된 데이터 로드\n",
    "    rgb_images, depth_maps, mde_maps = load_paired_data_from_existing_files(\n",
    "        rgb_dir, depth_array_dir ,depth_image_dir, mde_dir, max_samples\n",
    "    )\n",
    "    \n",
    "    print(f\"로드된 데이터 형태: RGB {rgb_images.shape}, Depth {depth_maps.shape}, MDE {mde_maps.shape}\")\n",
    "    \n",
    "    # 데이터 분할\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    rgb_train, rgb_val, depth_train, depth_val, mde_train, mde_val = train_test_split(\n",
    "        rgb_images, depth_maps, mde_maps, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"학습 데이터: {len(rgb_train)}개, 검증 데이터: {len(rgb_val)}개\")\n",
    "    \n",
    "    # 기존 코드 유지\n",
    "    train_dataset = process_and_create_dataset(\n",
    "        rgb_train, depth_train, mde_train, batch_size, target_size\n",
    "    )\n",
    "    \n",
    "    val_dataset = process_and_create_dataset(\n",
    "        rgb_val, depth_val, mde_val, batch_size, target_size\n",
    "    )\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def process_and_create_dataset(rgb_images, depth_maps, mde_maps, batch_size, target_size):\n",
    "    \"\"\"\n",
    "    배열에서 데이터셋 생성 및 전처리\n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(rgb_images)):\n",
    "        # RGB 이미지 크기 조정\n",
    "        rgb = cv2.resize(rgb_images[i], target_size, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # 깊이 맵 크기 조정\n",
    "        depth = cv2.resize(depth_maps[i], target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # MDE 맵 크기 조정\n",
    "        mde = cv2.resize(mde_maps[i], target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # RGB 정규화\n",
    "        rgb_norm = rgb.astype(np.float32) / 255.0\n",
    "        \n",
    "        # 신뢰도 맵 계산\n",
    "        sensor_confidence = np.ones_like(depth, dtype=np.float32) * 0.6\n",
    "        mde_confidence = np.ones_like(mde, dtype=np.float32) * 0.7\n",
    "        \n",
    "        # 입력 결합 - 7채널로 확장\n",
    "        combined_input = np.concatenate([\n",
    "            rgb_norm,\n",
    "            np.expand_dims(depth, axis=-1),\n",
    "            np.expand_dims(mde, axis=-1),  # MDE 깊이 추가\n",
    "            np.expand_dims(sensor_confidence, axis=-1),\n",
    "            np.expand_dims(mde_confidence, axis=-1)  # MDE 신뢰도 맵 추가\n",
    "        ], axis=-1)\n",
    "        \n",
    "        # 타겟 깊이 (실측 깊이)\n",
    "        target_depth = np.expand_dims(depth, axis=-1)\n",
    "        \n",
    "        inputs.append(combined_input)\n",
    "        targets.append(target_depth)\n",
    "    \n",
    "    # 데이터 유효성 확인\n",
    "    if len(inputs) == 0:\n",
    "        print(\"처리된 입력 데이터가 없습니다!\")\n",
    "        return None\n",
    "        \n",
    "    # NumPy 배열로 변환\n",
    "    inputs = np.array(inputs)\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    print(f\"입력 데이터 형태: {inputs.shape}\")\n",
    "    print(f\"타겟 데이터 형태: {targets.shape}\")\n",
    "    \n",
    "    # TensorFlow 데이터셋 생성\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
    "    \n",
    "    # 배치 및 프리페치\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "    \n",
    "# 신뢰도 맵 생성 함수 개선\n",
    "def create_confidence_map(depth):\n",
    "    \"\"\"더 현실적인 신뢰도 맵 생성\"\"\"\n",
    "    confidence = np.zeros_like(depth, dtype=np.float32)\n",
    "    \n",
    "    # 깊이 값이 존재하는 곳에는 높은 신뢰도 (하지만 1.0은 아님)\n",
    "    valid_mask = (depth > 0)\n",
    "    confidence[valid_mask] = 0.9\n",
    "    \n",
    "    # 에지에는 더 낮은 신뢰도 (에지 검출)\n",
    "    if np.sum(valid_mask) > 100:  # 충분한 유효 픽셀이 있을 때만\n",
    "        try:\n",
    "            from scipy.ndimage import sobel\n",
    "            edges = np.sqrt(sobel(depth, axis=0)**2 + sobel(depth, axis=1)**2)\n",
    "            edge_mask = edges > np.percentile(edges[valid_mask], 80)\n",
    "            confidence[edge_mask & valid_mask] = 0.7\n",
    "        except:\n",
    "            pass  # 예외가 발생하면 에지 처리 생략\n",
    "    \n",
    "    # 깊이 값이 없는 곳에는 낮은 신뢰도\n",
    "    confidence[~valid_mask] = 0.3\n",
    "    \n",
    "    # 신뢰도 맵 부드럽게 처리\n",
    "    try:\n",
    "        from scipy.ndimage import gaussian_filter\n",
    "        confidence = gaussian_filter(confidence, sigma=1.0)\n",
    "    except:\n",
    "        pass  # 예외가 발생하면 필터링 생략\n",
    "    \n",
    "    return confidence\n",
    "    \n",
    "# MDE와 깊이 맵 스케일 정렬 함수 (개선됨)\n",
    "def align_mde_with_depth_improved(mde, depth):\n",
    "    \"\"\"Improved MDE and depth map scale alignment with better robust estimation\"\"\"\n",
    "    # Convert MDE from m to mm\n",
    "    mde_mm = mde * 1000.0\n",
    "    \n",
    "    # Valid depth pixel mask\n",
    "    valid_mask = (depth > 0)\n",
    "    \n",
    "    if np.sum(valid_mask) < 100:  # Need more valid pixels for reliable estimation\n",
    "        return mde_mm\n",
    "    \n",
    "    # Extract depth values excluding outliers (use 10-90 percentiles for stricter filtering)\n",
    "    valid_depth = depth[valid_mask]\n",
    "    valid_mde = mde_mm[valid_mask]\n",
    "    \n",
    "    # Calculate depth valid range (stricter outlier removal)\n",
    "    depth_q10 = np.percentile(valid_depth, 10)\n",
    "    depth_q90 = np.percentile(valid_depth, 90)\n",
    "    valid_range_mask = (valid_depth >= depth_q10) & (valid_depth <= depth_q90)\n",
    "    \n",
    "    if np.sum(valid_range_mask) < 100:\n",
    "        # Fall back to a more aggressive median-based scaling\n",
    "        median_ratio = np.median(valid_depth) / np.median(valid_mde)\n",
    "        median_ratio = np.clip(median_ratio, 0.5, 2.0)  # Limit scaling range\n",
    "        return mde_mm * median_ratio\n",
    "    \n",
    "    # Use only values within valid range\n",
    "    filtered_depth = valid_depth[valid_range_mask]\n",
    "    filtered_mde = valid_mde[valid_range_mask]\n",
    "    \n",
    "    # Use more robust scaling approach (multi-scale fitting)\n",
    "    try:\n",
    "        # Try multiple scale estimations and choose the best one\n",
    "        scale_options = []\n",
    "        \n",
    "        # Option 1: Simple median ratio\n",
    "        median_ratio = np.median(filtered_depth) / np.median(filtered_mde)\n",
    "        median_ratio = np.clip(median_ratio, 0.5, 2.0)\n",
    "        scale_options.append(median_ratio)\n",
    "        \n",
    "        # Option 2: RANSAC regression for robust scale estimation\n",
    "        model = RANSACRegressor(min_samples=0.7, max_trials=200)\n",
    "        model.fit(filtered_mde.reshape(-1, 1), filtered_depth.reshape(-1, 1))\n",
    "        ransac_scale = model.estimator_.coef_[0][0]\n",
    "        ransac_scale = np.clip(ransac_scale, 0.5, 2.0)\n",
    "        scale_options.append(ransac_scale)\n",
    "        \n",
    "        # Option 3: Quartile-based ratio (more robust than median)\n",
    "        q3_depth = np.percentile(filtered_depth, 75)\n",
    "        q3_mde = np.percentile(filtered_mde, 75)\n",
    "        q3_ratio = q3_depth / q3_mde if q3_mde > 0 else 1.0\n",
    "        q3_ratio = np.clip(q3_ratio, 0.5, 2.0)\n",
    "        scale_options.append(q3_ratio)\n",
    "        \n",
    "        # Choose the median of all scale options for better stability\n",
    "        final_scale = np.median(scale_options)\n",
    "        \n",
    "        # Apply scaling\n",
    "        aligned_mde = mde_mm * final_scale\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during MDE alignment: {str(e)}\")\n",
    "        # Fall back to simple median scaling\n",
    "        median_ratio = np.median(filtered_depth) / np.median(filtered_mde)\n",
    "        median_ratio = np.clip(median_ratio, 0.5, 2.0)\n",
    "        aligned_mde = mde_mm * median_ratio\n",
    "    \n",
    "    return aligned_mde\n",
    "\n",
    "# 개선된 하이브리드 깊이 맵 생성 함수\n",
    "def create_hybrid_depth_robust(rgb, depth, mde):\n",
    "    \"\"\"More robust hybrid depth map creation with better blending strategy\"\"\"\n",
    "    # Align MDE scale with depth\n",
    "    aligned_mde = align_mde_with_depth_improved(mde, depth)\n",
    "    \n",
    "    # Valid depth pixel mask\n",
    "    valid_mask = (depth > 0)\n",
    "    \n",
    "    # Missing depth pixel mask\n",
    "    missing_mask = (depth == 0)\n",
    "    \n",
    "    # Initialize hybrid depth map\n",
    "    hybrid_depth = depth.copy().astype(np.float32)\n",
    "    \n",
    "    # Identify reliable MDE regions (with stricter filtering)\n",
    "    mde_valid = (aligned_mde > 0)\n",
    "    \n",
    "    # Use hybrid approach for confidence-based blending\n",
    "    if np.any(valid_mask) and np.any(mde_valid):\n",
    "        # Calculate statistics for better outlier detection\n",
    "        valid_depth_values = depth[valid_mask]\n",
    "        \n",
    "        # Calculate depth value valid range using more robust IQR method\n",
    "        depth_q25 = np.percentile(valid_depth_values, 25)\n",
    "        depth_q75 = np.percentile(valid_depth_values, 75)\n",
    "        depth_iqr = depth_q75 - depth_q25\n",
    "        depth_median = np.median(valid_depth_values)\n",
    "        \n",
    "        # Stricter bounds for outlier detection\n",
    "        lower_bound = depth_median - 1.5 * depth_iqr\n",
    "        upper_bound = depth_median + 1.5 * depth_iqr\n",
    "        \n",
    "        # MDE outlier mask\n",
    "        mde_outlier = (aligned_mde < lower_bound) | (aligned_mde > upper_bound)\n",
    "        \n",
    "        # Use only valid and non-outlier MDE\n",
    "        reliable_mde_mask = mde_valid & ~mde_outlier\n",
    "        \n",
    "        # Fill missing parts with reliable MDE\n",
    "        fill_mask = missing_mask & reliable_mde_mask\n",
    "        hybrid_depth[fill_mask] = aligned_mde[fill_mask]\n",
    "        \n",
    "        # Create confidence-based blending for partially valid regions\n",
    "        # (areas where both depth and MDE exist, but we want to use the more reliable one)\n",
    "        blend_mask = valid_mask & reliable_mde_mask\n",
    "        \n",
    "        # Edge detection on depth map for finding discontinuities\n",
    "        depth_edges = np.sqrt(sobel(depth, axis=0)**2 + sobel(depth, axis=1)**2)\n",
    "        edge_mask = depth_edges > np.percentile(depth_edges[depth > 0], 85)\n",
    "        \n",
    "        # Higher MDE confidence near edges (depth sensors often fail at edges)\n",
    "        edge_dilated = binary_dilation(edge_mask, iterations=3)\n",
    "        \n",
    "        # Blend based on confidence - use MDE more near edges\n",
    "        edge_blend_mask = blend_mask & edge_dilated\n",
    "        if np.any(edge_blend_mask):\n",
    "            # Smooth blending - 70% MDE, 30% depth at edges\n",
    "            hybrid_depth[edge_blend_mask] = 0.7 * aligned_mde[edge_blend_mask] + 0.3 * depth[edge_blend_mask]\n",
    "    \n",
    "    # Apply median filtering to remove any remaining noise\n",
    "    if np.sum(hybrid_depth > 0) > 100:\n",
    "        # Only apply median filter to areas with depth values\n",
    "        valid_hybrid = hybrid_depth > 0\n",
    "        filtered = median_filter(hybrid_depth, size=3)\n",
    "        hybrid_depth[valid_hybrid] = filtered[valid_hybrid]\n",
    "    \n",
    "    # Smooth confidence transitions\n",
    "    confidence_map = create_confidence_map(depth)\n",
    "    \n",
    "    return hybrid_depth, confidence_map\n",
    "\n",
    "\n",
    "def prepare_model_input(rgb, depth, mde, target_size=(192, 192)):\n",
    "    \"\"\"\n",
    "    모델 입력 데이터를 준비하는 함수\n",
    "    \n",
    "    매개변수:\n",
    "    - rgb: RGB 이미지\n",
    "    - depth: 실측 깊이 맵\n",
    "    - mde: MDE 깊이 맵\n",
    "    - target_size: 모델 입력 크기 (기본값 192x192)\n",
    "    \n",
    "    반환값:\n",
    "    - model_input: 모델 입력 데이터 (배치 차원 포함)\n",
    "    - hybrid_depth: 생성된 하이브리드 깊이 맵\n",
    "    - confidence_map: 신뢰도 맵\n",
    "    \"\"\"\n",
    "    # 이미지 크기 조정\n",
    "    rgb_resized = cv2.resize(rgb, target_size, interpolation=cv2.INTER_AREA)\n",
    "    depth_resized = cv2.resize(depth, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "    mde_resized = cv2.resize(mde, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    # 하이브리드 깊이 맵 생성\n",
    "    hybrid_depth, _ = create_hybrid_depth_robust(rgb_resized, depth_resized, mde_resized)\n",
    "    \n",
    "    # 신뢰도 맵 생성 - 여기를 수정\n",
    "    confidence_map = create_confidence_map(depth_resized)  # 새 함수 사용\n",
    "    \n",
    "    # 입력 전처리\n",
    "    rgb_norm = rgb_resized.astype(np.float32) / 255.0  # RGB 정규화\n",
    "    \n",
    "    # 차원 확장\n",
    "    hybrid_depth_expanded = np.expand_dims(hybrid_depth, axis=-1)\n",
    "    confidence_map_expanded = np.expand_dims(confidence_map, axis=-1)\n",
    "    \n",
    "    # 입력 결합\n",
    "    combined_input = np.concatenate([rgb_norm, hybrid_depth_expanded, confidence_map_expanded], axis=-1)\n",
    "    \n",
    "    # 배치 차원 추가\n",
    "    model_input = np.expand_dims(combined_input, axis=0)\n",
    "    \n",
    "    return model_input, hybrid_depth, confidence_map\n",
    "\n",
    "def apply_depth_correction(model, rgb, depth, mde, target_size=(192, 192)):\n",
    "    \"\"\"\n",
    "    전체 깊이 보정 과정을 처리하는 함수\n",
    "    \n",
    "    매개변수:\n",
    "    - model: 깊이 보정 모델\n",
    "    - rgb: RGB 이미지\n",
    "    - depth: 실측 깊이 맵\n",
    "    - mde: MDE 깊이 맵\n",
    "    - target_size: 모델 입력 크기 (기본값 192x192)\n",
    "    \n",
    "    반환값:\n",
    "    - corrected_depth: 보정된 깊이 맵\n",
    "    - hybrid_depth: 하이브리드 깊이 맵 (모델 입력으로 사용됨)\n",
    "    - confidence_map: 신뢰도 맵\n",
    "    \"\"\"\n",
    "    # 모델 입력 준비\n",
    "    model_input, hybrid_depth, confidence_map = prepare_model_input(rgb, depth, mde, target_size)\n",
    "    \n",
    "    # 모델 예측\n",
    "    prediction = model.predict(model_input)\n",
    "    \n",
    "    # 결과 추출 (배치 차원 제거 및 채널 차원 제거)\n",
    "    corrected_depth = prediction[0, :, :, 0]\n",
    "    \n",
    "    # 원본 크기로 다시 확장\n",
    "    corrected_depth = cv2.resize(corrected_depth, (depth.shape[1], depth.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    hybrid_depth = cv2.resize(hybrid_depth, (depth.shape[1], depth.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    confidence_map = cv2.resize(confidence_map, (depth.shape[1], depth.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    return corrected_depth, hybrid_depth, confidence_map\n",
    "\n",
    "# 3. 손실 함수 개선 - 에지 보존에 더 큰 가중치 부여\n",
    "def improved_depth_correction_loss_v3(y_true, y_pred):\n",
    "    \"\"\"강화된 깊이 보정 손실 함수\"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    # 유효한 깊이 마스크\n",
    "    mask = tf.cast(tf.greater(y_true, 0), tf.float32)\n",
    "    mask_sum = tf.reduce_sum(mask)\n",
    "    \n",
    "    # 반드시 기본 손실 포함 (마스크가 비어 있어도 학습 가능하도록)\n",
    "    base_loss = 0.0001 * tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "    \n",
    "    # 마스크 유효성 검사\n",
    "    if_valid = lambda: tf.reduce_sum(tf.abs(y_true - y_pred) * mask) / tf.maximum(mask_sum, 1.0)\n",
    "    if_invalid = lambda: base_loss\n",
    "    \n",
    "    # 유효한 마스크가 있으면 마스크된 손실 반환, 그렇지 않으면 기본 손실 반환\n",
    "    l1_loss = tf.cond(tf.greater(mask_sum, 0), if_valid, if_invalid)\n",
    "    \n",
    "    # 에지 인식 그래디언트 손실 (원래 코드와 동일)\n",
    "    dy_true, dx_true = tf.image.image_gradients(y_true)\n",
    "    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n",
    "\n",
    "    grad_true = tf.sqrt(tf.square(dy_true) + tf.square(dx_true) + 1e-8)\n",
    "    grad_pred = tf.sqrt(tf.square(dy_pred) + tf.square(dx_pred) + 1e-8)\n",
    "\n",
    "    grad_loss = tf.reduce_mean(tf.abs(grad_true - grad_pred))  # 간단한 평균으로 계산\n",
    "\n",
    "    # 손실 조합 (기본 손실 포함)\n",
    "    total_loss = l1_loss + 0.5 * grad_loss + base_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "class NanLossCallback(tf.keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None and (np.isnan(loss) or np.isinf(loss)):\n",
    "            print(f\"NaN/Inf 손실 감지됨: {loss}, 학습 중지\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None and (np.isnan(loss) or np.isinf(loss)):\n",
    "            print(f\"에폭 {epoch}에서 NaN/Inf 손실 감지됨: {loss}, 학습 중지\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "def ultra_stable_depth_loss_v2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    개선된 깊이 손실 함수 - NaN 방지 및 안정성 강화\n",
    "    \n",
    "    주요 개선점:\n",
    "    1. 극단적인 클리핑\n",
    "    2. 소프트 마스킹\n",
    "    3. 유효 깊이 픽셀에 대한 가중치 부여\n",
    "    4. 다중 손실 항목\n",
    "    \"\"\"\n",
    "    # 타입 캐스팅 및 안전한 변환\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    # 엡실론 값 - 매우 작은 값으로 나누기/로그 연산 방지\n",
    "    epsilon = 1e-7\n",
    "    \n",
    "    # 극단적인 클리핑 (0-1 범위, 아주 작은 마진 포함)\n",
    "    y_true = tf.clip_by_value(y_true, epsilon, 1.0 - epsilon)\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "    \n",
    "    # 유효한 깊이 픽셀 마스크 (0보다 큰 값)\n",
    "    valid_mask = tf.cast(tf.greater(y_true, epsilon), tf.float32)\n",
    "    \n",
    "    # 마스크된 유효 픽셀 수\n",
    "    mask_sum = tf.maximum(tf.reduce_sum(valid_mask), 1.0)\n",
    "    \n",
    "    # L1 손실 (절대 오차)\n",
    "    l1_loss = tf.reduce_sum(tf.abs(y_true - y_pred) * valid_mask) / mask_sum\n",
    "    \n",
    "    # 로그 코시 손실 - 극단값에 더 강건함\n",
    "    log_cosh_loss = tf.reduce_sum(\n",
    "        tf.math.log(tf.cosh(y_true - y_pred)) * valid_mask\n",
    "    ) / mask_sum\n",
    "    \n",
    "    # 그래디언트 손실 - 에지 보존\n",
    "    dy_true, dx_true = tf.image.image_gradients(y_true)\n",
    "    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n",
    "    \n",
    "    # 그래디언트 크기 계산\n",
    "    grad_true = tf.sqrt(tf.square(dy_true) + tf.square(dx_true) + epsilon)\n",
    "    grad_pred = tf.sqrt(tf.square(dy_pred) + tf.square(dx_pred) + epsilon)\n",
    "    \n",
    "    # 그래디언트 손실\n",
    "    grad_loss = tf.reduce_mean(tf.abs(grad_true - grad_pred))\n",
    "    \n",
    "    # 가중치를 적용한 최종 손실\n",
    "    total_loss = (\n",
    "        1.0 * l1_loss +  # 주요 깊이 오차\n",
    "        0.5 * log_cosh_loss +  # 극단값 강건성\n",
    "        0.3 * grad_loss +  # 에지 보존\n",
    "        0.1 * tf.reduce_mean(tf.square(y_true - y_pred))  # 추가 안정성\n",
    "    )\n",
    "    \n",
    "    # NaN 방지를 위한 최종 안전장치\n",
    "    return tf.where(tf.math.is_finite(total_loss), total_loss, epsilon)\n",
    "\n",
    "def safe_clip_gradients(grads_and_vars, clip_norm=1.0):\n",
    "    \"\"\"\n",
    "    그래디언트 클리핑 및 NaN 방지 함수\n",
    "    \n",
    "    매개변수:\n",
    "    - grads_and_vars: 그래디언트와 변수 쌍\n",
    "    - clip_norm: 최대 그래디언트 노름\n",
    "    \n",
    "    반환값:\n",
    "    안전하게 클리핑된 그래디언트와 변수 쌍\n",
    "    \"\"\"\n",
    "    clipped_grads_and_vars = []\n",
    "    for grad, var in grads_and_vars:\n",
    "        if grad is not None:\n",
    "            # NaN 값 제거\n",
    "            grad = tf.where(tf.math.is_finite(grad), grad, tf.zeros_like(grad))\n",
    "            \n",
    "            # 그래디언트 클리핑\n",
    "            grad = tf.clip_by_norm(grad, clip_norm)\n",
    "            \n",
    "            clipped_grads_and_vars.append((grad, var))\n",
    "        else:\n",
    "            clipped_grads_and_vars.append((grad, var))\n",
    "    \n",
    "    return clipped_grads_and_vars\n",
    "\n",
    "class SafeAdamOptimizer(tf.keras.optimizers.Adam):\n",
    "    \"\"\"\n",
    "    NaN에 강건한 개선된 Adam 옵티마이저\n",
    "    \"\"\"\n",
    "    def _compute_gradients(self, loss, var_list):\n",
    "        # 원래 그래디언트 계산\n",
    "        grads_and_vars = super()._compute_gradients(loss, var_list)\n",
    "        \n",
    "        # 안전한 그래디언트 클리핑 적용\n",
    "        return safe_clip_gradients(grads_and_vars)\n",
    "\n",
    "# ====================================================================================\n",
    "# ✅✅✅ 3. 모델 아키텍처 단순화 - 더 단순하고 안정적인 U-Net 모델\n",
    "# ====================================================================================\n",
    "\n",
    "# 개선된 컨볼루션 블록 함수\n",
    "def conv_block_improved(inputs, filters, kernel_size=3, dropout_rate=0.0, use_residual=True):\n",
    "    \"\"\"개선된 컨볼루션 블록 - 더 안정적인 학습을 위한 정규화 기능 강화\"\"\"\n",
    "    # 첫 번째 컨볼루션\n",
    "    x = layers.Conv2D(\n",
    "        filters, \n",
    "        kernel_size=kernel_size, \n",
    "        padding=\"same\",\n",
    "        kernel_initializer=tf.keras.initializers.HeNormal(),  # He 초기화 사용\n",
    "        kernel_regularizer=l2(1e-5)  # L2 정규화 추가\n",
    "    )(inputs)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    if dropout_rate > 0:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        \n",
    "    # 두 번째 컨볼루션\n",
    "    x = layers.Conv2D(\n",
    "        filters, \n",
    "        kernel_size=kernel_size, \n",
    "        padding=\"same\",\n",
    "        kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "        kernel_regularizer=l2(1e-5)  # L2 정규화 추가\n",
    "    )(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # 잔차 연결 (필요한 경우)\n",
    "    if use_residual:\n",
    "        # 채널 수 맞추기\n",
    "        shortcut = inputs\n",
    "        if int(inputs.shape[-1]) != filters:\n",
    "            shortcut = layers.Conv2D(filters, (1, 1), padding=\"same\")(inputs)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "        x = Add()([x, shortcut])\n",
    "        \n",
    "    return x\n",
    "\n",
    "def resize_compatible_dimensions(rgb_images, depth_maps, mde_predictions, target_size=(60, 80)):\n",
    "    \"\"\"U-Net에 적합한 크기로 이미지 조정 (항상 짝수 차원)\"\"\"\n",
    "    # 각 차원이 8의 배수가 되도록 조정 (3번의 MaxPooling을 고려)\n",
    "    h, w = target_size\n",
    "    h_adjusted = (h // 8) * 8\n",
    "    w_adjusted = (w // 8) * 8\n",
    "    \n",
    "    if h_adjusted != h or w_adjusted != w:\n",
    "        print(f\"크기가 조정됨: {target_size} -> {(h_adjusted, w_adjusted)}\")\n",
    "    \n",
    "    return resize_dataset(rgb_images, depth_maps, mde_predictions, (h_adjusted, w_adjusted))\n",
    "\n",
    "# 개선된 어텐션 블록 - MDE 깊이 모델에 특화된 버전\n",
    "\n",
    "def channel_attention_block(inputs, ratio=8):\n",
    "    \"\"\"\n",
    "    채널 어텐션 블록 - 각 특징 채널의 중요도를 학습\n",
    "    입력의 채널 수에 따라 중요도 가중치 반환\n",
    "    \"\"\"\n",
    "    channel = inputs.shape[-1]\n",
    "    \n",
    "    # 전역 평균 풀링\n",
    "    avg_pool = layers.GlobalAveragePooling2D()(inputs)\n",
    "    avg_pool = layers.Reshape((1, 1, channel))(avg_pool)\n",
    "    \n",
    "    # 전역 최대 풀링\n",
    "    max_pool = layers.GlobalMaxPooling2D()(inputs)\n",
    "    max_pool = layers.Reshape((1, 1, channel))(max_pool)\n",
    "    \n",
    "    # 공유 MLP를 통한 채널 압축 및 확장\n",
    "    shared_mlp_1 = layers.Dense(channel // ratio, activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                use_bias=True, \n",
    "                                bias_initializer='zeros')\n",
    "    shared_mlp_2 = layers.Dense(channel, \n",
    "                                kernel_initializer='he_normal', \n",
    "                                use_bias=True, \n",
    "                                bias_initializer='zeros')\n",
    "    \n",
    "    # 평균 풀링 경로\n",
    "    avg_pool = shared_mlp_1(avg_pool)\n",
    "    avg_pool = shared_mlp_2(avg_pool)\n",
    "    \n",
    "    # 최대 풀링 경로\n",
    "    max_pool = shared_mlp_1(max_pool)\n",
    "    max_pool = shared_mlp_2(max_pool)\n",
    "    \n",
    "    # 특징 융합\n",
    "    attention = layers.Add()([avg_pool, max_pool])\n",
    "    attention = Activation('sigmoid')(attention)\n",
    "    \n",
    "    # 채널별 가중치 적용\n",
    "    return layers.Multiply()([inputs, attention])\n",
    "\n",
    "def spatial_attention_block(inputs):\n",
    "    \"\"\"\n",
    "    공간 어텐션 블록 - 이미지의 어느 부분이 중요한지 학습\n",
    "    \"\"\"\n",
    "    # 채널 축을 따라 평균 및 최대값 계산\n",
    "    avg_pool = layers.Lambda(lambda x: K.mean(x, axis=-1, keepdims=True))(inputs)\n",
    "    max_pool = layers.Lambda(lambda x: K.max(x, axis=-1, keepdims=True))(inputs)\n",
    "    \n",
    "    # 두 특징 연결\n",
    "    concat = layers.Concatenate()([avg_pool, max_pool])\n",
    "    \n",
    "    # 공간 어텐션 맵 생성 - 큰 커널 사용으로 더 넓은 범위 고려\n",
    "    attention = layers.Conv2D(1, kernel_size=7, strides=1, padding='same', \n",
    "                             activation='sigmoid', \n",
    "                             kernel_initializer='he_normal', \n",
    "                             use_bias=False)(concat)\n",
    "    \n",
    "    # 공간 가중치 적용\n",
    "    return layers.Multiply()([inputs, attention])\n",
    "\n",
    "def cbam_block(inputs, ratio=8):\n",
    "    \"\"\"\n",
    "    CBAM(Convolutional Block Attention Module) - 채널과 공간 어텐션 결합\n",
    "    \"\"\"\n",
    "    # 채널 어텐션 적용\n",
    "    channel_attention = channel_attention_block(inputs, ratio)\n",
    "    \n",
    "    # 공간 어텐션 적용\n",
    "    spatial_attention = spatial_attention_block(channel_attention)\n",
    "    \n",
    "    return spatial_attention\n",
    "\n",
    "def depth_aware_attention_block(rgb_features, depth_features, mde_features):\n",
    "    \"\"\"\n",
    "    깊이 인식 어텐션 블록 - RGB, 센서 깊이, MDE 특징 간의 상호작용 학습\n",
    "    \"\"\"\n",
    "    # 채널 수 결정 및 1x1 컨볼루션으로 채널 정규화\n",
    "    channels = max(rgb_features.shape[-1], depth_features.shape[-1], mde_features.shape[-1])\n",
    "    \n",
    "    # 채널 수 맞추기 위한 1x1 컨볼루션\n",
    "    rgb_features = layers.Conv2D(channels, kernel_size=1, padding='same')(rgb_features)\n",
    "    depth_features = layers.Conv2D(channels, kernel_size=1, padding='same')(depth_features)\n",
    "    mde_features = layers.Conv2D(channels, kernel_size=1, padding='same')(mde_features)\n",
    "    \n",
    "    # 모든 특징 연결\n",
    "    all_features = layers.Concatenate()([rgb_features, depth_features, mde_features])\n",
    "    \n",
    "    # 상관관계 학습 (각 특징 간의 상호작용 캡처)\n",
    "    correlation = layers.Conv2D(channels, kernel_size=3, padding='same')(all_features)\n",
    "    correlation = BatchNormalization()(correlation)\n",
    "    correlation = Activation('relu')(correlation)\n",
    "    \n",
    "    # 각 특징별 가중치 생성\n",
    "    weights = layers.Conv2D(3, kernel_size=1, padding='same', activation='softmax')(correlation)\n",
    "    \n",
    "    # 가중치 분리\n",
    "    rgb_weight = layers.Lambda(lambda x: x[:, :, :, 0:1])(weights)\n",
    "    depth_weight = layers.Lambda(lambda x: x[:, :, :, 1:2])(weights)\n",
    "    mde_weight = layers.Lambda(lambda x: x[:, :, :, 2:3])(weights)\n",
    "    \n",
    "    # 가중치 확장\n",
    "    rgb_weight = layers.Lambda(lambda x: K.repeat_elements(x, channels, axis=-1))(rgb_weight)\n",
    "    depth_weight = layers.Lambda(lambda x: K.repeat_elements(x, channels, axis=-1))(depth_weight)\n",
    "    mde_weight = layers.Lambda(lambda x: K.repeat_elements(x, channels, axis=-1))(mde_weight)\n",
    "    \n",
    "    # 가중 특징\n",
    "    weighted_rgb = layers.Multiply()([rgb_features, rgb_weight])\n",
    "    weighted_depth = layers.Multiply()([depth_features, depth_weight])\n",
    "    weighted_mde = layers.Multiply()([mde_features, mde_weight])\n",
    "    \n",
    "    # 가중 특징 결합\n",
    "    weighted_features = layers.Add()([weighted_rgb, weighted_depth, weighted_mde])\n",
    "    \n",
    "    # CBAM 어텐션 적용\n",
    "    enhanced_features = cbam_block(weighted_features)\n",
    "    \n",
    "    # 채널 수 일치를 위해 1x1 컨볼루션 사용\n",
    "    enhanced_features = layers.Conv2D(channels, kernel_size=1, padding='same')(enhanced_features)\n",
    "    \n",
    "    # 잔차 연결 - 1x1 컨볼루션으로 채널 및 차원 정규화\n",
    "    residual_connection = layers.Conv2D(channels, kernel_size=1, padding='same')(all_features)\n",
    "    \n",
    "    # 잔차 연결\n",
    "    output = layers.Add()([residual_connection, enhanced_features])\n",
    "    \n",
    "    return output\n",
    "\n",
    "# 보정 어텐션 계층 - 모델의 어느 부분이 더 많은 보정을 필요로 하는지 예측\n",
    "def correction_attention_block(rgb, depth, mde, confidence):\n",
    "    \"\"\"\n",
    "    보정 어텐션 블록 - 어느 영역이 보정이 필요한지 예측\n",
    "    \"\"\"\n",
    "    # 모든 입력 정보 결합\n",
    "    combined = layers.Concatenate()([rgb, depth, mde, confidence])\n",
    "    \n",
    "    # 보정 필요 영역 예측 네트워크\n",
    "    x = layers.Conv2D(16, kernel_size=3, padding='same')(combined)\n",
    "    x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = layers.Conv2D(8, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # 보정 필요 맵 생성 (높은 값 = 많은 보정 필요)\n",
    "    correction_map = layers.Conv2D(1, kernel_size=3, padding='same', activation='sigmoid')(x)\n",
    "    \n",
    "    # 에지와 불확실성 강조\n",
    "    edge_detector = layers.Conv2D(1, kernel_size=3, padding='same', \n",
    "                                 kernel_initializer=tf.keras.initializers.Constant([\n",
    "                                     [-1, -1, -1],\n",
    "                                     [-1, 8, -1],\n",
    "                                     [-1, -1, -1]\n",
    "                                 ]))(depth)\n",
    "    \n",
    "    edge_response = layers.Lambda(lambda x: K.abs(x))(edge_detector)\n",
    "    edge_response = layers.Lambda(lambda x: K.sigmoid(5 * x))(edge_response)\n",
    "    \n",
    "    # 에지와 보정 맵 결합\n",
    "    final_attention = layers.Add()([correction_map, 0.5 * edge_response])\n",
    "    final_attention = layers.Lambda(lambda x: K.clip(x, 0, 1))(final_attention)\n",
    "    \n",
    "    return final_attention\n",
    "\n",
    "def create_mde_aware_correction_model_with_attention(input_shape=(64, 64, 7)):\n",
    "    \"\"\"\n",
    "    어텐션 메커니즘이 강화된 MDE 인식 깊이 보정 모델\n",
    "    \n",
    "    입력:\n",
    "    - RGB (3채널)\n",
    "    - 센서 깊이 (1채널)\n",
    "    - MDE 예측 깊이 (1채널)\n",
    "    - 센서 깊이 신뢰도 (1채널)\n",
    "    - MDE 예측 신뢰도 (1채널)\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    rgb = layers.Lambda(lambda x: x[:, :, :, :3])(inputs)\n",
    "    sensor_depth = layers.Lambda(lambda x: x[:, :, :, 3:4])(inputs)\n",
    "    mde_depth = layers.Lambda(lambda x: x[:, :, :, 4:5])(inputs)\n",
    "    sensor_confidence = layers.Lambda(lambda x: x[:, :, :, 5:6])(inputs)\n",
    "    mde_confidence = layers.Lambda(lambda x: x[:, :, :, 6:7])(inputs)\n",
    "    \n",
    "    # 보정 어텐션 계산 - 어느 부분이 보정이 필요한지 예측\n",
    "    correction_attention = correction_attention_block(\n",
    "        rgb, sensor_depth, mde_depth,\n",
    "        layers.Concatenate()([sensor_confidence, mde_confidence])\n",
    "    )\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # 인코더 부분 - 각 브랜치에서 특징 추출\n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    # RGB 인코더 브랜치\n",
    "    rgb_conv1 = layers.Conv2D(32, (3, 3), padding='same')(rgb)\n",
    "    rgb_conv1 = BatchNormalization()(rgb_conv1)\n",
    "    rgb_conv1 = Activation('relu')(rgb_conv1)\n",
    "    # 채널 어텐션 적용\n",
    "    rgb_conv1 = channel_attention_block(rgb_conv1)\n",
    "    rgb_pool1 = layers.MaxPooling2D((2, 2))(rgb_conv1)\n",
    "    \n",
    "    rgb_conv2 = layers.Conv2D(64, (3, 3), padding='same')(rgb_pool1)\n",
    "    rgb_conv2 = BatchNormalization()(rgb_conv2)\n",
    "    rgb_conv2 = Activation('relu')(rgb_conv2)\n",
    "    # 채널 어텐션 적용\n",
    "    rgb_conv2 = channel_attention_block(rgb_conv2)\n",
    "    rgb_pool2 = layers.MaxPooling2D((2, 2))(rgb_conv2)\n",
    "    \n",
    "    # 깊이 인코더 브랜치 (센서 깊이 + 신뢰도)\n",
    "    sensor_depth_with_conf = layers.Concatenate()([sensor_depth, sensor_confidence])\n",
    "    depth_conv1 = layers.Conv2D(32, (3, 3), padding='same')(sensor_depth_with_conf)\n",
    "    depth_conv1 = BatchNormalization()(depth_conv1)\n",
    "    depth_conv1 = Activation('relu')(depth_conv1)\n",
    "    # 공간 어텐션 적용\n",
    "    depth_conv1 = spatial_attention_block(depth_conv1)\n",
    "    depth_pool1 = layers.MaxPooling2D((2, 2))(depth_conv1)\n",
    "    \n",
    "    depth_conv2 = layers.Conv2D(64, (3, 3), padding='same')(depth_pool1)\n",
    "    depth_conv2 = BatchNormalization()(depth_conv2)\n",
    "    depth_conv2 = Activation('relu')(depth_conv2)\n",
    "    # 공간 어텐션 적용\n",
    "    depth_conv2 = spatial_attention_block(depth_conv2)\n",
    "    depth_pool2 = layers.MaxPooling2D((2, 2))(depth_conv2)\n",
    "    \n",
    "    # MDE 인코더 브랜치 (MDE 예측 + 신뢰도)\n",
    "    mde_with_conf = layers.Concatenate()([mde_depth, mde_confidence])\n",
    "    mde_conv1 = layers.Conv2D(32, (3, 3), padding='same')(mde_with_conf)\n",
    "    mde_conv1 = BatchNormalization()(mde_conv1)\n",
    "    mde_conv1 = Activation('relu')(mde_conv1)\n",
    "    # 공간 어텐션 적용\n",
    "    mde_conv1 = spatial_attention_block(mde_conv1)\n",
    "    mde_pool1 = layers.MaxPooling2D((2, 2))(mde_conv1)\n",
    "    \n",
    "    mde_conv2 = layers.Conv2D(64, (3, 3), padding='same')(mde_pool1)\n",
    "    mde_conv2 = BatchNormalization()(mde_conv2)\n",
    "    mde_conv2 = Activation('relu')(mde_conv2)\n",
    "    # 공간 어텐션 적용\n",
    "    mde_conv2 = spatial_attention_block(mde_conv2)\n",
    "    mde_pool2 = layers.MaxPooling2D((2, 2))(mde_conv2)\n",
    "    \n",
    "    # 차이 학습 브랜치 - 깊이 센서와 MDE 간의 차이 패턴 학습\n",
    "    depth_diff = layers.Subtract()([sensor_depth, mde_depth])\n",
    "    diff_conv1 = layers.Conv2D(32, (3, 3), padding='same')(depth_diff)\n",
    "    diff_conv1 = BatchNormalization()(diff_conv1)\n",
    "    diff_conv1 = Activation('relu')(diff_conv1)\n",
    "    diff_pool1 = layers.MaxPooling2D((2, 2))(diff_conv1)\n",
    "    \n",
    "    diff_conv2 = layers.Conv2D(64, (3, 3), padding='same')(diff_pool1)\n",
    "    diff_conv2 = BatchNormalization()(diff_conv2)\n",
    "    diff_conv2 = Activation('relu')(diff_conv2)\n",
    "    diff_pool2 = layers.MaxPooling2D((2, 2))(diff_conv2)\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # 중간층 - 특징 융합 및 어텐션 적용\n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    # 첫 번째 레벨 어텐션 적용 특징\n",
    "    level1_attention = depth_aware_attention_block(rgb_conv1, depth_conv1, mde_conv1)\n",
    "    level1_pool = layers.MaxPooling2D((2, 2))(level1_attention)\n",
    "    \n",
    "    # 두 번째 레벨 어텐션 적용 특징\n",
    "    level2_attention = depth_aware_attention_block(rgb_conv2, depth_conv2, mde_conv2)\n",
    "    \n",
    "    # 인코더 특징 융합\n",
    "    encoder_fusion = layers.Concatenate()([rgb_pool2, depth_pool2, mde_pool2, diff_pool2])\n",
    "    \n",
    "    # CBAM 어텐션 적용\n",
    "    attended_fusion = cbam_block(encoder_fusion)\n",
    "    \n",
    "    # 병목층\n",
    "    bottleneck = layers.Conv2D(256, (3, 3), padding='same')(attended_fusion)\n",
    "    bottleneck = BatchNormalization()(bottleneck)\n",
    "    bottleneck = Activation('relu')(bottleneck)\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # 디코더 부분 - 업샘플링 및 스킵 연결\n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    # 첫 번째 업샘플링\n",
    "    up1 = layers.UpSampling2D((2, 2))(bottleneck)\n",
    "    up1 = layers.Conv2D(128, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    \n",
    "    # 스킵 연결\n",
    "    skip1 = layers.Concatenate()([up1, level2_attention])\n",
    "    \n",
    "    # 두 번째 업샘플링\n",
    "    up2 = layers.UpSampling2D((2, 2))(skip1)\n",
    "    up2 = layers.Conv2D(64, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    \n",
    "    # 스킵 연결\n",
    "    skip2 = layers.Concatenate()([up2, level1_attention])\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # 출력 부분 - 깊이 융합 및 보정\n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    # 최종 특징 계산\n",
    "    final_features = layers.Conv2D(32, (3, 3), padding='same')(skip2)\n",
    "    final_features = BatchNormalization()(final_features)\n",
    "    final_features = Activation('relu')(final_features)\n",
    "\n",
    "    # 보정 어텐션 적용\n",
    "    attended_features = layers.Multiply()([\n",
    "        final_features,\n",
    "        layers.Lambda(lambda x: K.repeat_elements(x, 32, axis=-1))(correction_attention)\n",
    "    ])\n",
    "\n",
    "    # 깊이 잔차 예측\n",
    "    correction = layers.Conv2D(1, (3, 3), padding='same')(attended_features)\n",
    "    correction = layers.Lambda(lambda x: 0.1 * K.tanh(x))(correction)  # 보정 범위 축소 (0-1 범위 기준)\n",
    "\n",
    "    # 신뢰도 기반 가중치 계산\n",
    "    fusion_weight = layers.Conv2D(1, (3, 3), padding='same', activation='sigmoid')(final_features)\n",
    "\n",
    "    # 센서 깊이와 MDE 깊이의 유효성 마스크\n",
    "    sensor_valid = layers.Lambda(lambda x: K.cast(K.greater(x, 0), 'float32'))(sensor_depth)\n",
    "    mde_valid = layers.Lambda(lambda x: K.cast(K.greater(x, 0), 'float32'))(mde_depth)\n",
    "\n",
    "    # 입력 깊이 융합 (신뢰도 기반)\n",
    "    base_depth = layers.Lambda(lambda x:\n",
    "                              x[0] * x[1] * x[2] * x[3] +\n",
    "                              x[4] * (1-x[1]) * x[3] +\n",
    "                              x[4] * (1-x[3])\n",
    "                             )([\n",
    "        sensor_depth,\n",
    "        fusion_weight,\n",
    "        sensor_confidence,\n",
    "        sensor_valid,\n",
    "        mde_depth\n",
    "    ])\n",
    "\n",
    "    # 최종 보정 깊이\n",
    "    corrected_depth = layers.Add()([\n",
    "        base_depth,\n",
    "        layers.Multiply()([correction, correction_attention])\n",
    "    ])\n",
    "\n",
    "    # 출력 값 범위 제한 (0-1 범위로)\n",
    "    corrected_depth = layers.Lambda(lambda x: K.clip(x, 0.0, 1.0))(corrected_depth)\n",
    "\n",
    "    model = Model(inputs, corrected_depth)\n",
    "    return model\n",
    "\n",
    "# 단순한 U-Net 모델 생성 함수\n",
    "def create_simple_unet_model(input_shape=(64, 64, 5)):\n",
    "    \"\"\"안정적인 간단한 U-Net 모델\"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "    conv1 = BatchNormalization(momentum=0.9, epsilon=1e-5)(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = layers.Conv2D(32, (3, 3), padding='same')(conv1)\n",
    "    conv1 = BatchNormalization(momentum=0.9, epsilon=1e-5)(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = layers.Conv2D(64, (3, 3), padding='same')(pool1)\n",
    "    conv2 = BatchNormalization(momentum=0.9, epsilon=1e-5)(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = layers.Conv2D(64, (3, 3), padding='same')(conv2)\n",
    "    conv2 = BatchNormalization(momentum=0.9, epsilon=1e-5)(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    conv3 = layers.Conv2D(128, (3, 3), padding='same')(pool2)\n",
    "    conv3 = BatchNormalization(momentum=0.9, epsilon=1e-5)(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = layers.Conv2D(128, (3, 3), padding='same')(conv3)\n",
    "    conv3 = BatchNormalization(momentum=0.9, epsilon=1e-5)(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    \n",
    "    # Decoder\n",
    "    up1 = layers.UpSampling2D(size=(2, 2))(conv3)\n",
    "    up1 = layers.Conv2D(64, (2, 2), padding='same')(up1)\n",
    "    up1 = BatchNormalization(momentum=0.9, epsilon=1e-5)(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    merge1 = layers.Concatenate()([conv2, up1])\n",
    "    conv4 = layers.Conv2D(64, (3, 3), padding='same')(merge1)\n",
    "    conv4 = BatchNormalization(momentum=0.9, epsilon=1e-5)(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    conv4 = layers.Conv2D(64, (3, 3), padding='same')(conv4)\n",
    "    conv4 = BatchNormalization(momentum=0.9, epsilon=1e-5)(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    \n",
    "    up2 = layers.UpSampling2D(size=(2, 2))(conv4)\n",
    "    up2 = layers.Conv2D(32, (2, 2), padding='same')(up2)\n",
    "    up2 = BatchNormalization(momentum=0.9, epsilon=1e-5)(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    merge2 = layers.Concatenate()([conv1, up2])\n",
    "    conv5 = layers.Conv2D(32, (3, 3), padding='same')(merge2)\n",
    "    conv5 = BatchNormalization(momentum=0.9, epsilon=1e-5)(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    conv5 = layers.Conv2D(32, (3, 3), padding='same')(conv5)\n",
    "    conv5 = BatchNormalization(momentum=0.9, epsilon=1e-5)(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    \n",
    "    # 출력 - 활성화 함수 변경 (sigmoid -> linear with clip)\n",
    "    outputs = layers.Conv2D(1, (1, 1), padding='same')(conv5)\n",
    "    outputs = layers.Lambda(lambda x: tf.clip_by_value(x, 0, 1))(outputs)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# ✅✅✅ 4. 학습 파라미터 및 콜백 조정\n",
    "# ====================================================================================\n",
    "\n",
    "# ✅ 학습 중 예측 시각화 콜백 - 중간 결과 확인을 위한 필수 도구\n",
    "class VisualizePredictions(tf.keras.callbacks.Callback):\n",
    "    \"\"\"학습 중 예측 결과를 시각화하는 콜백\"\"\"\n",
    "    def __init__(self, test_data, test_labels, num_samples=3, threshold=0.3):\n",
    "        self.test_data = test_data[:num_samples]\n",
    "        self.test_labels = test_labels[:num_samples]\n",
    "        self.num_samples = num_samples\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 5 == 0:  # 5 에폭마다 시각화\n",
    "            predictions = self.model.predict(self.test_data)\n",
    "            binary_preds = (predictions > self.threshold).astype(np.float32)\n",
    "            \n",
    "            fig, axes = plt.subplots(self.num_samples, 3, figsize=(15, 5*self.num_samples))\n",
    "            for i in range(self.num_samples):\n",
    "                axes[i, 0].imshow(self.test_data[i].squeeze(), cmap=\"gray\")\n",
    "                axes[i, 0].set_title(\"Input\")\n",
    "                axes[i, 1].imshow(self.test_labels[i].squeeze(), cmap=\"gray\")\n",
    "                axes[i, 1].set_title(\"Ground Truth\")\n",
    "                axes[i, 2].imshow(binary_preds[i].squeeze(), cmap=\"gray\")\n",
    "                axes[i, 2].set_title(f\"Prediction (Threshold: {self.threshold})\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'visualizations/pred_epoch_{epoch}.png')\n",
    "            plt.close()\n",
    "\n",
    "# ✅ 학습 설정 함수 개선 - 학습률 증가, 콜백 추가\n",
    "def setup_training(initial_lr=1e-5):  # 학습률도 낮춤\n",
    "    \"\"\"\n",
    "    개선된 학습 설정 - 안정적인 손실 함수 적용\n",
    "    \n",
    "    매개변수:\n",
    "    - initial_lr: 초기 학습률\n",
    "    \"\"\"\n",
    "    # 조기 종료 설정\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        min_delta=1e-4\n",
    "    )\n",
    "\n",
    "    # 학습률 감소 스케줄러\n",
    "    lr_scheduler = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        min_lr=1e-6,\n",
    "        min_delta=1e-4\n",
    "    )\n",
    "\n",
    "    # 체크포인트\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        'checkpoints/model.{epoch:02d}-{val_loss:.4f}.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "    \n",
    "    # NaN 감지 콜백 추가\n",
    "    nan_callback = NanLossCallback()\n",
    "    \n",
    "    # 차원 호환성 문제를 피하기 위한 컴파일 설정\n",
    "    optimizer = Adam(\n",
    "        learning_rate=initial_lr,\n",
    "        clipnorm=0.5,  # 그래디언트 클리핑 추가\n",
    "        epsilon=1e-8\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'callbacks': [early_stopping, lr_scheduler, checkpoint, nan_callback],\n",
    "        'optimizer': optimizer,\n",
    "        'loss': ultra_stable_depth_loss_v2,  # 안정적인 손실 함수로 변경\n",
    "        'metrics': ['mae']\n",
    "    }\n",
    "\n",
    "\n",
    "def debug_dataset_creation(rgb_dir, depth_array_dir, depth_image_dir, mde_dir, indices):\n",
    "    print(\"디버깅: 데이터셋 생성 검사\")\n",
    "    print(f\"RGB 디렉토리: {rgb_dir}\")\n",
    "    print(f\"깊이 배열 디렉토리: {depth_array_dir}\")\n",
    "    print(f\"깊이 이미지 디렉토리: {depth_image_dir}\")\n",
    "    print(f\"MDE 디렉토리: {mde_dir}\")\n",
    "    \n",
    "    rgb_files = sorted([f for f in os.listdir(rgb_dir) if f.endswith('.png')])\n",
    "    depth_array_files = sorted([f for f in os.listdir(depth_array_dir) if f.endswith('.npy')])\n",
    "    depth_image_files = sorted([f for f in os.listdir(depth_image_dir) if f.endswith('.png')])\n",
    "    mde_files = sorted([f for f in os.listdir(mde_dir) if f.endswith('_depth.npy')])\n",
    "    \n",
    "    print(f\"RGB 파일 수: {len(rgb_files)}\")\n",
    "    print(f\"깊이 배열 파일 수: {len(depth_array_files)}\")\n",
    "    print(f\"깊이 이미지 파일 수: {len(depth_image_files)}\")\n",
    "    print(f\"MDE 파일 수: {len(mde_files)}\")\n",
    "    \n",
    "    print(\"\\n첫 5개 파일명 예시:\")\n",
    "    print(\"RGB:\", rgb_files[:5])\n",
    "    print(\"깊이 배열:\", depth_array_files[:5])\n",
    "    print(\"깊이 이미지:\", depth_image_files[:5])\n",
    "    print(\"MDE:\", mde_files[:5])\n",
    "\n",
    "def safe_load_image(path, color_conversion=cv2.COLOR_BGR2RGB):\n",
    "    \"\"\"안전한 이미지 로딩\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"❌ 이미지 로드 실패: {path}\")\n",
    "            return None\n",
    "        return cv2.cvtColor(img, color_conversion)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 이미지 로드 중 오류: {path}, {e}\")\n",
    "        return None\n",
    "\n",
    "def safe_load_depth(path, is_npy=False):\n",
    "    \"\"\"안전한 깊이 데이터 로딩\"\"\"\n",
    "    try:\n",
    "        if is_npy:\n",
    "            depth = np.load(path)\n",
    "        else:\n",
    "            depth = cv2.imread(path, cv2.IMREAD_ANYDEPTH)\n",
    "        \n",
    "        if depth is None:\n",
    "            print(f\"❌ 깊이 데이터 로드 실패: {path}\")\n",
    "            return None\n",
    "        return depth\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 깊이 데이터 로드 중 오류: {path}, {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_timestamp_safely(filename):\n",
    "    try:\n",
    "        # color_20250314_154240.png 형식\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 3 and parts[0] == 'color':\n",
    "            return f\"{parts[1]}_{parts[2].replace('.png', '')}\"\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"타임스탬프 추출 오류: {filename}, {e}\")\n",
    "        return None\n",
    "\n",
    "def robust_dataset_loading(rgb_dir, depth_array_dir, depth_image_dir, mde_dir, indices, target_size=(64, 64)):\n",
    "    \"\"\"개선된 데이터셋 로딩 함수\"\"\"\n",
    "    rgb_files = sorted([f for f in os.listdir(rgb_dir) if f.startswith('color_') and f.endswith('.png')])\n",
    "    \n",
    "    rgb_images = []\n",
    "    depth_maps = []\n",
    "    mde_maps = []\n",
    "    \n",
    "    for index in indices:\n",
    "        if index >= len(rgb_files):\n",
    "            print(f\"❌ 인덱스 {index}는 파일 범위를 벗어났습니다.\")\n",
    "            continue\n",
    "        \n",
    "        rgb_filename = rgb_files[index]\n",
    "        timestamp = extract_timestamp_safely(rgb_filename)\n",
    "        \n",
    "        if not timestamp:\n",
    "            continue\n",
    "        \n",
    "        # RGB 이미지 로드\n",
    "        rgb_path = os.path.join(rgb_dir, rgb_filename)\n",
    "        rgb = safe_load_image(rgb_path)\n",
    "        if rgb is None:\n",
    "            continue\n",
    "        \n",
    "        # 깊이 맵 로드 (우선순위: NPY > PNG)\n",
    "        depth_npy_path = os.path.join(depth_array_dir, f'depth_{timestamp}.npy')\n",
    "        depth_png_path = os.path.join(depth_image_dir, f'depth_{timestamp}.png')\n",
    "        \n",
    "        depth = safe_load_depth(depth_npy_path, is_npy=True)\n",
    "        if depth is None:\n",
    "            depth = safe_load_depth(depth_png_path)\n",
    "        \n",
    "        if depth is None:\n",
    "            continue\n",
    "        \n",
    "        # MDE 맵 로드\n",
    "        mde_path = os.path.join(mde_dir, f'color_{timestamp}_depth.npy')\n",
    "        mde = safe_load_depth(mde_path, is_npy=True)\n",
    "        \n",
    "        if mde is None:\n",
    "            continue\n",
    "        \n",
    "        # 크기 조정\n",
    "        rgb_resized = cv2.resize(rgb, target_size, interpolation=cv2.INTER_AREA)\n",
    "        depth_resized = cv2.resize(depth, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        mde_resized = cv2.resize(mde, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        rgb_images.append(rgb_resized)\n",
    "        depth_maps.append(depth_resized)\n",
    "        mde_maps.append(mde_resized)\n",
    "    \n",
    "    if not rgb_images:\n",
    "        print(\"❌ 유효한 샘플이 없습니다!\")\n",
    "        return None\n",
    "    \n",
    "    return (\n",
    "        np.array(rgb_images), \n",
    "        np.array(depth_maps), \n",
    "        np.array(mde_maps)\n",
    "    )\n",
    "\n",
    "def enhanced_dataset_creator(\n",
    "    rgb_dir, \n",
    "    depth_array_dir, \n",
    "    depth_image_dir, \n",
    "    mde_dir, \n",
    "    indices, \n",
    "    batch_size=8, \n",
    "    target_size=(64, 64)\n",
    "):\n",
    "    rgb_files = sorted([f for f in os.listdir(rgb_dir) if f.startswith('color_') and f.endswith('.png')])\n",
    "    \n",
    "    rgb_images, depth_maps, mde_maps = [], [], []\n",
    "    \n",
    "    for idx in indices:\n",
    "        if idx >= len(rgb_files):\n",
    "            continue\n",
    "        \n",
    "        rgb_filename = rgb_files[idx]\n",
    "        timestamp = extract_timestamp_safely(rgb_filename)\n",
    "        \n",
    "        if not timestamp:\n",
    "            continue\n",
    "        \n",
    "        # RGB 이미지 로드\n",
    "        rgb_path = os.path.join(rgb_dir, rgb_filename)\n",
    "        rgb = safe_load_image(rgb_path)\n",
    "        if rgb is None:\n",
    "            continue\n",
    "        \n",
    "        # 깊이 맵 로드\n",
    "        depth_npy_path = os.path.join(depth_array_dir, f'depth_{timestamp}.npy')\n",
    "        depth_png_path = os.path.join(depth_image_dir, f'depth_{timestamp}.png')\n",
    "        \n",
    "        depth = safe_load_depth(depth_npy_path, is_npy=True)\n",
    "        if depth is None:\n",
    "            depth = safe_load_depth(depth_png_path)\n",
    "        if depth is None:\n",
    "            continue\n",
    "        \n",
    "        # MDE 맵 로드\n",
    "        mde_path = os.path.join(mde_dir, f'color_{timestamp}_depth.npy')\n",
    "        mde = safe_load_depth(mde_path, is_npy=True)\n",
    "        if mde is None:\n",
    "            continue\n",
    "        \n",
    "        # 크기 조정\n",
    "        rgb_resized = cv2.resize(rgb, target_size, interpolation=cv2.INTER_AREA)\n",
    "        depth_resized = cv2.resize(depth, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        mde_resized = cv2.resize(mde, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        rgb_images.append(rgb_resized)\n",
    "        depth_maps.append(depth_resized)\n",
    "        mde_maps.append(mde_resized)\n",
    "    \n",
    "    if not rgb_images:\n",
    "        print(\"❌ 유효한 샘플이 없습니다!\")\n",
    "        return None\n",
    "    \n",
    "    # 데이터 정규화\n",
    "    rgb_norm = np.array(rgb_images).astype(np.float32) / 255.0\n",
    "    depth_norm = np.array(depth_maps).astype(np.float32)\n",
    "    mde_norm = np.array(mde_maps).astype(np.float32)\n",
    "    \n",
    "    # 깊이와 MDE 정규화 (0-1 범위)\n",
    "    for data in [depth_norm, mde_norm]:\n",
    "        valid_mask = data > 0\n",
    "        if np.sum(valid_mask) > 0:\n",
    "            min_val = np.min(data[valid_mask])\n",
    "            max_val = np.max(data[valid_mask])\n",
    "            if max_val > min_val:\n",
    "                data[valid_mask] = (data[valid_mask] - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # 5채널 입력 생성\n",
    "    inputs = np.concatenate([\n",
    "        rgb_norm,\n",
    "        np.expand_dims(depth_norm, axis=-1),\n",
    "        np.expand_dims(mde_norm, axis=-1)\n",
    "    ], axis=-1)\n",
    "    \n",
    "    targets = np.expand_dims(depth_norm, axis=-1)\n",
    "    \n",
    "    print(f\"입력 데이터 형태: {inputs.shape}\")\n",
    "    print(f\"타겟 데이터 형태: {targets.shape}\")\n",
    "    \n",
    "    # 데이터셋 생성\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# 수정된 데이터셋 생성 함수\n",
    "def create_simple_dataset_with_monitoring(\n",
    "    rgb_dir, \n",
    "    depth_array_dir, \n",
    "    depth_image_dir, \n",
    "    mde_dir, \n",
    "    indices, \n",
    "    batch_size, \n",
    "    target_size=(64, 64),\n",
    "    stage=0  # Stage 인자를 추가하여 입력 채널 수를 조정\n",
    "):\n",
    "    \"\"\"\n",
    "    데이터셋 생성 및 모니터링 함수\n",
    "    stage: 학습 단계 (0이면 5채널, 1 이상이면 7채널)\n",
    "    \"\"\"\n",
    "    print(f\"데이터셋 생성 중... 대상 해상도: {target_size}, Stage: {stage}\")\n",
    "    \n",
    "    rgb_images = []\n",
    "    depth_maps = []\n",
    "    mde_predictions = []\n",
    "\n",
    "    # 데이터 로드\n",
    "    rgb_files = sorted([f for f in os.listdir(rgb_dir) if f.endswith('.png')])\n",
    "    for i in indices:\n",
    "        if i >= len(rgb_files):\n",
    "            print(f\"❌ 인덱스 {i}는 RGB 파일 범위를 벗어났습니다.\")\n",
    "            continue\n",
    "        \n",
    "        rgb_filename = rgb_files[i]\n",
    "        timestamp = rgb_filename.replace('color_', '').replace('.png', '')\n",
    "        \n",
    "        # RGB 이미지 로드\n",
    "        rgb_path = os.path.join(rgb_dir, rgb_filename)\n",
    "        try:\n",
    "            rgb = cv2.imread(rgb_path)\n",
    "            if rgb is None:\n",
    "                print(f\"❌ RGB 이미지 로드 실패: {rgb_path}\")\n",
    "                continue\n",
    "            rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ RGB 이미지 로드 중 오류: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # 깊이 맵 로드\n",
    "        depth_array_path = os.path.join(depth_array_dir, f'depth_{timestamp}.npy')\n",
    "        depth_image_path = os.path.join(depth_image_dir, f'depth_{timestamp}.png')\n",
    "        depth = None\n",
    "        try:\n",
    "            if os.path.exists(depth_array_path):\n",
    "                depth = np.load(depth_array_path)\n",
    "            elif os.path.exists(depth_image_path):\n",
    "                depth = cv2.imread(depth_image_path, cv2.IMREAD_ANYDEPTH)\n",
    "            if depth is None:\n",
    "                print(f\"❌ 깊이 데이터 로드 실패: {timestamp}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 깊이 데이터 로드 중 오류: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # MDE 예측 로드\n",
    "        mde_path = os.path.join(mde_dir, f'color_{timestamp}_depth.npy')\n",
    "        try:\n",
    "            if not os.path.exists(mde_path):\n",
    "                print(f\"❌ MDE 파일 없음: {mde_path}\")\n",
    "                continue\n",
    "            mde = np.load(mde_path)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ MDE 데이터 로드 중 오류: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # 크기 조정\n",
    "        resize_dims = (target_size[1], target_size[0])  # (너비, 높이)로 변환\n",
    "        rgb = cv2.resize(rgb, resize_dims, interpolation=cv2.INTER_AREA)\n",
    "        depth = cv2.resize(depth, resize_dims, interpolation=cv2.INTER_NEAREST)\n",
    "        mde = cv2.resize(mde, resize_dims, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        rgb_images.append(rgb)\n",
    "        depth_maps.append(depth)\n",
    "        mde_predictions.append(mde)\n",
    "    \n",
    "    print(f\"로드된 샘플 수: {len(rgb_images)}\")\n",
    "    if len(rgb_images) == 0:\n",
    "        raise ValueError(\"유효한 샘플이 없습니다!\")\n",
    "\n",
    "    # NumPy 배열로 변환\n",
    "    rgb_images = np.array(rgb_images)\n",
    "    depth_maps = np.array(depth_maps)\n",
    "    mde_predictions = np.array(mde_predictions)\n",
    "\n",
    "    def preprocess_data(rgb, depth, mde):\n",
    "        \"\"\"수치적 안정성이 향상된 데이터 전처리 함수\"\"\"\n",
    "        try:\n",
    "            # 입력 데이터 유효성 검사\n",
    "            if (rgb is None or depth is None or mde is None or\n",
    "                len(rgb.shape) != 3 or len(depth.shape) != 2 or len(mde.shape) != 2):\n",
    "                print(f\"❌ 잘못된 입력 데이터: RGB {rgb.shape if rgb is not None else None}, \"\n",
    "                      f\"깊이 {depth.shape if depth is not None else None}, \"\n",
    "                      f\"MDE {mde.shape if mde is not None else None}\")\n",
    "                return None, None\n",
    "    \n",
    "            # 전처리 함수 추가\n",
    "            def enhanced_preprocessing(data):\n",
    "                data = np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                data = np.clip(data, 0.0, 1.0)\n",
    "                data[data < 1e-7] = 0.0\n",
    "                return data\n",
    "    \n",
    "            # RGB 정규화\n",
    "            rgb_norm = rgb.astype(np.float32) / 255.0\n",
    "            rgb_norm = enhanced_preprocessing(rgb_norm)\n",
    "    \n",
    "            # 깊이 맵 정규화\n",
    "            valid_depth_mask = depth > 0\n",
    "            depth_normalized = np.zeros_like(depth, dtype=np.float32)\n",
    "            if np.sum(valid_depth_mask) > 0:\n",
    "                depth_min = np.min(depth[valid_depth_mask])\n",
    "                depth_max = np.max(depth[valid_depth_mask])\n",
    "                if depth_max > depth_min:\n",
    "                    depth_normalized[valid_depth_mask] = (depth[valid_depth_mask] - depth_min) / (depth_max - depth_min)\n",
    "            depth_normalized = enhanced_preprocessing(depth_normalized)\n",
    "    \n",
    "            # MDE 맵 정규화\n",
    "            mde_valid_mask = mde > 0\n",
    "            mde_normalized = np.zeros_like(mde, dtype=np.float32)\n",
    "            if np.sum(mde_valid_mask) > 0:\n",
    "                mde_min = np.min(mde[mde_valid_mask])\n",
    "                mde_max = np.max(mde[mde_valid_mask])\n",
    "                if mde_max > mde_min:\n",
    "                    mde_normalized[mde_valid_mask] = (mde[mde_valid_mask] - mde_min) / (mde_max - mde_min)\n",
    "            mde_normalized = enhanced_preprocessing(mde_normalized)\n",
    "    \n",
    "            # 신뢰도 맵 생성\n",
    "            sensor_confidence = np.full_like(depth, 0.7, dtype=np.float32)\n",
    "            sensor_confidence[~valid_depth_mask] = 0.3  # 깊이 값이 없는 픽셀에 낮은 신뢰도\n",
    "            mde_confidence = np.full_like(mde, 0.7, dtype=np.float32)\n",
    "            mde_confidence[~mde_valid_mask] = 0.3      # MDE 값이 없는 픽셀에 낮은 신뢰도\n",
    "    \n",
    "            # 입력 결합\n",
    "            if stage == 0:  # Stage 1: 5채널\n",
    "                combined_input = np.concatenate([\n",
    "                    rgb_norm,\n",
    "                    np.expand_dims(depth_normalized, axis=-1),\n",
    "                    np.expand_dims(mde_normalized, axis=-1)\n",
    "                ], axis=-1)\n",
    "            else:  # Stage 2 이상: 7채널\n",
    "                combined_input = np.concatenate([\n",
    "                    rgb_norm,\n",
    "                    np.expand_dims(depth_normalized, axis=-1),\n",
    "                    np.expand_dims(mde_normalized, axis=-1),\n",
    "                    np.expand_dims(sensor_confidence, axis=-1),\n",
    "                    np.expand_dims(mde_confidence, axis=-1)\n",
    "                ], axis=-1)\n",
    "        \n",
    "            # 타겟 깊이\n",
    "            target_depth = np.expand_dims(depth_normalized, axis=-1)\n",
    "            return combined_input, target_depth\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"데이터 전처리 중 오류 발생: {e}\")\n",
    "            return None, None\n",
    "    \n",
    "    print(\"데이터 전처리 시작\")\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(rgb_images)):\n",
    "        x, y = preprocess_data(rgb_images[i], depth_maps[i], mde_predictions[i])\n",
    "        if x is not None and y is not None:\n",
    "            inputs.append(x)\n",
    "            targets.append(y)\n",
    "    \n",
    "    if len(inputs) == 0:\n",
    "        print(\"❌ 전처리 후 유효한 샘플이 없습니다!\")\n",
    "        return None\n",
    "    \n",
    "    # NumPy 배열로 변환\n",
    "    inputs = np.array(inputs)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    # 입력 데이터 최종 확인\n",
    "    print(\"최종 입력 데이터 형태:\", inputs.shape)\n",
    "    print(\"입력 데이터 범위:\")\n",
    "    print(\"  RGB:\", np.min(inputs[:,:,:,:3]), \"~\", np.max(inputs[:,:,:,:3]))\n",
    "    print(\"  깊이:\", np.min(inputs[:,:,:,3]), \"~\", np.max(inputs[:,:,:,3]))\n",
    "    print(\"  MDE:\", np.min(inputs[:,:,:,4]), \"~\", np.max(inputs[:,:,:,4]))\n",
    "    if stage > 0:\n",
    "        print(\"  Sensor Confidence:\", np.min(inputs[:,:,:,5]), \"~\", np.max(inputs[:,:,:,5]))\n",
    "        print(\"  MDE Confidence:\", np.min(inputs[:,:,:,6]), \"~\", np.max(inputs[:,:,:,6]))\n",
    "    print(\"최종 타겟 데이터 형태:\", targets.shape)\n",
    "    print(\"타겟 깊이 범위:\", np.min(targets), \"~\", np.max(targets))\n",
    "\n",
    "    # TensorFlow 데이터셋 생성\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def plot_evaluation_metrics(metrics):\n",
    "    \"\"\"\n",
    "    깊이 예측 평가 메트릭을 시각화하는 함수\n",
    "    \n",
    "    매개변수:\n",
    "    - metrics: 평가 메트릭 딕셔너리\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # 각 메트릭에 대한 박스 플롯과 히스토그램\n",
    "    metric_names = list(metrics.keys())\n",
    "    \n",
    "    # 박스 플롯\n",
    "    plt.subplot(121)\n",
    "    plt.boxplot([metrics[name] for name in metric_names], labels=metric_names)\n",
    "    plt.title('Depth Prediction Metrics - Box Plot')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 히스토그램\n",
    "    plt.subplot(122)\n",
    "    for name in metric_names:\n",
    "        plt.hist(metrics[name], alpha=0.5, label=name, bins=10)\n",
    "    plt.title('Depth Prediction Metrics - Histogram')\n",
    "    plt.xlabel('Metric Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/depth_metrics_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "def visualize_results(rgb, true_depth, hybrid_depth, confidence, pred_depth, error):\n",
    "    \"\"\"\n",
    "    깊이 예측 결과를 시각화하는 함수\n",
    "    \n",
    "    매개변수:\n",
    "    - rgb: RGB 이미지\n",
    "    - true_depth: 실제 깊이 맵\n",
    "    - hybrid_depth: 하이브리드 깊이 맵 (입력)\n",
    "    - confidence: 신뢰도 맵\n",
    "    - pred_depth: 예측된 깊이 맵\n",
    "    - error: 깊이 오차 맵\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # RGB 이미지\n",
    "    plt.subplot(231)\n",
    "    plt.imshow(rgb.astype(np.uint8))\n",
    "    plt.title('RGB Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 실제 깊이 맵\n",
    "    plt.subplot(232)\n",
    "    plt.imshow(true_depth, cmap='viridis')\n",
    "    plt.title('Ground Truth Depth')\n",
    "    plt.colorbar(label='Depth')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 하이브리드 깊이 맵 (입력)\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(hybrid_depth, cmap='viridis')\n",
    "    plt.title('Hybrid Depth (Input)')\n",
    "    plt.colorbar(label='Depth')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 신뢰도 맵\n",
    "    plt.subplot(234)\n",
    "    plt.imshow(confidence, cmap='gray')\n",
    "    plt.title('Confidence Map')\n",
    "    plt.colorbar(label='Confidence')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 예측된 깊이 맵\n",
    "    plt.subplot(235)\n",
    "    plt.imshow(pred_depth, cmap='viridis')\n",
    "    plt.title('Predicted Depth')\n",
    "    plt.colorbar(label='Depth')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 깊이 오차 맵\n",
    "    plt.subplot(236)\n",
    "    plt.imshow(error, cmap='hot')\n",
    "    plt.title('Depth Error')\n",
    "    plt.colorbar(label='Error')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt\n",
    "\n",
    "def evaluate_and_visualize_depth_results(model, test_dataset, num_samples=5):\n",
    "    \"\"\"테스트 데이터셋에 대한 깊이 보정 결과 평가 및 시각화\"\"\"\n",
    "    # 메트릭 초기화\n",
    "    metrics = {\n",
    "        'RMSE': [],\n",
    "        'MAE': [],\n",
    "        '상대 오차': [],\n",
    "        '델타(δ) < 1.25': [],\n",
    "        '델타(δ) < 1.25²': [],\n",
    "        '델타(δ) < 1.25³': []\n",
    "    }\n",
    "    \n",
    "    # 디버깅: 데이터셋 확인\n",
    "    print(\"테스트 데이터셋 디버깅:\")\n",
    "    for inputs, targets in test_dataset.take(1):\n",
    "        print(\"입력 데이터 형태:\", inputs.shape)\n",
    "        print(\"타겟 데이터 형태:\", targets.shape)\n",
    "    \n",
    "    # 랜덤 샘플 선택\n",
    "    random_samples = list(test_dataset.take(num_samples))\n",
    "    \n",
    "    for inputs, targets in random_samples:\n",
    "        try:\n",
    "            # 모델 예측\n",
    "            predictions = model.predict(inputs)\n",
    "            \n",
    "            print(\"예측 결과 형태:\", predictions.shape)\n",
    "            \n",
    "            # 각 샘플에 대해\n",
    "            for i in range(inputs.shape[0]):\n",
    "                # 입력 데이터 추출\n",
    "                rgb = inputs[i, :, :, :3].numpy() * 255.0\n",
    "                true_depth = targets[i, :, :, 0].numpy()\n",
    "                \n",
    "                # 예측 결과 안전하게 추출\n",
    "                if len(predictions.shape) == 4:\n",
    "                    pred_depth = predictions[i, :, :, 0]\n",
    "                elif len(predictions.shape) == 3:\n",
    "                    pred_depth = predictions[i, :, :]\n",
    "                else:\n",
    "                    print(f\"예측 결과 형태 오류: {predictions.shape}\")\n",
    "                    continue\n",
    "                \n",
    "                # 유효한 깊이 픽셀 마스크\n",
    "                valid_mask = true_depth > 0\n",
    "                \n",
    "                if np.sum(valid_mask) > 0:\n",
    "                    # 메트릭 계산\n",
    "                    valid_true_depth = true_depth[valid_mask]\n",
    "                    valid_pred_depth = pred_depth[valid_mask]\n",
    "                    \n",
    "                    # RMSE\n",
    "                    rmse = np.sqrt(np.mean((valid_true_depth - valid_pred_depth)**2))\n",
    "                    metrics['RMSE'].append(rmse)\n",
    "                    \n",
    "                    # MAE\n",
    "                    mae = np.mean(np.abs(valid_true_depth - valid_pred_depth))\n",
    "                    metrics['MAE'].append(mae)\n",
    "                    \n",
    "                    # 상대 오차\n",
    "                    rel_error = np.mean(np.abs(valid_true_depth - valid_pred_depth) / valid_true_depth)\n",
    "                    metrics['상대 오차'].append(rel_error)\n",
    "                    \n",
    "                    # 델타 메트릭\n",
    "                    ratio = valid_pred_depth / valid_true_depth\n",
    "                    max_ratio = np.maximum(ratio, 1/ratio)\n",
    "                    \n",
    "                    metrics['델타(δ) < 1.25'].append(np.mean(max_ratio < 1.25))\n",
    "                    metrics['델타(δ) < 1.25²'].append(np.mean(max_ratio < 1.25**2))\n",
    "                    metrics['델타(δ) < 1.25³'].append(np.mean(max_ratio < 1.25**3))\n",
    "                    \n",
    "                    # 시각화\n",
    "                    plt.figure(figsize=(15, 5))\n",
    "                    plt.subplot(131)\n",
    "                    plt.title('RGB')\n",
    "                    plt.imshow(rgb.astype(np.uint8))\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    plt.subplot(132)\n",
    "                    plt.title('True Depth')\n",
    "                    plt.imshow(true_depth, cmap='viridis')\n",
    "                    plt.colorbar()\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    plt.subplot(133)\n",
    "                    plt.title('Predicted Depth')\n",
    "                    plt.imshow(pred_depth, cmap='viridis')\n",
    "                    plt.colorbar()\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(f'visualizations/depth_prediction_sample_{i}.png')\n",
    "                    plt.close()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"샘플 처리 중 오류: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    # 메트릭 요약\n",
    "    print(\"\\n===== 깊이 보정 성능 평가 =====\")\n",
    "    for metric_name, values in metrics.items():\n",
    "        if values:\n",
    "            print(f\"{metric_name}: {np.mean(values):.4f} ± {np.std(values):.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "#데이터셋 크기조정\n",
    "def resize_dataset(rgb_images, depth_maps, mde_predictions, target_size=(240, 320)):\n",
    "    \"\"\"데이터셋의 모든 이미지를 더 작은 해상도로 조정\"\"\"\n",
    "    import cv2\n",
    "    \n",
    "    resized_rgb = []\n",
    "    resized_depth = []\n",
    "    resized_mde = []\n",
    "    \n",
    "    for i in range(len(rgb_images)):\n",
    "        # RGB 이미지 크기 조정\n",
    "        rgb = cv2.resize(rgb_images[i], target_size, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # 깊이 맵 크기 조정 (INTER_NEAREST를 사용하여 깊이 값 보존)\n",
    "        depth = cv2.resize(depth_maps[i], target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # MDE 예측 크기 조정\n",
    "        mde = cv2.resize(mde_predictions[i], target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        resized_rgb.append(rgb)\n",
    "        resized_depth.append(depth)\n",
    "        resized_mde.append(mde)\n",
    "    \n",
    "    return np.array(resized_rgb), np.array(resized_depth), np.array(resized_mde)\n",
    "\n",
    "def setup_mixed_precision(use_mixed_precision=False):\n",
    "    \"\"\"혼합 정밀도 학습을 위한 TensorFlow 구성\"\"\"\n",
    "    if use_mixed_precision:\n",
    "        mixed_precision.set_global_policy('mixed_float16')\n",
    "        print('혼합 정밀도 정책 설정: mixed_float16')\n",
    "    else:\n",
    "        mixed_precision.set_global_policy('float32')\n",
    "        print('기본 정밀도 정책 설정: float32')\n",
    "\n",
    "def plot_training_history(histories, stages):\n",
    "    \"\"\"\n",
    "    다중 해상도 학습 단계의 훈련 히스토리를 시각화하는 함수\n",
    "    \n",
    "    매개변수:\n",
    "    - histories: 각 학습 단계의 히스토리 리스트\n",
    "    - stages: 각 학습 단계의 해상도 리스트\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 손실(Loss) 그래프\n",
    "    plt.subplot(2, 1, 1)\n",
    "    for i, (history, stage) in enumerate(zip(histories, stages)):\n",
    "        plt.plot(history.history['loss'], label=f'Train Loss (Stage {i+1}: {stage})', alpha=0.7)\n",
    "        plt.plot(history.history['val_loss'], label=f'Validation Loss (Stage {i+1}: {stage})', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.title('Training and Validation Loss across Stages')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # MAE(Mean Absolute Error) 그래프\n",
    "    plt.subplot(2, 1, 2)\n",
    "    for i, (history, stage) in enumerate(zip(histories, stages)):\n",
    "        plt.plot(history.history['mae'], label=f'Train MAE (Stage {i+1}: {stage})', alpha=0.7)\n",
    "        plt.plot(history.history['val_mae'], label=f'Validation MAE (Stage {i+1}: {stage})', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.title('Training and Validation Mean Absolute Error across Stages')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Absolute Error')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "def transfer_weights_safely_improved(old_model, new_model):\n",
    "    \"\"\"개선된 안전한 가중치 전이 함수 - skip_mismatch 옵션 사용\"\"\"\n",
    "    print(\"개선된 가중치 전이 함수 실행 중...\")\n",
    "    \n",
    "    # 임시 가중치 파일 저장\n",
    "    temp_weights_path = 'temp_weights.h5'\n",
    "    old_model.save_weights(temp_weights_path)\n",
    "    \n",
    "    try:\n",
    "        # by_name=True와 skip_mismatch=True 옵션으로 가중치 로드\n",
    "        new_model.load_weights(\n",
    "            temp_weights_path, \n",
    "            by_name=True, \n",
    "            skip_mismatch=True\n",
    "        )\n",
    "        print(\"가중치 전이 성공! (일치하지 않는 레이어는 건너뜀)\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"가중치 전이 오류: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        # 임시 파일 삭제 시도\n",
    "        try:\n",
    "            if os.path.exists(temp_weights_path):\n",
    "                os.remove(temp_weights_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# 깊이 보정 결과 시각화 콜백 클래스 (전역 범위로 이동)\n",
    "class DepthCorrectionVisualizer(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, dataset, log_dir, sample_count=2, save_freq=2):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.log_dir = log_dir\n",
    "        self.sample_count = sample_count\n",
    "        self.save_freq = save_freq\n",
    "        self.sample_inputs = []\n",
    "        self.sample_targets = []\n",
    "        for batch in self.dataset.take(sample_count):\n",
    "            inputs, targets = batch\n",
    "            self.sample_inputs.append(inputs[:1])\n",
    "            self.sample_targets.append(targets[:1])\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.save_freq != 0 or not self.sample_inputs:\n",
    "            return\n",
    "\n",
    "        plt.figure(figsize=(12, 4 * self.sample_count))\n",
    "        for i, (sample_input, sample_target) in enumerate(zip(self.sample_inputs, self.sample_targets)):\n",
    "            try:\n",
    "                sample_pred = self.model.predict(sample_input)\n",
    "                rgb = sample_input[0, :, :, :3].numpy()  # RGB만 추출\n",
    "                true_depth = sample_target[0, :, :, 0].numpy()\n",
    "                pred_depth = sample_pred[0, :, :, 0]\n",
    "\n",
    "                plt.subplot(self.sample_count, 3, 3*i + 1)\n",
    "                plt.imshow(rgb)\n",
    "                plt.title('RGB')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.subplot(self.sample_count, 3, 3*i + 2)\n",
    "                plt.imshow(true_depth, cmap='viridis')\n",
    "                plt.title('Ground Truth')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.subplot(self.sample_count, 3, 3*i + 3)\n",
    "                plt.imshow(pred_depth, cmap='viridis')\n",
    "                plt.title('Prediction')\n",
    "                plt.axis('off')\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sample {i}: {e}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.log_dir}/vis_epoch_{epoch:03d}.png', dpi=100)\n",
    "        plt.close()\n",
    "\n",
    "# 개선된 학습 콜백 함수\n",
    "def get_improved_callbacks():\n",
    "    \"\"\"개선된 학습 콜백 함수\"\"\"\n",
    "    # 더 긴 인내심으로 조기 종료 설정\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,  # 늘림\n",
    "        restore_best_weights=True,\n",
    "        min_delta=0.0005  # 더 작은 변화에도 반응\n",
    "    )\n",
    "\n",
    "    # 더 점진적인 학습률 감소\n",
    "    lr_scheduler = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.8,  # 더 작은 감소 계수\n",
    "        patience=10,  # 늘림\n",
    "        verbose=1,\n",
    "        min_lr=1e-7  # 더 낮은 최소 학습률\n",
    "    )\n",
    "\n",
    "    # 체크포인트\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        'checkpoints/depth_model_{epoch:02d}_{val_loss:.6f}.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False  # 전체 모델 저장\n",
    "    )\n",
    "    \n",
    "    # 텐서보드 로깅 추가\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='./logs',\n",
    "        histogram_freq=1,\n",
    "        write_graph=True,\n",
    "        update_freq='epoch'\n",
    "    )\n",
    "    \n",
    "    return [early_stopping, lr_scheduler, checkpoint, tensorboard]\n",
    "\n",
    "# 테스트 결과 저장 함수\n",
    "def save_test_results(test_results, metrics):\n",
    "    \"\"\"테스트 결과를 파일로 저장\"\"\"\n",
    "    results_dir = 'test_results'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    with open(f'{results_dir}/test_metrics.txt', 'w') as f:\n",
    "        f.write(\"===== 깊이 보정 모델 테스트 결과 =====\\n\\n\")\n",
    "        f.write(f\"테스트 손실: {test_results[0]:.4f}\\n\")\n",
    "        f.write(f\"테스트 MAE: {test_results[1]:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"개별 메트릭 평균:\\n\")\n",
    "        for metric_name, values in metrics.items():\n",
    "            if values:\n",
    "                mean_val = np.mean(values)\n",
    "                std_val = np.std(values)\n",
    "                f.write(f\"{metric_name}: {mean_val:.4f} ± {std_val:.4f}\\n\")\n",
    "    \n",
    "    print(f\"✅ 테스트 결과가 저장되었습니다: {results_dir}/test_metrics.txt\")\n",
    "\n",
    "# 모델 컴파일 함수 수정\n",
    "def compile_model_with_gradient_clipping(model, learning_rate=1e-5):\n",
    "    \"\"\"안정적인 학습을 위한 모델 컴파일\"\"\"\n",
    "    # 개선된 옵티마이저 사용\n",
    "    optimizer = SafeAdamOptimizer(\n",
    "        learning_rate=learning_rate,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-7\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=ultra_stable_depth_loss_v2,  # 새로운 손실 함수\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# 모델 학습 직전에 NaN 탐지 함수 추가\n",
    "def detect_nan_values(dataset, name=\"데이터셋\"):\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataset):\n",
    "        inputs_np = inputs.numpy()\n",
    "        targets_np = targets.numpy()\n",
    "        \n",
    "        if np.isnan(inputs_np).any() or np.isinf(inputs_np).any():\n",
    "            print(f\"{name} 입력 배치 {batch_idx}에 NaN/Inf 값이 있습니다!\")\n",
    "            return False\n",
    "        if np.isnan(targets_np).any() or np.isinf(targets_np).any():\n",
    "            print(f\"{name} 타겟 배치 {batch_idx}에 NaN/Inf 값이 있습니다!\")\n",
    "            return False\n",
    "    print(f\"{name}에 NaN/Inf 값이 감지되지 않았습니다.\")\n",
    "    return True\n",
    "\n",
    "def plot_training_metrics(metrics_history):\n",
    "    \"\"\"학습 과정의 메트릭을 시각화\"\"\"\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # 1. 훈련 및 검증 손실\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(metrics_history['train_loss'], label='Train Loss')\n",
    "    plt.plot(metrics_history['val_loss'], label='Validation Loss')\n",
    "    \n",
    "    # 해상도 전환 구간 표시\n",
    "    res_changes = []\n",
    "    prev_res = None\n",
    "    for i, res in enumerate(metrics_history['resolutions']):\n",
    "        if res != prev_res:\n",
    "            res_changes.append(i)\n",
    "            prev_res = res\n",
    "    \n",
    "    for idx in res_changes[1:]:\n",
    "        plt.axvline(x=idx, color='r', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    plt.title('Loss over Training')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 훈련 및 검증 MAE\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(metrics_history['train_mae'], label='Train MAE')\n",
    "    plt.plot(metrics_history['val_mae'], label='Validation MAE')\n",
    "    \n",
    "    for idx in res_changes[1:]:\n",
    "        plt.axvline(x=idx, color='r', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    plt.title('Mean Absolute Error over Training')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. 학습률 변화\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(metrics_history['learning_rates'])\n",
    "    \n",
    "    for idx in res_changes[1:]:\n",
    "        plt.axvline(x=idx, color='r', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    plt.title('Learning Rate over Training')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 해상도 변화 표시\n",
    "    plt.subplot(2, 2, 4)\n",
    "    # 해상도별 구간 막대 그래프\n",
    "    unique_res = []\n",
    "    res_counts = []\n",
    "    current_res = None\n",
    "    count = 0\n",
    "    \n",
    "    for res in metrics_history['resolutions']:\n",
    "        if res != current_res:\n",
    "            if current_res is not None:\n",
    "                unique_res.append(current_res)\n",
    "                res_counts.append(count)\n",
    "            current_res = res\n",
    "            count = 1\n",
    "        else:\n",
    "            count += 1\n",
    "    \n",
    "    # 마지막 해상도 추가\n",
    "    if current_res is not None:\n",
    "        unique_res.append(current_res)\n",
    "        res_counts.append(count)\n",
    "    \n",
    "    plt.bar(unique_res, res_counts)\n",
    "    plt.title('Epochs per Resolution')\n",
    "    plt.xlabel('Resolution')\n",
    "    plt.ylabel('Epochs')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/training_metrics.png', dpi=150)\n",
    "    plt.close()\n",
    "    print(\"✅ 학습 메트릭 시각화가 저장되었습니다: visualizations/training_metrics.png\")\n",
    "\n",
    "# NaN 감지 콜백 (이미 있는 코드)\n",
    "class NanLossCallback(tf.keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None and (np.isnan(loss) or np.isinf(loss)):\n",
    "            print(f\"NaN/Inf 손실 감지됨: {loss}, 학습 중지\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None and (np.isnan(loss) or np.isinf(loss)):\n",
    "            print(f\"에폭 {epoch}에서 NaN/Inf 손실 감지됨: {loss}, 학습 중지\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "def debug_dataset_loading(rgb_dir, depth_array_dir, depth_image_dir, mde_dir, indices, target_size=(64, 64)):\n",
    "    \"\"\"\n",
    "    데이터셋 로딩 과정을 상세히 디버깅하는 함수\n",
    "    \"\"\"\n",
    "    print(\"데이터셋 로딩 디버깅 시작\")\n",
    "    \n",
    "    # 파일 목록\n",
    "    rgb_files = sorted([f for f in os.listdir(rgb_dir) if f.endswith('.png')])\n",
    "    depth_array_files = sorted([f for f in os.listdir(depth_array_dir) if f.endswith('.npy')])\n",
    "    depth_image_files = sorted([f for f in os.listdir(depth_image_dir) if f.endswith('.png')])\n",
    "    mde_files = sorted([f for f in os.listdir(mde_dir) if f.endswith('_depth.npy')])\n",
    "    \n",
    "    print(f\"RGB 파일 수: {len(rgb_files)}\")\n",
    "    print(f\"깊이 배열 파일 수: {len(depth_array_files)}\")\n",
    "    print(f\"깊이 이미지 파일 수: {len(depth_image_files)}\")\n",
    "    print(f\"MDE 파일 수: {len(mde_files)}\")\n",
    "    \n",
    "    # 디버깅용 로깅\n",
    "    detailed_errors = []\n",
    "    \n",
    "    loaded_samples = 0\n",
    "    for i in indices:\n",
    "        if i >= len(rgb_files) or i >= len(mde_files):\n",
    "            detailed_errors.append(f\"인덱스 {i}는 파일 범위를 벗어났습니다.\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # RGB 이미지 로드\n",
    "            rgb_path = os.path.join(rgb_dir, rgb_files[i])\n",
    "            rgb = cv2.imread(rgb_path)\n",
    "            if rgb is None:\n",
    "                detailed_errors.append(f\"RGB 이미지 로드 실패: {rgb_path}\")\n",
    "                continue\n",
    "            rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # 파일명에서 타임스탬프 추출\n",
    "            timestamp = None\n",
    "            parts = rgb_files[i].split('_')\n",
    "            if len(parts) >= 3 and parts[0] == 'color':\n",
    "                timestamp = f\"{parts[1]}_{parts[2].replace('.png', '')}\"\n",
    "            else:\n",
    "                detailed_errors.append(f\"RGB 파일명 형식 오류: {rgb_files[i]}\")\n",
    "                continue\n",
    "            \n",
    "            # 깊이 맵 로드\n",
    "            depth_array_path = os.path.join(depth_array_dir, f\"depth_{timestamp}.npy\")\n",
    "            depth_image_path = os.path.join(depth_image_dir, f\"depth_{timestamp}.png\")\n",
    "            \n",
    "            depth = None\n",
    "            if os.path.exists(depth_array_path):\n",
    "                depth = np.load(depth_array_path)\n",
    "            elif os.path.exists(depth_image_path):\n",
    "                depth = cv2.imread(depth_image_path, cv2.IMREAD_ANYDEPTH)\n",
    "            \n",
    "            if depth is None:\n",
    "                detailed_errors.append(f\"타임스탬프 {timestamp}에 대한 깊이 데이터 없음\")\n",
    "                continue\n",
    "            \n",
    "            # MDE 예측 로드\n",
    "            mde_path = os.path.join(mde_dir, f\"color_{timestamp}_depth.npy\")\n",
    "            if not os.path.exists(mde_path):\n",
    "                detailed_errors.append(f\"MDE 파일 없음: {mde_path}\")\n",
    "                continue\n",
    "            \n",
    "            mde = np.load(mde_path)\n",
    "            \n",
    "            # 크기 조정\n",
    "            rgb_resized = cv2.resize(rgb, target_size, interpolation=cv2.INTER_AREA)\n",
    "            depth_resized = cv2.resize(depth, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "            mde_resized = cv2.resize(mde, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "            \n",
    "            # 데이터 형태 및 범위 확인\n",
    "            print(f\"샘플 {loaded_samples} 데이터 형태:\")\n",
    "            print(f\"  RGB: {rgb_resized.shape}, 타입: {rgb_resized.dtype}\")\n",
    "            print(f\"  깊이: {depth_resized.shape}, 타입: {depth_resized.dtype}\")\n",
    "            print(f\"  MDE: {mde_resized.shape}, 타입: {mde_resized.dtype}\")\n",
    "            print(f\"  깊이 범위: {np.min(depth_resized)} ~ {np.max(depth_resized)}\")\n",
    "            print(f\"  MDE 범위: {np.min(mde_resized)} ~ {np.max(mde_resized)}\")\n",
    "            \n",
    "            loaded_samples += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            detailed_errors.append(f\"샘플 {i} 처리 중 오류: {str(e)}\")\n",
    "    \n",
    "    print(f\"총 로드된 샘플 수: {loaded_samples}\")\n",
    "    \n",
    "    if detailed_errors:\n",
    "        print(\"\\n상세 오류:\")\n",
    "        for error in detailed_errors:\n",
    "            print(error)\n",
    "    \n",
    "    return loaded_samples > 0\n",
    "\n",
    "def progressive_resolution_training_improved(\n",
    "    rgb_dir, depth_array_dir, depth_image_dir, mde_dir, train_idx, val_idx, test_idx\n",
    "):\n",
    "    \"\"\"\n",
    "    개선된 점진적 해상도 훈련 함수\n",
    "    - 안정성 강화\n",
    "    - 학습 진행 상황 시각화 개선\n",
    "    - 결과 분석 기능 추가\n",
    "    \"\"\"\n",
    "    # 낮은 해상도에서 시작하여 점진적으로 증가\n",
    "    resolutions = [(32, 32), (48, 64), (96, 128), (240, 320), (480, 640)]\n",
    "    epochs_per_stage = [15, 12, 10, 8, 5]  # 점진적으로 줄임\n",
    "    batch_sizes = [16, 12, 8, 4, 2]  # 640x480에서는 배치 크기를 2로 줄임\n",
    "    \n",
    "    # 안정적인 학습을 위한 학습률 감소\n",
    "    base_lr = 1e-5\n",
    "    lr_factors = [1.0, 0.1, 0.05, 0.02]\n",
    "    \n",
    "    # 학습/검증/테스트 분할 확인\n",
    "    print(f\"학습 샘플: {len(train_idx)}, 검증 샘플: {len(val_idx)}, 테스트 샘플: {len(test_idx)}\")\n",
    "    \n",
    "    # 로그 디렉토리 생성\n",
    "    log_dir = \"training_logs\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    # 모니터링 메트릭 저장\n",
    "    metrics_history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_mae': [],\n",
    "        'val_mae': [],\n",
    "        'learning_rates': [],\n",
    "        'resolutions': []\n",
    "    }\n",
    "    \n",
    "    # 모델 초기화\n",
    "    model = None\n",
    "    \n",
    "    for stage, (resolution, epochs, batch_size, lr_factor) in enumerate(zip(resolutions, epochs_per_stage, batch_sizes, lr_factors)):\n",
    "        stage_name = f\"Stage{stage+1}_{resolution[0]}x{resolution[1]}\"\n",
    "        print(f\"\\n{'='*20} 학습 단계 {stage+1}/{len(resolutions)}: 해상도 {resolution} {'='*20}\")\n",
    "        \n",
    "        # 현재 단계의 학습률 계산\n",
    "        current_lr = base_lr * lr_factor\n",
    "        print(f\"현재 학습률: {current_lr:.2e}\")\n",
    "    \n",
    "        try:\n",
    "            # 데이터셋 생성\n",
    "            print(f\"데이터셋 생성 중... 대상 해상도: {resolution}\")\n",
    "            train_ds = create_simple_dataset_with_monitoring(\n",
    "                rgb_dir, depth_array_dir, depth_image_dir, mde_dir, train_idx, batch_size, target_size=resolution, stage=stage\n",
    "            )\n",
    "            val_ds = create_simple_dataset_with_monitoring(\n",
    "                rgb_dir, depth_array_dir, depth_image_dir, mde_dir, val_idx, batch_size, target_size=resolution, stage=stage\n",
    "            )\n",
    "\n",
    "            # 데이터셋 생성 실패 시 종료\n",
    "            if train_ds is None or val_ds is None:\n",
    "                raise ValueError(f\"Stage {stage+1}에서 데이터셋 생성에 실패했습니다.\")\n",
    "\n",
    "            # 데이터셋 배치 형태 확인\n",
    "            for batch in train_ds.take(1):\n",
    "                inputs, targets = batch\n",
    "                print(f\"학습 데이터 배치 형태: 입력={inputs.shape}, 타겟={targets.shape}\")\n",
    "            \n",
    "            # 데이터셋 NaN 검사\n",
    "            print(\"데이터셋 NaN/Inf 검사 중...\")\n",
    "            train_data_valid = detect_nan_values(train_ds, \"학습 데이터셋\")\n",
    "            val_data_valid = detect_nan_values(val_ds, \"검증 데이터셋\")\n",
    "            if not (train_data_valid and val_data_valid):\n",
    "                raise ValueError(f\"Stage {stage+1}에서 데이터셋에 NaN/Inf 값이 발견되었습니다.\")\n",
    "        \n",
    "            # 모델 생성 또는 조정\n",
    "            input_shape = (resolution[0], resolution[1], 5 if stage == 0 else 7)\n",
    "            print(f\"모델 입력 차원: {input_shape}\")\n",
    "            \n",
    "            if model is None or stage == 0:\n",
    "                if stage == 0:\n",
    "                    model = create_simple_unet_model(input_shape)\n",
    "                else:\n",
    "                    model = create_mde_aware_correction_model_with_attention(input_shape)\n",
    "                model = compile_model_with_gradient_clipping(model, learning_rate=current_lr)\n",
    "                print(\"새 모델 생성 완료\")\n",
    "            else:\n",
    "                old_model_weights_path = f'checkpoints/depth_model_stage{stage}_weights.h5'\n",
    "                model.save_weights(old_model_weights_path)\n",
    "                new_model = create_mde_aware_correction_model_with_attention(input_shape)\n",
    "                new_model = compile_model_with_gradient_clipping(new_model, learning_rate=current_lr)\n",
    "                transfer_success = transfer_weights_safely_improved(model, new_model)\n",
    "                if transfer_success:\n",
    "                    print(\"가중치 전이 성공\")\n",
    "                else:\n",
    "                    print(\"가중치 전이 실패, 새 가중치로 시작합니다\")\n",
    "                model = new_model\n",
    "            \n",
    "            # 모델 요약 출력 (디버깅용)\n",
    "            model.summary(print_fn=lambda x: print(x))\n",
    "            \n",
    "            # 체크포인트 디렉토리\n",
    "            stage_checkpoint_dir = f'checkpoints/stage{stage+1}'\n",
    "            os.makedirs(stage_checkpoint_dir, exist_ok=True)\n",
    "            \n",
    "            # 콜백 설정\n",
    "            callbacks = [\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=10,\n",
    "                    restore_best_weights=True,\n",
    "                    min_delta=0.0005\n",
    "                ),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor='val_loss',\n",
    "                    factor=0.7,\n",
    "                    patience=5,\n",
    "                    verbose=1,\n",
    "                    min_lr=1e-7\n",
    "                ),\n",
    "                tf.keras.callbacks.ModelCheckpoint(\n",
    "                    f'{stage_checkpoint_dir}/model_epoch_{{epoch:02d}}_valloss_{{val_loss:.4f}}.h5',\n",
    "                    monitor='val_loss',\n",
    "                    save_best_only=True\n",
    "                ),\n",
    "                NanLossCallback(),\n",
    "                tf.keras.callbacks.TensorBoard(\n",
    "                    log_dir=f'{log_dir}/{stage_name}',\n",
    "                    histogram_freq=1,\n",
    "                    update_freq='epoch'\n",
    "                ),\n",
    "                DepthCorrectionVisualizer(\n",
    "                    dataset=val_ds,\n",
    "                    log_dir=f'visualizations/stage{stage+1}',\n",
    "                    sample_count=2,\n",
    "                    save_freq=2\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            # 학습 시작\n",
    "            print(f\"학습 시작: 단계 {stage+1}, 해상도 {resolution}, 에폭 {epochs}\")\n",
    "            history = model.fit(\n",
    "                train_ds,\n",
    "                epochs=epochs,\n",
    "                validation_data=val_ds,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # 메트릭 저장\n",
    "            metrics_history['train_loss'].extend(history.history['loss'])\n",
    "            metrics_history['val_loss'].extend(history.history['val_loss'])\n",
    "            metrics_history['train_mae'].extend(history.history['mae'])\n",
    "            metrics_history['val_mae'].extend(history.history['val_mae'])\n",
    "            metrics_history['learning_rates'].extend([current_lr] * len(history.history['loss']))\n",
    "            metrics_history['resolutions'].extend([f\"{resolution[0]}x{resolution[1]}\"] * len(history.history['loss']))\n",
    "            \n",
    "            # 학습 결과 출력\n",
    "            print(f\"단계 {stage+1} 최종 결과:\")\n",
    "            print(f\"  - 훈련 손실: {history.history['loss'][-1]:.4f}\")\n",
    "            print(f\"  - 검증 손실: {history.history['val_loss'][-1]:.4f}\")\n",
    "            print(f\"  - 훈련 MAE: {history.history['mae'][-1]:.4f}\")\n",
    "            print(f\"  - 검증 MAE: {history.history['val_mae'][-1]:.4f}\")\n",
    "            \n",
    "            # 단계별 모델 저장\n",
    "            stage_model_path = f'checkpoints/depth_model_stage{stage+1}.h5'\n",
    "            model.save(stage_model_path)\n",
    "            print(f\"단계 {stage+1} 모델 저장 완료: {stage_model_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 학습 단계 {stage+1} 중 오류 발생: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            raise  # 오류 발생 시 종료\n",
    "    \n",
    "    # 학습 진행 상황 시각화\n",
    "    plot_training_metrics(metrics_history)\n",
    "    \n",
    "    # 최종 모델 저장\n",
    "    try:\n",
    "        final_model_path = 'depth_correction_model_final.h5'\n",
    "        model.save(final_model_path)\n",
    "        print(f\"✅ 최종 모델이 저장되었습니다: {final_model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 최종 모델 저장 중 오류 발생: {e}\")\n",
    "    \n",
    "    # 테스트 세트로 최종 평가\n",
    "    print(\"\\n===== 최종 모델 평가 =====\")\n",
    "    test_ds = create_simple_dataset_with_monitoring(\n",
    "        rgb_dir, depth_array_dir, depth_image_dir, mde_dir, test_idx, batch_sizes[-1], target_size=resolutions[-1], stage=len(resolutions)-1\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        test_results = model.evaluate(test_ds, verbose=1)\n",
    "        print(f\"테스트 손실: {test_results[0]:.4f}, MAE: {test_results[1]:.4f}\")\n",
    "        metrics = evaluate_and_visualize_depth_results(model, test_ds, num_samples=5)\n",
    "        save_test_results(test_results, metrics)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 테스트 평가 중 오류 발생: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    return model, train_idx, val_idx, test_idx\n",
    "\n",
    "# 실행 함수\n",
    "def run_improved_depth_correction_pipeline():\n",
    "    \"\"\"개선된 깊이 보정 파이프라인 실행 함수\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🚀 개선된 깊이 보정 파이프라인 시작\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 시작 시간 기록\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 시각화 및 체크포인트 디렉토리 생성\n",
    "    for directory in ['visualizations', 'checkpoints', 'logs', 'test_results']:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        print(f\"📁 {directory} 디렉토리 확인 완료\")\n",
    "    \n",
    "    # 파일 경로 설정\n",
    "    rgb_dir = 'color_depth_images/color'\n",
    "    depth_image_dir = 'color_depth_images/depth'  # 깊이 이미지 디렉토리\n",
    "    depth_array_dir = 'color_depth_images/depth_npz'  # 깊이 배열 디렉토리\n",
    "    mde_dir = 'color_depth_images/mde'\n",
    "    \n",
    "    # 사용 가능한 샘플 확인\n",
    "    rgb_files = sorted([f for f in os.listdir(rgb_dir) if f.endswith('.png')])\n",
    "    print(f\"📊 발견된 RGB 이미지: {len(rgb_files)}개\")\n",
    "    \n",
    "    # 샘플 개수 설정 (전체 파일 수와 지정 값 중 작은 값)\n",
    "    num_samples = min(1000, len(rgb_files))\n",
    "    print(f\"📊 사용할 샘플 수: {num_samples}개\")\n",
    "    \n",
    "    # 혼합 정밀도 설정 (float32로 고정)\n",
    "    print(\"🔧 정밀도 설정: float32 (안정성 향상)\")\n",
    "    mixed_precision.set_global_policy('float32')\n",
    "    \n",
    "    # 학습/검증/테스트 분할\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    indices = np.arange(num_samples)\n",
    "    train_idx, temp_idx = train_test_split(indices, test_size=0.4, random_state=42)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # 점진적 해상도 모델 학습 실행\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"📚 점진적 해상도 학습 시작\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    try:\n",
    "        # 모델 학습\n",
    "        model, train_idx, val_idx, test_idx = progressive_resolution_training_improved(\n",
    "            rgb_dir=rgb_dir,\n",
    "            depth_array_dir=depth_array_dir,\n",
    "            depth_image_dir=depth_image_dir,\n",
    "            mde_dir=mde_dir,\n",
    "            train_idx=train_idx,\n",
    "            val_idx=val_idx,\n",
    "            test_idx=test_idx\n",
    "        )\n",
    "        \n",
    "        if model is None:\n",
    "            raise ValueError(\"모델 학습이 실패했습니다.\")\n",
    "        \n",
    "        print(\"✅ 모델 학습 완료!\")\n",
    "        \n",
    "        # 최종 모델 저장\n",
    "        final_model_path = 'depth_correction_model_final.h5'\n",
    "        model.save(final_model_path)\n",
    "        print(f\"✅ 최종 모델이 저장되었습니다: {final_model_path}\")\n",
    "        \n",
    "        # 테스트 데이터셋 생성\n",
    "        print(\"\\n테스트 데이터셋 생성 중...\")\n",
    "        test_ds = create_simple_dataset_with_monitoring(\n",
    "            rgb_dir=rgb_dir,\n",
    "            depth_array_dir=depth_array_dir,\n",
    "            depth_image_dir=depth_image_dir, \n",
    "            mde_dir=mde_dir,\n",
    "            indices=test_idx, \n",
    "            batch_size=8, \n",
    "            target_size=(480, 640),  # 마지막 해상도와 일치\n",
    "            stage=3  # 마지막 Stage (7채널 입력)\n",
    "        )\n",
    "        \n",
    "        if test_ds is None:\n",
    "            raise ValueError(\"테스트 데이터셋 생성에 실패했습니다.\")\n",
    "        \n",
    "        # 최종 모델 평가\n",
    "        print(\"\\n===== 최종 모델 평가 =====\")\n",
    "        test_results = model.evaluate(test_ds, verbose=1)\n",
    "        print(f\"테스트 손실: {test_results[0]:.4f}, MAE: {test_results[1]:.4f}\")\n",
    "        \n",
    "        # 테스트 샘플 시각화\n",
    "        metrics = evaluate_and_visualize_depth_results(model, test_ds, num_samples=5)\n",
    "        \n",
    "        # 종료 시간 및 총 소요 시간 계산\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        hours, remainder = divmod(elapsed_time, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        \n",
    "        print(f\"\\n⏱️ 총 학습 시간: {int(hours)}시간 {int(minutes)}분 {int(seconds)}초\")\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 학습 중 오류 발생: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"\\n⚠️ 파이프라인 실행 실패\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    model = run_improved_depth_correction_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd2358-7686-48bb-bb9c-958bd0efe6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
